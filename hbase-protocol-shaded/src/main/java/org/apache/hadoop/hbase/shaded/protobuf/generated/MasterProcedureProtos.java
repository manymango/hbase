// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: MasterProcedure.proto

package org.apache.hadoop.hbase.shaded.protobuf.generated;

@javax.annotation.Generated("proto") public final class MasterProcedureProtos {
  private MasterProcedureProtos() {}
  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * Protobuf enum {@code hbase.pb.CreateTableState}
   */
  public enum CreateTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CREATE_TABLE_PRE_OPERATION = 1;</code>
     */
    CREATE_TABLE_PRE_OPERATION(1),
    /**
     * <code>CREATE_TABLE_WRITE_FS_LAYOUT = 2;</code>
     */
    CREATE_TABLE_WRITE_FS_LAYOUT(2),
    /**
     * <code>CREATE_TABLE_ADD_TO_META = 3;</code>
     */
    CREATE_TABLE_ADD_TO_META(3),
    /**
     * <code>CREATE_TABLE_ASSIGN_REGIONS = 4;</code>
     */
    CREATE_TABLE_ASSIGN_REGIONS(4),
    /**
     * <code>CREATE_TABLE_UPDATE_DESC_CACHE = 5;</code>
     */
    CREATE_TABLE_UPDATE_DESC_CACHE(5),
    /**
     * <code>CREATE_TABLE_POST_OPERATION = 6;</code>
     */
    CREATE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>CREATE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int CREATE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>CREATE_TABLE_WRITE_FS_LAYOUT = 2;</code>
     */
    public static final int CREATE_TABLE_WRITE_FS_LAYOUT_VALUE = 2;
    /**
     * <code>CREATE_TABLE_ADD_TO_META = 3;</code>
     */
    public static final int CREATE_TABLE_ADD_TO_META_VALUE = 3;
    /**
     * <code>CREATE_TABLE_ASSIGN_REGIONS = 4;</code>
     */
    public static final int CREATE_TABLE_ASSIGN_REGIONS_VALUE = 4;
    /**
     * <code>CREATE_TABLE_UPDATE_DESC_CACHE = 5;</code>
     */
    public static final int CREATE_TABLE_UPDATE_DESC_CACHE_VALUE = 5;
    /**
     * <code>CREATE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int CREATE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CreateTableState valueOf(int value) {
      return forNumber(value);
    }

    public static CreateTableState forNumber(int value) {
      switch (value) {
        case 1: return CREATE_TABLE_PRE_OPERATION;
        case 2: return CREATE_TABLE_WRITE_FS_LAYOUT;
        case 3: return CREATE_TABLE_ADD_TO_META;
        case 4: return CREATE_TABLE_ASSIGN_REGIONS;
        case 5: return CREATE_TABLE_UPDATE_DESC_CACHE;
        case 6: return CREATE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CreateTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        CreateTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CreateTableState>() {
            public CreateTableState findValueByNumber(int number) {
              return CreateTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final CreateTableState[] VALUES = values();

    public static CreateTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CreateTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CreateTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyTableState}
   */
  public enum ModifyTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_TABLE_PREPARE = 1;</code>
     */
    MODIFY_TABLE_PREPARE(1),
    /**
     * <code>MODIFY_TABLE_PRE_OPERATION = 2;</code>
     */
    MODIFY_TABLE_PRE_OPERATION(2),
    /**
     * <code>MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR(3),
    /**
     * <code>MODIFY_TABLE_REMOVE_REPLICA_COLUMN = 4;</code>
     */
    MODIFY_TABLE_REMOVE_REPLICA_COLUMN(4),
    /**
     * <code>MODIFY_TABLE_DELETE_FS_LAYOUT = 5;</code>
     */
    MODIFY_TABLE_DELETE_FS_LAYOUT(5),
    /**
     * <code>MODIFY_TABLE_POST_OPERATION = 6;</code>
     */
    MODIFY_TABLE_POST_OPERATION(6),
    /**
     * <code>MODIFY_TABLE_REOPEN_ALL_REGIONS = 7;</code>
     */
    MODIFY_TABLE_REOPEN_ALL_REGIONS(7),
    ;

    /**
     * <code>MODIFY_TABLE_PREPARE = 1;</code>
     */
    public static final int MODIFY_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int MODIFY_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>MODIFY_TABLE_REMOVE_REPLICA_COLUMN = 4;</code>
     */
    public static final int MODIFY_TABLE_REMOVE_REPLICA_COLUMN_VALUE = 4;
    /**
     * <code>MODIFY_TABLE_DELETE_FS_LAYOUT = 5;</code>
     */
    public static final int MODIFY_TABLE_DELETE_FS_LAYOUT_VALUE = 5;
    /**
     * <code>MODIFY_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int MODIFY_TABLE_POST_OPERATION_VALUE = 6;
    /**
     * <code>MODIFY_TABLE_REOPEN_ALL_REGIONS = 7;</code>
     */
    public static final int MODIFY_TABLE_REOPEN_ALL_REGIONS_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyTableState valueOf(int value) {
      return forNumber(value);
    }

    public static ModifyTableState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_TABLE_PREPARE;
        case 2: return MODIFY_TABLE_PRE_OPERATION;
        case 3: return MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR;
        case 4: return MODIFY_TABLE_REMOVE_REPLICA_COLUMN;
        case 5: return MODIFY_TABLE_DELETE_FS_LAYOUT;
        case 6: return MODIFY_TABLE_POST_OPERATION;
        case 7: return MODIFY_TABLE_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ModifyTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>() {
            public ModifyTableState findValueByNumber(int number) {
              return ModifyTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final ModifyTableState[] VALUES = values();

    public static ModifyTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.TruncateTableState}
   */
  public enum TruncateTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>TRUNCATE_TABLE_PRE_OPERATION = 1;</code>
     */
    TRUNCATE_TABLE_PRE_OPERATION(1),
    /**
     * <code>TRUNCATE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    TRUNCATE_TABLE_REMOVE_FROM_META(2),
    /**
     * <code>TRUNCATE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    TRUNCATE_TABLE_CLEAR_FS_LAYOUT(3),
    /**
     * <code>TRUNCATE_TABLE_CREATE_FS_LAYOUT = 4;</code>
     */
    TRUNCATE_TABLE_CREATE_FS_LAYOUT(4),
    /**
     * <code>TRUNCATE_TABLE_ADD_TO_META = 5;</code>
     */
    TRUNCATE_TABLE_ADD_TO_META(5),
    /**
     * <code>TRUNCATE_TABLE_ASSIGN_REGIONS = 6;</code>
     */
    TRUNCATE_TABLE_ASSIGN_REGIONS(6),
    /**
     * <code>TRUNCATE_TABLE_POST_OPERATION = 7;</code>
     */
    TRUNCATE_TABLE_POST_OPERATION(7),
    ;

    /**
     * <code>TRUNCATE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int TRUNCATE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>TRUNCATE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    public static final int TRUNCATE_TABLE_REMOVE_FROM_META_VALUE = 2;
    /**
     * <code>TRUNCATE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    public static final int TRUNCATE_TABLE_CLEAR_FS_LAYOUT_VALUE = 3;
    /**
     * <code>TRUNCATE_TABLE_CREATE_FS_LAYOUT = 4;</code>
     */
    public static final int TRUNCATE_TABLE_CREATE_FS_LAYOUT_VALUE = 4;
    /**
     * <code>TRUNCATE_TABLE_ADD_TO_META = 5;</code>
     */
    public static final int TRUNCATE_TABLE_ADD_TO_META_VALUE = 5;
    /**
     * <code>TRUNCATE_TABLE_ASSIGN_REGIONS = 6;</code>
     */
    public static final int TRUNCATE_TABLE_ASSIGN_REGIONS_VALUE = 6;
    /**
     * <code>TRUNCATE_TABLE_POST_OPERATION = 7;</code>
     */
    public static final int TRUNCATE_TABLE_POST_OPERATION_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static TruncateTableState valueOf(int value) {
      return forNumber(value);
    }

    public static TruncateTableState forNumber(int value) {
      switch (value) {
        case 1: return TRUNCATE_TABLE_PRE_OPERATION;
        case 2: return TRUNCATE_TABLE_REMOVE_FROM_META;
        case 3: return TRUNCATE_TABLE_CLEAR_FS_LAYOUT;
        case 4: return TRUNCATE_TABLE_CREATE_FS_LAYOUT;
        case 5: return TRUNCATE_TABLE_ADD_TO_META;
        case 6: return TRUNCATE_TABLE_ASSIGN_REGIONS;
        case 7: return TRUNCATE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        TruncateTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>() {
            public TruncateTableState findValueByNumber(int number) {
              return TruncateTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final TruncateTableState[] VALUES = values();

    public static TruncateTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private TruncateTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.TruncateTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteTableState}
   */
  public enum DeleteTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_TABLE_PRE_OPERATION = 1;</code>
     */
    DELETE_TABLE_PRE_OPERATION(1),
    /**
     * <code>DELETE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    DELETE_TABLE_REMOVE_FROM_META(2),
    /**
     * <code>DELETE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    DELETE_TABLE_CLEAR_FS_LAYOUT(3),
    /**
     * <code>DELETE_TABLE_UPDATE_DESC_CACHE = 4;</code>
     */
    DELETE_TABLE_UPDATE_DESC_CACHE(4),
    /**
     * <code>DELETE_TABLE_UNASSIGN_REGIONS = 5;</code>
     */
    DELETE_TABLE_UNASSIGN_REGIONS(5),
    /**
     * <code>DELETE_TABLE_POST_OPERATION = 6;</code>
     */
    DELETE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>DELETE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int DELETE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>DELETE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    public static final int DELETE_TABLE_REMOVE_FROM_META_VALUE = 2;
    /**
     * <code>DELETE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    public static final int DELETE_TABLE_CLEAR_FS_LAYOUT_VALUE = 3;
    /**
     * <code>DELETE_TABLE_UPDATE_DESC_CACHE = 4;</code>
     */
    public static final int DELETE_TABLE_UPDATE_DESC_CACHE_VALUE = 4;
    /**
     * <code>DELETE_TABLE_UNASSIGN_REGIONS = 5;</code>
     */
    public static final int DELETE_TABLE_UNASSIGN_REGIONS_VALUE = 5;
    /**
     * <code>DELETE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int DELETE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DeleteTableState valueOf(int value) {
      return forNumber(value);
    }

    public static DeleteTableState forNumber(int value) {
      switch (value) {
        case 1: return DELETE_TABLE_PRE_OPERATION;
        case 2: return DELETE_TABLE_REMOVE_FROM_META;
        case 3: return DELETE_TABLE_CLEAR_FS_LAYOUT;
        case 4: return DELETE_TABLE_UPDATE_DESC_CACHE;
        case 5: return DELETE_TABLE_UNASSIGN_REGIONS;
        case 6: return DELETE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        DeleteTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>() {
            public DeleteTableState findValueByNumber(int number) {
              return DeleteTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(3);
    }

    private static final DeleteTableState[] VALUES = values();

    public static DeleteTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DeleteTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.CreateNamespaceState}
   */
  public enum CreateNamespaceState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CREATE_NAMESPACE_PREPARE = 1;</code>
     */
    CREATE_NAMESPACE_PREPARE(1),
    /**
     * <code>CREATE_NAMESPACE_CREATE_DIRECTORY = 2;</code>
     */
    CREATE_NAMESPACE_CREATE_DIRECTORY(2),
    /**
     * <code>CREATE_NAMESPACE_INSERT_INTO_NS_TABLE = 3;</code>
     */
    CREATE_NAMESPACE_INSERT_INTO_NS_TABLE(3),
    /**
     * <code>CREATE_NAMESPACE_UPDATE_ZK = 4 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    CREATE_NAMESPACE_UPDATE_ZK(4),
    /**
     * <code>CREATE_NAMESPACE_SET_NAMESPACE_QUOTA = 5;</code>
     */
    CREATE_NAMESPACE_SET_NAMESPACE_QUOTA(5),
    ;

    /**
     * <code>CREATE_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int CREATE_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>CREATE_NAMESPACE_CREATE_DIRECTORY = 2;</code>
     */
    public static final int CREATE_NAMESPACE_CREATE_DIRECTORY_VALUE = 2;
    /**
     * <code>CREATE_NAMESPACE_INSERT_INTO_NS_TABLE = 3;</code>
     */
    public static final int CREATE_NAMESPACE_INSERT_INTO_NS_TABLE_VALUE = 3;
    /**
     * <code>CREATE_NAMESPACE_UPDATE_ZK = 4 [deprecated = true];</code>
     */
    public static final int CREATE_NAMESPACE_UPDATE_ZK_VALUE = 4;
    /**
     * <code>CREATE_NAMESPACE_SET_NAMESPACE_QUOTA = 5;</code>
     */
    public static final int CREATE_NAMESPACE_SET_NAMESPACE_QUOTA_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CreateNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    public static CreateNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return CREATE_NAMESPACE_PREPARE;
        case 2: return CREATE_NAMESPACE_CREATE_DIRECTORY;
        case 3: return CREATE_NAMESPACE_INSERT_INTO_NS_TABLE;
        case 4: return CREATE_NAMESPACE_UPDATE_ZK;
        case 5: return CREATE_NAMESPACE_SET_NAMESPACE_QUOTA;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        CreateNamespaceState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>() {
            public CreateNamespaceState findValueByNumber(int number) {
              return CreateNamespaceState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(4);
    }

    private static final CreateNamespaceState[] VALUES = values();

    public static CreateNamespaceState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CreateNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CreateNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyNamespaceState}
   */
  public enum ModifyNamespaceState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_NAMESPACE_PREPARE = 1;</code>
     */
    MODIFY_NAMESPACE_PREPARE(1),
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_NS_TABLE = 2;</code>
     */
    MODIFY_NAMESPACE_UPDATE_NS_TABLE(2),
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_ZK = 3 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    MODIFY_NAMESPACE_UPDATE_ZK(3),
    ;

    /**
     * <code>MODIFY_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int MODIFY_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_NS_TABLE = 2;</code>
     */
    public static final int MODIFY_NAMESPACE_UPDATE_NS_TABLE_VALUE = 2;
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_ZK = 3 [deprecated = true];</code>
     */
    public static final int MODIFY_NAMESPACE_UPDATE_ZK_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    public static ModifyNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_NAMESPACE_PREPARE;
        case 2: return MODIFY_NAMESPACE_UPDATE_NS_TABLE;
        case 3: return MODIFY_NAMESPACE_UPDATE_ZK;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ModifyNamespaceState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>() {
            public ModifyNamespaceState findValueByNumber(int number) {
              return ModifyNamespaceState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(5);
    }

    private static final ModifyNamespaceState[] VALUES = values();

    public static ModifyNamespaceState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteNamespaceState}
   */
  public enum DeleteNamespaceState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_NAMESPACE_PREPARE = 1;</code>
     */
    DELETE_NAMESPACE_PREPARE(1),
    /**
     * <code>DELETE_NAMESPACE_DELETE_FROM_NS_TABLE = 2;</code>
     */
    DELETE_NAMESPACE_DELETE_FROM_NS_TABLE(2),
    /**
     * <code>DELETE_NAMESPACE_REMOVE_FROM_ZK = 3 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    DELETE_NAMESPACE_REMOVE_FROM_ZK(3),
    /**
     * <code>DELETE_NAMESPACE_DELETE_DIRECTORIES = 4;</code>
     */
    DELETE_NAMESPACE_DELETE_DIRECTORIES(4),
    /**
     * <code>DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA = 5;</code>
     */
    DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA(5),
    ;

    /**
     * <code>DELETE_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int DELETE_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>DELETE_NAMESPACE_DELETE_FROM_NS_TABLE = 2;</code>
     */
    public static final int DELETE_NAMESPACE_DELETE_FROM_NS_TABLE_VALUE = 2;
    /**
     * <code>DELETE_NAMESPACE_REMOVE_FROM_ZK = 3 [deprecated = true];</code>
     */
    public static final int DELETE_NAMESPACE_REMOVE_FROM_ZK_VALUE = 3;
    /**
     * <code>DELETE_NAMESPACE_DELETE_DIRECTORIES = 4;</code>
     */
    public static final int DELETE_NAMESPACE_DELETE_DIRECTORIES_VALUE = 4;
    /**
     * <code>DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA = 5;</code>
     */
    public static final int DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DeleteNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    public static DeleteNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return DELETE_NAMESPACE_PREPARE;
        case 2: return DELETE_NAMESPACE_DELETE_FROM_NS_TABLE;
        case 3: return DELETE_NAMESPACE_REMOVE_FROM_ZK;
        case 4: return DELETE_NAMESPACE_DELETE_DIRECTORIES;
        case 5: return DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        DeleteNamespaceState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>() {
            public DeleteNamespaceState findValueByNumber(int number) {
              return DeleteNamespaceState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(6);
    }

    private static final DeleteNamespaceState[] VALUES = values();

    public static DeleteNamespaceState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DeleteNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.EnableTableState}
   */
  public enum EnableTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ENABLE_TABLE_PREPARE = 1;</code>
     */
    ENABLE_TABLE_PREPARE(1),
    /**
     * <code>ENABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    ENABLE_TABLE_PRE_OPERATION(2),
    /**
     * <code>ENABLE_TABLE_SET_ENABLING_TABLE_STATE = 3;</code>
     */
    ENABLE_TABLE_SET_ENABLING_TABLE_STATE(3),
    /**
     * <code>ENABLE_TABLE_MARK_REGIONS_ONLINE = 4;</code>
     */
    ENABLE_TABLE_MARK_REGIONS_ONLINE(4),
    /**
     * <code>ENABLE_TABLE_SET_ENABLED_TABLE_STATE = 5;</code>
     */
    ENABLE_TABLE_SET_ENABLED_TABLE_STATE(5),
    /**
     * <code>ENABLE_TABLE_POST_OPERATION = 6;</code>
     */
    ENABLE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>ENABLE_TABLE_PREPARE = 1;</code>
     */
    public static final int ENABLE_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>ENABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int ENABLE_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>ENABLE_TABLE_SET_ENABLING_TABLE_STATE = 3;</code>
     */
    public static final int ENABLE_TABLE_SET_ENABLING_TABLE_STATE_VALUE = 3;
    /**
     * <code>ENABLE_TABLE_MARK_REGIONS_ONLINE = 4;</code>
     */
    public static final int ENABLE_TABLE_MARK_REGIONS_ONLINE_VALUE = 4;
    /**
     * <code>ENABLE_TABLE_SET_ENABLED_TABLE_STATE = 5;</code>
     */
    public static final int ENABLE_TABLE_SET_ENABLED_TABLE_STATE_VALUE = 5;
    /**
     * <code>ENABLE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int ENABLE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static EnableTableState valueOf(int value) {
      return forNumber(value);
    }

    public static EnableTableState forNumber(int value) {
      switch (value) {
        case 1: return ENABLE_TABLE_PREPARE;
        case 2: return ENABLE_TABLE_PRE_OPERATION;
        case 3: return ENABLE_TABLE_SET_ENABLING_TABLE_STATE;
        case 4: return ENABLE_TABLE_MARK_REGIONS_ONLINE;
        case 5: return ENABLE_TABLE_SET_ENABLED_TABLE_STATE;
        case 6: return ENABLE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<EnableTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        EnableTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<EnableTableState>() {
            public EnableTableState findValueByNumber(int number) {
              return EnableTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(7);
    }

    private static final EnableTableState[] VALUES = values();

    public static EnableTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private EnableTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.EnableTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DisableTableState}
   */
  public enum DisableTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DISABLE_TABLE_PREPARE = 1;</code>
     */
    DISABLE_TABLE_PREPARE(1),
    /**
     * <code>DISABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    DISABLE_TABLE_PRE_OPERATION(2),
    /**
     * <code>DISABLE_TABLE_SET_DISABLING_TABLE_STATE = 3;</code>
     */
    DISABLE_TABLE_SET_DISABLING_TABLE_STATE(3),
    /**
     * <code>DISABLE_TABLE_MARK_REGIONS_OFFLINE = 4;</code>
     */
    DISABLE_TABLE_MARK_REGIONS_OFFLINE(4),
    /**
     * <code>DISABLE_TABLE_SET_DISABLED_TABLE_STATE = 5;</code>
     */
    DISABLE_TABLE_SET_DISABLED_TABLE_STATE(5),
    /**
     * <code>DISABLE_TABLE_POST_OPERATION = 6;</code>
     */
    DISABLE_TABLE_POST_OPERATION(6),
    /**
     * <code>DISABLE_TABLE_ADD_REPLICATION_BARRIER = 7;</code>
     */
    DISABLE_TABLE_ADD_REPLICATION_BARRIER(7),
    ;

    /**
     * <code>DISABLE_TABLE_PREPARE = 1;</code>
     */
    public static final int DISABLE_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>DISABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int DISABLE_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>DISABLE_TABLE_SET_DISABLING_TABLE_STATE = 3;</code>
     */
    public static final int DISABLE_TABLE_SET_DISABLING_TABLE_STATE_VALUE = 3;
    /**
     * <code>DISABLE_TABLE_MARK_REGIONS_OFFLINE = 4;</code>
     */
    public static final int DISABLE_TABLE_MARK_REGIONS_OFFLINE_VALUE = 4;
    /**
     * <code>DISABLE_TABLE_SET_DISABLED_TABLE_STATE = 5;</code>
     */
    public static final int DISABLE_TABLE_SET_DISABLED_TABLE_STATE_VALUE = 5;
    /**
     * <code>DISABLE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int DISABLE_TABLE_POST_OPERATION_VALUE = 6;
    /**
     * <code>DISABLE_TABLE_ADD_REPLICATION_BARRIER = 7;</code>
     */
    public static final int DISABLE_TABLE_ADD_REPLICATION_BARRIER_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DisableTableState valueOf(int value) {
      return forNumber(value);
    }

    public static DisableTableState forNumber(int value) {
      switch (value) {
        case 1: return DISABLE_TABLE_PREPARE;
        case 2: return DISABLE_TABLE_PRE_OPERATION;
        case 3: return DISABLE_TABLE_SET_DISABLING_TABLE_STATE;
        case 4: return DISABLE_TABLE_MARK_REGIONS_OFFLINE;
        case 5: return DISABLE_TABLE_SET_DISABLED_TABLE_STATE;
        case 6: return DISABLE_TABLE_POST_OPERATION;
        case 7: return DISABLE_TABLE_ADD_REPLICATION_BARRIER;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DisableTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        DisableTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DisableTableState>() {
            public DisableTableState findValueByNumber(int number) {
              return DisableTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(8);
    }

    private static final DisableTableState[] VALUES = values();

    public static DisableTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DisableTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DisableTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.CloneSnapshotState}
   */
  public enum CloneSnapshotState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CLONE_SNAPSHOT_PRE_OPERATION = 1;</code>
     */
    CLONE_SNAPSHOT_PRE_OPERATION(1),
    /**
     * <code>CLONE_SNAPSHOT_WRITE_FS_LAYOUT = 2;</code>
     */
    CLONE_SNAPSHOT_WRITE_FS_LAYOUT(2),
    /**
     * <code>CLONE_SNAPSHOT_ADD_TO_META = 3;</code>
     */
    CLONE_SNAPSHOT_ADD_TO_META(3),
    /**
     * <code>CLONE_SNAPSHOT_ASSIGN_REGIONS = 4;</code>
     */
    CLONE_SNAPSHOT_ASSIGN_REGIONS(4),
    /**
     * <code>CLONE_SNAPSHOT_UPDATE_DESC_CACHE = 5;</code>
     */
    CLONE_SNAPSHOT_UPDATE_DESC_CACHE(5),
    /**
     * <code>CLONE_SNAPSHOT_POST_OPERATION = 6;</code>
     */
    CLONE_SNAPSHOT_POST_OPERATION(6),
    /**
     * <code>CLONE_SNAPHOST_RESTORE_ACL = 7;</code>
     */
    CLONE_SNAPHOST_RESTORE_ACL(7),
    ;

    /**
     * <code>CLONE_SNAPSHOT_PRE_OPERATION = 1;</code>
     */
    public static final int CLONE_SNAPSHOT_PRE_OPERATION_VALUE = 1;
    /**
     * <code>CLONE_SNAPSHOT_WRITE_FS_LAYOUT = 2;</code>
     */
    public static final int CLONE_SNAPSHOT_WRITE_FS_LAYOUT_VALUE = 2;
    /**
     * <code>CLONE_SNAPSHOT_ADD_TO_META = 3;</code>
     */
    public static final int CLONE_SNAPSHOT_ADD_TO_META_VALUE = 3;
    /**
     * <code>CLONE_SNAPSHOT_ASSIGN_REGIONS = 4;</code>
     */
    public static final int CLONE_SNAPSHOT_ASSIGN_REGIONS_VALUE = 4;
    /**
     * <code>CLONE_SNAPSHOT_UPDATE_DESC_CACHE = 5;</code>
     */
    public static final int CLONE_SNAPSHOT_UPDATE_DESC_CACHE_VALUE = 5;
    /**
     * <code>CLONE_SNAPSHOT_POST_OPERATION = 6;</code>
     */
    public static final int CLONE_SNAPSHOT_POST_OPERATION_VALUE = 6;
    /**
     * <code>CLONE_SNAPHOST_RESTORE_ACL = 7;</code>
     */
    public static final int CLONE_SNAPHOST_RESTORE_ACL_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CloneSnapshotState valueOf(int value) {
      return forNumber(value);
    }

    public static CloneSnapshotState forNumber(int value) {
      switch (value) {
        case 1: return CLONE_SNAPSHOT_PRE_OPERATION;
        case 2: return CLONE_SNAPSHOT_WRITE_FS_LAYOUT;
        case 3: return CLONE_SNAPSHOT_ADD_TO_META;
        case 4: return CLONE_SNAPSHOT_ASSIGN_REGIONS;
        case 5: return CLONE_SNAPSHOT_UPDATE_DESC_CACHE;
        case 6: return CLONE_SNAPSHOT_POST_OPERATION;
        case 7: return CLONE_SNAPHOST_RESTORE_ACL;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CloneSnapshotState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        CloneSnapshotState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CloneSnapshotState>() {
            public CloneSnapshotState findValueByNumber(int number) {
              return CloneSnapshotState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(9);
    }

    private static final CloneSnapshotState[] VALUES = values();

    public static CloneSnapshotState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CloneSnapshotState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CloneSnapshotState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RestoreSnapshotState}
   */
  public enum RestoreSnapshotState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>RESTORE_SNAPSHOT_PRE_OPERATION = 1;</code>
     */
    RESTORE_SNAPSHOT_PRE_OPERATION(1),
    /**
     * <code>RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR = 2;</code>
     */
    RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR(2),
    /**
     * <code>RESTORE_SNAPSHOT_WRITE_FS_LAYOUT = 3;</code>
     */
    RESTORE_SNAPSHOT_WRITE_FS_LAYOUT(3),
    /**
     * <code>RESTORE_SNAPSHOT_UPDATE_META = 4;</code>
     */
    RESTORE_SNAPSHOT_UPDATE_META(4),
    /**
     * <code>RESTORE_SNAPSHOT_RESTORE_ACL = 5;</code>
     */
    RESTORE_SNAPSHOT_RESTORE_ACL(5),
    ;

    /**
     * <code>RESTORE_SNAPSHOT_PRE_OPERATION = 1;</code>
     */
    public static final int RESTORE_SNAPSHOT_PRE_OPERATION_VALUE = 1;
    /**
     * <code>RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR = 2;</code>
     */
    public static final int RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR_VALUE = 2;
    /**
     * <code>RESTORE_SNAPSHOT_WRITE_FS_LAYOUT = 3;</code>
     */
    public static final int RESTORE_SNAPSHOT_WRITE_FS_LAYOUT_VALUE = 3;
    /**
     * <code>RESTORE_SNAPSHOT_UPDATE_META = 4;</code>
     */
    public static final int RESTORE_SNAPSHOT_UPDATE_META_VALUE = 4;
    /**
     * <code>RESTORE_SNAPSHOT_RESTORE_ACL = 5;</code>
     */
    public static final int RESTORE_SNAPSHOT_RESTORE_ACL_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RestoreSnapshotState valueOf(int value) {
      return forNumber(value);
    }

    public static RestoreSnapshotState forNumber(int value) {
      switch (value) {
        case 1: return RESTORE_SNAPSHOT_PRE_OPERATION;
        case 2: return RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR;
        case 3: return RESTORE_SNAPSHOT_WRITE_FS_LAYOUT;
        case 4: return RESTORE_SNAPSHOT_UPDATE_META;
        case 5: return RESTORE_SNAPSHOT_RESTORE_ACL;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RestoreSnapshotState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RestoreSnapshotState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RestoreSnapshotState>() {
            public RestoreSnapshotState findValueByNumber(int number) {
              return RestoreSnapshotState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(10);
    }

    private static final RestoreSnapshotState[] VALUES = values();

    public static RestoreSnapshotState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RestoreSnapshotState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RestoreSnapshotState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DispatchMergingRegionsState}
   */
  public enum DispatchMergingRegionsState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DISPATCH_MERGING_REGIONS_PREPARE = 1;</code>
     */
    DISPATCH_MERGING_REGIONS_PREPARE(1),
    /**
     * <code>DISPATCH_MERGING_REGIONS_PRE_OPERATION = 2;</code>
     */
    DISPATCH_MERGING_REGIONS_PRE_OPERATION(2),
    /**
     * <code>DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS = 3;</code>
     */
    DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS(3),
    /**
     * <code>DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS = 4;</code>
     */
    DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS(4),
    /**
     * <code>DISPATCH_MERGING_REGIONS_POST_OPERATION = 5;</code>
     */
    DISPATCH_MERGING_REGIONS_POST_OPERATION(5),
    ;

    /**
     * <code>DISPATCH_MERGING_REGIONS_PREPARE = 1;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_PREPARE_VALUE = 1;
    /**
     * <code>DISPATCH_MERGING_REGIONS_PRE_OPERATION = 2;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_PRE_OPERATION_VALUE = 2;
    /**
     * <code>DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS = 3;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS_VALUE = 3;
    /**
     * <code>DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS = 4;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS_VALUE = 4;
    /**
     * <code>DISPATCH_MERGING_REGIONS_POST_OPERATION = 5;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_POST_OPERATION_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DispatchMergingRegionsState valueOf(int value) {
      return forNumber(value);
    }

    public static DispatchMergingRegionsState forNumber(int value) {
      switch (value) {
        case 1: return DISPATCH_MERGING_REGIONS_PREPARE;
        case 2: return DISPATCH_MERGING_REGIONS_PRE_OPERATION;
        case 3: return DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS;
        case 4: return DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS;
        case 5: return DISPATCH_MERGING_REGIONS_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DispatchMergingRegionsState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        DispatchMergingRegionsState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DispatchMergingRegionsState>() {
            public DispatchMergingRegionsState findValueByNumber(int number) {
              return DispatchMergingRegionsState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(11);
    }

    private static final DispatchMergingRegionsState[] VALUES = values();

    public static DispatchMergingRegionsState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DispatchMergingRegionsState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DispatchMergingRegionsState)
  }

  /**
   * Protobuf enum {@code hbase.pb.SplitTableRegionState}
   */
  public enum SplitTableRegionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SPLIT_TABLE_REGION_PREPARE = 1;</code>
     */
    SPLIT_TABLE_REGION_PREPARE(1),
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION = 2;</code>
     */
    SPLIT_TABLE_REGION_PRE_OPERATION(2),
    /**
     * <code>SPLIT_TABLE_REGION_CLOSE_PARENT_REGION = 3;</code>
     */
    SPLIT_TABLE_REGION_CLOSE_PARENT_REGION(3),
    /**
     * <code>SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS = 4;</code>
     */
    SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS(4),
    /**
     * <code>SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE = 5;</code>
     */
    SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE(5),
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META = 6;</code>
     */
    SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META(6),
    /**
     * <code>SPLIT_TABLE_REGION_UPDATE_META = 7;</code>
     */
    SPLIT_TABLE_REGION_UPDATE_META(7),
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META = 8;</code>
     */
    SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META(8),
    /**
     * <code>SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS = 9;</code>
     */
    SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS(9),
    /**
     * <code>SPLIT_TABLE_REGION_POST_OPERATION = 10;</code>
     */
    SPLIT_TABLE_REGION_POST_OPERATION(10),
    /**
     * <code>SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS = 11;</code>
     */
    SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS(11),
    ;

    /**
     * <code>SPLIT_TABLE_REGION_PREPARE = 1;</code>
     */
    public static final int SPLIT_TABLE_REGION_PREPARE_VALUE = 1;
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION = 2;</code>
     */
    public static final int SPLIT_TABLE_REGION_PRE_OPERATION_VALUE = 2;
    /**
     * <code>SPLIT_TABLE_REGION_CLOSE_PARENT_REGION = 3;</code>
     */
    public static final int SPLIT_TABLE_REGION_CLOSE_PARENT_REGION_VALUE = 3;
    /**
     * <code>SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS = 4;</code>
     */
    public static final int SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS_VALUE = 4;
    /**
     * <code>SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE = 5;</code>
     */
    public static final int SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE_VALUE = 5;
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META = 6;</code>
     */
    public static final int SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META_VALUE = 6;
    /**
     * <code>SPLIT_TABLE_REGION_UPDATE_META = 7;</code>
     */
    public static final int SPLIT_TABLE_REGION_UPDATE_META_VALUE = 7;
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META = 8;</code>
     */
    public static final int SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META_VALUE = 8;
    /**
     * <code>SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS = 9;</code>
     */
    public static final int SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS_VALUE = 9;
    /**
     * <code>SPLIT_TABLE_REGION_POST_OPERATION = 10;</code>
     */
    public static final int SPLIT_TABLE_REGION_POST_OPERATION_VALUE = 10;
    /**
     * <code>SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS = 11;</code>
     */
    public static final int SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS_VALUE = 11;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SplitTableRegionState valueOf(int value) {
      return forNumber(value);
    }

    public static SplitTableRegionState forNumber(int value) {
      switch (value) {
        case 1: return SPLIT_TABLE_REGION_PREPARE;
        case 2: return SPLIT_TABLE_REGION_PRE_OPERATION;
        case 3: return SPLIT_TABLE_REGION_CLOSE_PARENT_REGION;
        case 4: return SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS;
        case 5: return SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE;
        case 6: return SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META;
        case 7: return SPLIT_TABLE_REGION_UPDATE_META;
        case 8: return SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META;
        case 9: return SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS;
        case 10: return SPLIT_TABLE_REGION_POST_OPERATION;
        case 11: return SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SplitTableRegionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        SplitTableRegionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SplitTableRegionState>() {
            public SplitTableRegionState findValueByNumber(int number) {
              return SplitTableRegionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(12);
    }

    private static final SplitTableRegionState[] VALUES = values();

    public static SplitTableRegionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private SplitTableRegionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.SplitTableRegionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.MergeTableRegionsState}
   */
  public enum MergeTableRegionsState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MERGE_TABLE_REGIONS_PREPARE = 1;</code>
     */
    MERGE_TABLE_REGIONS_PREPARE(1),
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_OPERATION = 2;</code>
     */
    MERGE_TABLE_REGIONS_PRE_OPERATION(2),
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION = 3;</code>
     */
    MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION(3),
    /**
     * <code>MERGE_TABLE_REGIONS_CLOSE_REGIONS = 4;</code>
     */
    MERGE_TABLE_REGIONS_CLOSE_REGIONS(4),
    /**
     * <code>MERGE_TABLE_REGIONS_CREATE_MERGED_REGION = 5;</code>
     */
    MERGE_TABLE_REGIONS_CREATE_MERGED_REGION(5),
    /**
     * <code>MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE = 6;</code>
     */
    MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE(6),
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION = 7;</code>
     */
    MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION(7),
    /**
     * <code>MERGE_TABLE_REGIONS_UPDATE_META = 8;</code>
     */
    MERGE_TABLE_REGIONS_UPDATE_META(8),
    /**
     * <code>MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION = 9;</code>
     */
    MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION(9),
    /**
     * <code>MERGE_TABLE_REGIONS_OPEN_MERGED_REGION = 10;</code>
     */
    MERGE_TABLE_REGIONS_OPEN_MERGED_REGION(10),
    /**
     * <code>MERGE_TABLE_REGIONS_POST_OPERATION = 11;</code>
     */
    MERGE_TABLE_REGIONS_POST_OPERATION(11),
    /**
     * <code>MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS = 12;</code>
     */
    MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS(12),
    ;

    /**
     * <code>MERGE_TABLE_REGIONS_PREPARE = 1;</code>
     */
    public static final int MERGE_TABLE_REGIONS_PREPARE_VALUE = 1;
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_OPERATION = 2;</code>
     */
    public static final int MERGE_TABLE_REGIONS_PRE_OPERATION_VALUE = 2;
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION = 3;</code>
     */
    public static final int MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION_VALUE = 3;
    /**
     * <code>MERGE_TABLE_REGIONS_CLOSE_REGIONS = 4;</code>
     */
    public static final int MERGE_TABLE_REGIONS_CLOSE_REGIONS_VALUE = 4;
    /**
     * <code>MERGE_TABLE_REGIONS_CREATE_MERGED_REGION = 5;</code>
     */
    public static final int MERGE_TABLE_REGIONS_CREATE_MERGED_REGION_VALUE = 5;
    /**
     * <code>MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE = 6;</code>
     */
    public static final int MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE_VALUE = 6;
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION = 7;</code>
     */
    public static final int MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION_VALUE = 7;
    /**
     * <code>MERGE_TABLE_REGIONS_UPDATE_META = 8;</code>
     */
    public static final int MERGE_TABLE_REGIONS_UPDATE_META_VALUE = 8;
    /**
     * <code>MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION = 9;</code>
     */
    public static final int MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION_VALUE = 9;
    /**
     * <code>MERGE_TABLE_REGIONS_OPEN_MERGED_REGION = 10;</code>
     */
    public static final int MERGE_TABLE_REGIONS_OPEN_MERGED_REGION_VALUE = 10;
    /**
     * <code>MERGE_TABLE_REGIONS_POST_OPERATION = 11;</code>
     */
    public static final int MERGE_TABLE_REGIONS_POST_OPERATION_VALUE = 11;
    /**
     * <code>MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS = 12;</code>
     */
    public static final int MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS_VALUE = 12;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static MergeTableRegionsState valueOf(int value) {
      return forNumber(value);
    }

    public static MergeTableRegionsState forNumber(int value) {
      switch (value) {
        case 1: return MERGE_TABLE_REGIONS_PREPARE;
        case 2: return MERGE_TABLE_REGIONS_PRE_OPERATION;
        case 3: return MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION;
        case 4: return MERGE_TABLE_REGIONS_CLOSE_REGIONS;
        case 5: return MERGE_TABLE_REGIONS_CREATE_MERGED_REGION;
        case 6: return MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE;
        case 7: return MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION;
        case 8: return MERGE_TABLE_REGIONS_UPDATE_META;
        case 9: return MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION;
        case 10: return MERGE_TABLE_REGIONS_OPEN_MERGED_REGION;
        case 11: return MERGE_TABLE_REGIONS_POST_OPERATION;
        case 12: return MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MergeTableRegionsState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        MergeTableRegionsState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MergeTableRegionsState>() {
            public MergeTableRegionsState findValueByNumber(int number) {
              return MergeTableRegionsState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(13);
    }

    private static final MergeTableRegionsState[] VALUES = values();

    public static MergeTableRegionsState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private MergeTableRegionsState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.MergeTableRegionsState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ServerCrashState}
   */
  public enum ServerCrashState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SERVER_CRASH_START = 1;</code>
     */
    SERVER_CRASH_START(1),
    /**
     * <code>SERVER_CRASH_PROCESS_META = 2 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    SERVER_CRASH_PROCESS_META(2),
    /**
     * <code>SERVER_CRASH_GET_REGIONS = 3;</code>
     */
    SERVER_CRASH_GET_REGIONS(3),
    /**
     * <code>SERVER_CRASH_NO_SPLIT_LOGS = 4 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    SERVER_CRASH_NO_SPLIT_LOGS(4),
    /**
     * <code>SERVER_CRASH_SPLIT_LOGS = 5;</code>
     */
    SERVER_CRASH_SPLIT_LOGS(5),
    /**
     * <pre>
     * Removed SERVER_CRASH_PREPARE_LOG_REPLAY = 6;
     * Removed SERVER_CRASH_CALC_REGIONS_TO_ASSIGN = 7;
     * </pre>
     *
     * <code>SERVER_CRASH_ASSIGN = 8;</code>
     */
    SERVER_CRASH_ASSIGN(8),
    /**
     * <code>SERVER_CRASH_WAIT_ON_ASSIGN = 9;</code>
     */
    SERVER_CRASH_WAIT_ON_ASSIGN(9),
    /**
     * <code>SERVER_CRASH_SPLIT_META_LOGS = 10;</code>
     */
    SERVER_CRASH_SPLIT_META_LOGS(10),
    /**
     * <code>SERVER_CRASH_ASSIGN_META = 11;</code>
     */
    SERVER_CRASH_ASSIGN_META(11),
    /**
     * <code>SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR = 12;</code>
     */
    SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR(12),
    /**
     * <code>SERVER_CRASH_DELETE_SPLIT_WALS_DIR = 13;</code>
     */
    SERVER_CRASH_DELETE_SPLIT_WALS_DIR(13),
    /**
     * <code>SERVER_CRASH_HANDLE_RIT2 = 20 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    SERVER_CRASH_HANDLE_RIT2(20),
    /**
     * <code>SERVER_CRASH_FINISH = 100;</code>
     */
    SERVER_CRASH_FINISH(100),
    ;

    /**
     * <code>SERVER_CRASH_START = 1;</code>
     */
    public static final int SERVER_CRASH_START_VALUE = 1;
    /**
     * <code>SERVER_CRASH_PROCESS_META = 2 [deprecated = true];</code>
     */
    public static final int SERVER_CRASH_PROCESS_META_VALUE = 2;
    /**
     * <code>SERVER_CRASH_GET_REGIONS = 3;</code>
     */
    public static final int SERVER_CRASH_GET_REGIONS_VALUE = 3;
    /**
     * <code>SERVER_CRASH_NO_SPLIT_LOGS = 4 [deprecated = true];</code>
     */
    public static final int SERVER_CRASH_NO_SPLIT_LOGS_VALUE = 4;
    /**
     * <code>SERVER_CRASH_SPLIT_LOGS = 5;</code>
     */
    public static final int SERVER_CRASH_SPLIT_LOGS_VALUE = 5;
    /**
     * <pre>
     * Removed SERVER_CRASH_PREPARE_LOG_REPLAY = 6;
     * Removed SERVER_CRASH_CALC_REGIONS_TO_ASSIGN = 7;
     * </pre>
     *
     * <code>SERVER_CRASH_ASSIGN = 8;</code>
     */
    public static final int SERVER_CRASH_ASSIGN_VALUE = 8;
    /**
     * <code>SERVER_CRASH_WAIT_ON_ASSIGN = 9;</code>
     */
    public static final int SERVER_CRASH_WAIT_ON_ASSIGN_VALUE = 9;
    /**
     * <code>SERVER_CRASH_SPLIT_META_LOGS = 10;</code>
     */
    public static final int SERVER_CRASH_SPLIT_META_LOGS_VALUE = 10;
    /**
     * <code>SERVER_CRASH_ASSIGN_META = 11;</code>
     */
    public static final int SERVER_CRASH_ASSIGN_META_VALUE = 11;
    /**
     * <code>SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR = 12;</code>
     */
    public static final int SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR_VALUE = 12;
    /**
     * <code>SERVER_CRASH_DELETE_SPLIT_WALS_DIR = 13;</code>
     */
    public static final int SERVER_CRASH_DELETE_SPLIT_WALS_DIR_VALUE = 13;
    /**
     * <code>SERVER_CRASH_HANDLE_RIT2 = 20 [deprecated = true];</code>
     */
    public static final int SERVER_CRASH_HANDLE_RIT2_VALUE = 20;
    /**
     * <code>SERVER_CRASH_FINISH = 100;</code>
     */
    public static final int SERVER_CRASH_FINISH_VALUE = 100;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ServerCrashState valueOf(int value) {
      return forNumber(value);
    }

    public static ServerCrashState forNumber(int value) {
      switch (value) {
        case 1: return SERVER_CRASH_START;
        case 2: return SERVER_CRASH_PROCESS_META;
        case 3: return SERVER_CRASH_GET_REGIONS;
        case 4: return SERVER_CRASH_NO_SPLIT_LOGS;
        case 5: return SERVER_CRASH_SPLIT_LOGS;
        case 8: return SERVER_CRASH_ASSIGN;
        case 9: return SERVER_CRASH_WAIT_ON_ASSIGN;
        case 10: return SERVER_CRASH_SPLIT_META_LOGS;
        case 11: return SERVER_CRASH_ASSIGN_META;
        case 12: return SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR;
        case 13: return SERVER_CRASH_DELETE_SPLIT_WALS_DIR;
        case 20: return SERVER_CRASH_HANDLE_RIT2;
        case 100: return SERVER_CRASH_FINISH;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ServerCrashState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>() {
            public ServerCrashState findValueByNumber(int number) {
              return ServerCrashState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(14);
    }

    private static final ServerCrashState[] VALUES = values();

    public static ServerCrashState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ServerCrashState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ServerCrashState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RecoverMetaState}
   */
  public enum RecoverMetaState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>RECOVER_META_PREPARE = 0;</code>
     */
    RECOVER_META_PREPARE(0),
    /**
     * <code>RECOVER_META_SPLIT_LOGS = 1;</code>
     */
    RECOVER_META_SPLIT_LOGS(1),
    /**
     * <code>RECOVER_META_ASSIGN_REGIONS = 2;</code>
     */
    RECOVER_META_ASSIGN_REGIONS(2),
    ;

    /**
     * <code>RECOVER_META_PREPARE = 0;</code>
     */
    public static final int RECOVER_META_PREPARE_VALUE = 0;
    /**
     * <code>RECOVER_META_SPLIT_LOGS = 1;</code>
     */
    public static final int RECOVER_META_SPLIT_LOGS_VALUE = 1;
    /**
     * <code>RECOVER_META_ASSIGN_REGIONS = 2;</code>
     */
    public static final int RECOVER_META_ASSIGN_REGIONS_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RecoverMetaState valueOf(int value) {
      return forNumber(value);
    }

    public static RecoverMetaState forNumber(int value) {
      switch (value) {
        case 0: return RECOVER_META_PREPARE;
        case 1: return RECOVER_META_SPLIT_LOGS;
        case 2: return RECOVER_META_ASSIGN_REGIONS;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RecoverMetaState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RecoverMetaState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RecoverMetaState>() {
            public RecoverMetaState findValueByNumber(int number) {
              return RecoverMetaState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(15);
    }

    private static final RecoverMetaState[] VALUES = values();

    public static RecoverMetaState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RecoverMetaState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RecoverMetaState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RegionTransitionState}
   */
  public enum RegionTransitionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REGION_TRANSITION_QUEUE = 1;</code>
     */
    REGION_TRANSITION_QUEUE(1),
    /**
     * <code>REGION_TRANSITION_DISPATCH = 2;</code>
     */
    REGION_TRANSITION_DISPATCH(2),
    /**
     * <code>REGION_TRANSITION_FINISH = 3;</code>
     */
    REGION_TRANSITION_FINISH(3),
    ;

    /**
     * <code>REGION_TRANSITION_QUEUE = 1;</code>
     */
    public static final int REGION_TRANSITION_QUEUE_VALUE = 1;
    /**
     * <code>REGION_TRANSITION_DISPATCH = 2;</code>
     */
    public static final int REGION_TRANSITION_DISPATCH_VALUE = 2;
    /**
     * <code>REGION_TRANSITION_FINISH = 3;</code>
     */
    public static final int REGION_TRANSITION_FINISH_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RegionTransitionState valueOf(int value) {
      return forNumber(value);
    }

    public static RegionTransitionState forNumber(int value) {
      switch (value) {
        case 1: return REGION_TRANSITION_QUEUE;
        case 2: return REGION_TRANSITION_DISPATCH;
        case 3: return REGION_TRANSITION_FINISH;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionTransitionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RegionTransitionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionTransitionState>() {
            public RegionTransitionState findValueByNumber(int number) {
              return RegionTransitionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(16);
    }

    private static final RegionTransitionState[] VALUES = values();

    public static RegionTransitionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RegionTransitionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RegionTransitionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.MoveRegionState}
   */
  public enum MoveRegionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MOVE_REGION_PREPARE = 0;</code>
     */
    MOVE_REGION_PREPARE(0),
    /**
     * <code>MOVE_REGION_UNASSIGN = 1;</code>
     */
    MOVE_REGION_UNASSIGN(1),
    /**
     * <code>MOVE_REGION_ASSIGN = 2;</code>
     */
    MOVE_REGION_ASSIGN(2),
    ;

    /**
     * <code>MOVE_REGION_PREPARE = 0;</code>
     */
    public static final int MOVE_REGION_PREPARE_VALUE = 0;
    /**
     * <code>MOVE_REGION_UNASSIGN = 1;</code>
     */
    public static final int MOVE_REGION_UNASSIGN_VALUE = 1;
    /**
     * <code>MOVE_REGION_ASSIGN = 2;</code>
     */
    public static final int MOVE_REGION_ASSIGN_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static MoveRegionState valueOf(int value) {
      return forNumber(value);
    }

    public static MoveRegionState forNumber(int value) {
      switch (value) {
        case 0: return MOVE_REGION_PREPARE;
        case 1: return MOVE_REGION_UNASSIGN;
        case 2: return MOVE_REGION_ASSIGN;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MoveRegionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        MoveRegionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MoveRegionState>() {
            public MoveRegionState findValueByNumber(int number) {
              return MoveRegionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(17);
    }

    private static final MoveRegionState[] VALUES = values();

    public static MoveRegionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private MoveRegionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.MoveRegionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.GCRegionState}
   */
  public enum GCRegionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>GC_REGION_PREPARE = 1;</code>
     */
    GC_REGION_PREPARE(1),
    /**
     * <code>GC_REGION_ARCHIVE = 2;</code>
     */
    GC_REGION_ARCHIVE(2),
    /**
     * <code>GC_REGION_PURGE_METADATA = 3;</code>
     */
    GC_REGION_PURGE_METADATA(3),
    ;

    /**
     * <code>GC_REGION_PREPARE = 1;</code>
     */
    public static final int GC_REGION_PREPARE_VALUE = 1;
    /**
     * <code>GC_REGION_ARCHIVE = 2;</code>
     */
    public static final int GC_REGION_ARCHIVE_VALUE = 2;
    /**
     * <code>GC_REGION_PURGE_METADATA = 3;</code>
     */
    public static final int GC_REGION_PURGE_METADATA_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static GCRegionState valueOf(int value) {
      return forNumber(value);
    }

    public static GCRegionState forNumber(int value) {
      switch (value) {
        case 1: return GC_REGION_PREPARE;
        case 2: return GC_REGION_ARCHIVE;
        case 3: return GC_REGION_PURGE_METADATA;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<GCRegionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        GCRegionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<GCRegionState>() {
            public GCRegionState findValueByNumber(int number) {
              return GCRegionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(18);
    }

    private static final GCRegionState[] VALUES = values();

    public static GCRegionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private GCRegionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.GCRegionState)
  }

  /**
   * <pre>
   * NOTE: This message is used by GCMergedRegionStateProcedure
   * AND GCMultipleMergedRegionStateProcedure.
   * </pre>
   *
   * Protobuf enum {@code hbase.pb.GCMergedRegionsState}
   */
  public enum GCMergedRegionsState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>GC_MERGED_REGIONS_PREPARE = 1;</code>
     */
    GC_MERGED_REGIONS_PREPARE(1),
    /**
     * <code>GC_MERGED_REGIONS_PURGE = 2;</code>
     */
    GC_MERGED_REGIONS_PURGE(2),
    /**
     * <code>GC_REGION_EDIT_METADATA = 3;</code>
     */
    GC_REGION_EDIT_METADATA(3),
    ;

    /**
     * <code>GC_MERGED_REGIONS_PREPARE = 1;</code>
     */
    public static final int GC_MERGED_REGIONS_PREPARE_VALUE = 1;
    /**
     * <code>GC_MERGED_REGIONS_PURGE = 2;</code>
     */
    public static final int GC_MERGED_REGIONS_PURGE_VALUE = 2;
    /**
     * <code>GC_REGION_EDIT_METADATA = 3;</code>
     */
    public static final int GC_REGION_EDIT_METADATA_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static GCMergedRegionsState valueOf(int value) {
      return forNumber(value);
    }

    public static GCMergedRegionsState forNumber(int value) {
      switch (value) {
        case 1: return GC_MERGED_REGIONS_PREPARE;
        case 2: return GC_MERGED_REGIONS_PURGE;
        case 3: return GC_REGION_EDIT_METADATA;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<GCMergedRegionsState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        GCMergedRegionsState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<GCMergedRegionsState>() {
            public GCMergedRegionsState findValueByNumber(int number) {
              return GCMergedRegionsState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(19);
    }

    private static final GCMergedRegionsState[] VALUES = values();

    public static GCMergedRegionsState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private GCMergedRegionsState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.GCMergedRegionsState)
  }

  /**
   * Protobuf enum {@code hbase.pb.PeerModificationState}
   */
  public enum PeerModificationState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>PRE_PEER_MODIFICATION = 1;</code>
     */
    PRE_PEER_MODIFICATION(1),
    /**
     * <code>UPDATE_PEER_STORAGE = 2;</code>
     */
    UPDATE_PEER_STORAGE(2),
    /**
     * <code>REFRESH_PEER_ON_RS = 3;</code>
     */
    REFRESH_PEER_ON_RS(3),
    /**
     * <code>SERIAL_PEER_REOPEN_REGIONS = 4;</code>
     */
    SERIAL_PEER_REOPEN_REGIONS(4),
    /**
     * <code>SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID = 5;</code>
     */
    SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID(5),
    /**
     * <code>SERIAL_PEER_SET_PEER_ENABLED = 6;</code>
     */
    SERIAL_PEER_SET_PEER_ENABLED(6),
    /**
     * <code>SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS = 7;</code>
     */
    SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS(7),
    /**
     * <code>POST_PEER_MODIFICATION = 8;</code>
     */
    POST_PEER_MODIFICATION(8),
    ;

    /**
     * <code>PRE_PEER_MODIFICATION = 1;</code>
     */
    public static final int PRE_PEER_MODIFICATION_VALUE = 1;
    /**
     * <code>UPDATE_PEER_STORAGE = 2;</code>
     */
    public static final int UPDATE_PEER_STORAGE_VALUE = 2;
    /**
     * <code>REFRESH_PEER_ON_RS = 3;</code>
     */
    public static final int REFRESH_PEER_ON_RS_VALUE = 3;
    /**
     * <code>SERIAL_PEER_REOPEN_REGIONS = 4;</code>
     */
    public static final int SERIAL_PEER_REOPEN_REGIONS_VALUE = 4;
    /**
     * <code>SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID = 5;</code>
     */
    public static final int SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID_VALUE = 5;
    /**
     * <code>SERIAL_PEER_SET_PEER_ENABLED = 6;</code>
     */
    public static final int SERIAL_PEER_SET_PEER_ENABLED_VALUE = 6;
    /**
     * <code>SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS = 7;</code>
     */
    public static final int SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS_VALUE = 7;
    /**
     * <code>POST_PEER_MODIFICATION = 8;</code>
     */
    public static final int POST_PEER_MODIFICATION_VALUE = 8;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static PeerModificationState valueOf(int value) {
      return forNumber(value);
    }

    public static PeerModificationState forNumber(int value) {
      switch (value) {
        case 1: return PRE_PEER_MODIFICATION;
        case 2: return UPDATE_PEER_STORAGE;
        case 3: return REFRESH_PEER_ON_RS;
        case 4: return SERIAL_PEER_REOPEN_REGIONS;
        case 5: return SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID;
        case 6: return SERIAL_PEER_SET_PEER_ENABLED;
        case 7: return SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS;
        case 8: return POST_PEER_MODIFICATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerModificationState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        PeerModificationState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerModificationState>() {
            public PeerModificationState findValueByNumber(int number) {
              return PeerModificationState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(20);
    }

    private static final PeerModificationState[] VALUES = values();

    public static PeerModificationState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private PeerModificationState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.PeerModificationState)
  }

  /**
   * Protobuf enum {@code hbase.pb.PeerSyncReplicationStateTransitionState}
   */
  public enum PeerSyncReplicationStateTransitionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>PRE_PEER_SYNC_REPLICATION_STATE_TRANSITION = 1;</code>
     */
    PRE_PEER_SYNC_REPLICATION_STATE_TRANSITION(1),
    /**
     * <code>SET_PEER_NEW_SYNC_REPLICATION_STATE = 2;</code>
     */
    SET_PEER_NEW_SYNC_REPLICATION_STATE(2),
    /**
     * <code>REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_BEGIN = 3;</code>
     */
    REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_BEGIN(3),
    /**
     * <code>REOPEN_ALL_REGIONS_IN_PEER = 4;</code>
     */
    REOPEN_ALL_REGIONS_IN_PEER(4),
    /**
     * <code>SYNC_REPLICATION_UPDATE_LAST_PUSHED_SEQ_ID_FOR_SERIAL_PEER = 5;</code>
     */
    SYNC_REPLICATION_UPDATE_LAST_PUSHED_SEQ_ID_FOR_SERIAL_PEER(5),
    /**
     * <code>REPLAY_REMOTE_WAL_IN_PEER = 6;</code>
     */
    REPLAY_REMOTE_WAL_IN_PEER(6),
    /**
     * <code>REMOVE_ALL_REPLICATION_QUEUES_IN_PEER = 7;</code>
     */
    REMOVE_ALL_REPLICATION_QUEUES_IN_PEER(7),
    /**
     * <code>TRANSIT_PEER_NEW_SYNC_REPLICATION_STATE = 8;</code>
     */
    TRANSIT_PEER_NEW_SYNC_REPLICATION_STATE(8),
    /**
     * <code>REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_END = 9;</code>
     */
    REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_END(9),
    /**
     * <code>SYNC_REPLICATION_SET_PEER_ENABLED = 10;</code>
     */
    SYNC_REPLICATION_SET_PEER_ENABLED(10),
    /**
     * <code>SYNC_REPLICATION_ENABLE_PEER_REFRESH_PEER_ON_RS = 11;</code>
     */
    SYNC_REPLICATION_ENABLE_PEER_REFRESH_PEER_ON_RS(11),
    /**
     * <code>CREATE_DIR_FOR_REMOTE_WAL = 12;</code>
     */
    CREATE_DIR_FOR_REMOTE_WAL(12),
    /**
     * <code>POST_PEER_SYNC_REPLICATION_STATE_TRANSITION = 13;</code>
     */
    POST_PEER_SYNC_REPLICATION_STATE_TRANSITION(13),
    ;

    /**
     * <code>PRE_PEER_SYNC_REPLICATION_STATE_TRANSITION = 1;</code>
     */
    public static final int PRE_PEER_SYNC_REPLICATION_STATE_TRANSITION_VALUE = 1;
    /**
     * <code>SET_PEER_NEW_SYNC_REPLICATION_STATE = 2;</code>
     */
    public static final int SET_PEER_NEW_SYNC_REPLICATION_STATE_VALUE = 2;
    /**
     * <code>REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_BEGIN = 3;</code>
     */
    public static final int REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_BEGIN_VALUE = 3;
    /**
     * <code>REOPEN_ALL_REGIONS_IN_PEER = 4;</code>
     */
    public static final int REOPEN_ALL_REGIONS_IN_PEER_VALUE = 4;
    /**
     * <code>SYNC_REPLICATION_UPDATE_LAST_PUSHED_SEQ_ID_FOR_SERIAL_PEER = 5;</code>
     */
    public static final int SYNC_REPLICATION_UPDATE_LAST_PUSHED_SEQ_ID_FOR_SERIAL_PEER_VALUE = 5;
    /**
     * <code>REPLAY_REMOTE_WAL_IN_PEER = 6;</code>
     */
    public static final int REPLAY_REMOTE_WAL_IN_PEER_VALUE = 6;
    /**
     * <code>REMOVE_ALL_REPLICATION_QUEUES_IN_PEER = 7;</code>
     */
    public static final int REMOVE_ALL_REPLICATION_QUEUES_IN_PEER_VALUE = 7;
    /**
     * <code>TRANSIT_PEER_NEW_SYNC_REPLICATION_STATE = 8;</code>
     */
    public static final int TRANSIT_PEER_NEW_SYNC_REPLICATION_STATE_VALUE = 8;
    /**
     * <code>REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_END = 9;</code>
     */
    public static final int REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_END_VALUE = 9;
    /**
     * <code>SYNC_REPLICATION_SET_PEER_ENABLED = 10;</code>
     */
    public static final int SYNC_REPLICATION_SET_PEER_ENABLED_VALUE = 10;
    /**
     * <code>SYNC_REPLICATION_ENABLE_PEER_REFRESH_PEER_ON_RS = 11;</code>
     */
    public static final int SYNC_REPLICATION_ENABLE_PEER_REFRESH_PEER_ON_RS_VALUE = 11;
    /**
     * <code>CREATE_DIR_FOR_REMOTE_WAL = 12;</code>
     */
    public static final int CREATE_DIR_FOR_REMOTE_WAL_VALUE = 12;
    /**
     * <code>POST_PEER_SYNC_REPLICATION_STATE_TRANSITION = 13;</code>
     */
    public static final int POST_PEER_SYNC_REPLICATION_STATE_TRANSITION_VALUE = 13;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static PeerSyncReplicationStateTransitionState valueOf(int value) {
      return forNumber(value);
    }

    public static PeerSyncReplicationStateTransitionState forNumber(int value) {
      switch (value) {
        case 1: return PRE_PEER_SYNC_REPLICATION_STATE_TRANSITION;
        case 2: return SET_PEER_NEW_SYNC_REPLICATION_STATE;
        case 3: return REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_BEGIN;
        case 4: return REOPEN_ALL_REGIONS_IN_PEER;
        case 5: return SYNC_REPLICATION_UPDATE_LAST_PUSHED_SEQ_ID_FOR_SERIAL_PEER;
        case 6: return REPLAY_REMOTE_WAL_IN_PEER;
        case 7: return REMOVE_ALL_REPLICATION_QUEUES_IN_PEER;
        case 8: return TRANSIT_PEER_NEW_SYNC_REPLICATION_STATE;
        case 9: return REFRESH_PEER_SYNC_REPLICATION_STATE_ON_RS_END;
        case 10: return SYNC_REPLICATION_SET_PEER_ENABLED;
        case 11: return SYNC_REPLICATION_ENABLE_PEER_REFRESH_PEER_ON_RS;
        case 12: return CREATE_DIR_FOR_REMOTE_WAL;
        case 13: return POST_PEER_SYNC_REPLICATION_STATE_TRANSITION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerSyncReplicationStateTransitionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        PeerSyncReplicationStateTransitionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerSyncReplicationStateTransitionState>() {
            public PeerSyncReplicationStateTransitionState findValueByNumber(int number) {
              return PeerSyncReplicationStateTransitionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(21);
    }

    private static final PeerSyncReplicationStateTransitionState[] VALUES = values();

    public static PeerSyncReplicationStateTransitionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private PeerSyncReplicationStateTransitionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.PeerSyncReplicationStateTransitionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.PeerModificationType}
   */
  public enum PeerModificationType
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ADD_PEER = 1;</code>
     */
    ADD_PEER(1),
    /**
     * <code>REMOVE_PEER = 2;</code>
     */
    REMOVE_PEER(2),
    /**
     * <code>ENABLE_PEER = 3;</code>
     */
    ENABLE_PEER(3),
    /**
     * <code>DISABLE_PEER = 4;</code>
     */
    DISABLE_PEER(4),
    /**
     * <code>UPDATE_PEER_CONFIG = 5;</code>
     */
    UPDATE_PEER_CONFIG(5),
    /**
     * <code>TRANSIT_SYNC_REPLICATION_STATE = 6;</code>
     */
    TRANSIT_SYNC_REPLICATION_STATE(6),
    ;

    /**
     * <code>ADD_PEER = 1;</code>
     */
    public static final int ADD_PEER_VALUE = 1;
    /**
     * <code>REMOVE_PEER = 2;</code>
     */
    public static final int REMOVE_PEER_VALUE = 2;
    /**
     * <code>ENABLE_PEER = 3;</code>
     */
    public static final int ENABLE_PEER_VALUE = 3;
    /**
     * <code>DISABLE_PEER = 4;</code>
     */
    public static final int DISABLE_PEER_VALUE = 4;
    /**
     * <code>UPDATE_PEER_CONFIG = 5;</code>
     */
    public static final int UPDATE_PEER_CONFIG_VALUE = 5;
    /**
     * <code>TRANSIT_SYNC_REPLICATION_STATE = 6;</code>
     */
    public static final int TRANSIT_SYNC_REPLICATION_STATE_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static PeerModificationType valueOf(int value) {
      return forNumber(value);
    }

    public static PeerModificationType forNumber(int value) {
      switch (value) {
        case 1: return ADD_PEER;
        case 2: return REMOVE_PEER;
        case 3: return ENABLE_PEER;
        case 4: return DISABLE_PEER;
        case 5: return UPDATE_PEER_CONFIG;
        case 6: return TRANSIT_SYNC_REPLICATION_STATE;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerModificationType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        PeerModificationType> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerModificationType>() {
            public PeerModificationType findValueByNumber(int number) {
              return PeerModificationType.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(22);
    }

    private static final PeerModificationType[] VALUES = values();

    public static PeerModificationType valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private PeerModificationType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.PeerModificationType)
  }

  /**
   * Protobuf enum {@code hbase.pb.ReopenTableRegionsState}
   */
  public enum ReopenTableRegionsState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REOPEN_TABLE_REGIONS_GET_REGIONS = 1;</code>
     */
    REOPEN_TABLE_REGIONS_GET_REGIONS(1),
    /**
     * <code>REOPEN_TABLE_REGIONS_REOPEN_REGIONS = 2;</code>
     */
    REOPEN_TABLE_REGIONS_REOPEN_REGIONS(2),
    /**
     * <code>REOPEN_TABLE_REGIONS_CONFIRM_REOPENED = 3;</code>
     */
    REOPEN_TABLE_REGIONS_CONFIRM_REOPENED(3),
    ;

    /**
     * <code>REOPEN_TABLE_REGIONS_GET_REGIONS = 1;</code>
     */
    public static final int REOPEN_TABLE_REGIONS_GET_REGIONS_VALUE = 1;
    /**
     * <code>REOPEN_TABLE_REGIONS_REOPEN_REGIONS = 2;</code>
     */
    public static final int REOPEN_TABLE_REGIONS_REOPEN_REGIONS_VALUE = 2;
    /**
     * <code>REOPEN_TABLE_REGIONS_CONFIRM_REOPENED = 3;</code>
     */
    public static final int REOPEN_TABLE_REGIONS_CONFIRM_REOPENED_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ReopenTableRegionsState valueOf(int value) {
      return forNumber(value);
    }

    public static ReopenTableRegionsState forNumber(int value) {
      switch (value) {
        case 1: return REOPEN_TABLE_REGIONS_GET_REGIONS;
        case 2: return REOPEN_TABLE_REGIONS_REOPEN_REGIONS;
        case 3: return REOPEN_TABLE_REGIONS_CONFIRM_REOPENED;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ReopenTableRegionsState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ReopenTableRegionsState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ReopenTableRegionsState>() {
            public ReopenTableRegionsState findValueByNumber(int number) {
              return ReopenTableRegionsState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(23);
    }

    private static final ReopenTableRegionsState[] VALUES = values();

    public static ReopenTableRegionsState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ReopenTableRegionsState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ReopenTableRegionsState)
  }

  /**
   * Protobuf enum {@code hbase.pb.InitMetaState}
   */
  public enum InitMetaState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>INIT_META_ASSIGN_META = 1;</code>
     */
    INIT_META_ASSIGN_META(1),
    /**
     * <code>INIT_META_CREATE_NAMESPACES = 2;</code>
     */
    INIT_META_CREATE_NAMESPACES(2),
    ;

    /**
     * <code>INIT_META_ASSIGN_META = 1;</code>
     */
    public static final int INIT_META_ASSIGN_META_VALUE = 1;
    /**
     * <code>INIT_META_CREATE_NAMESPACES = 2;</code>
     */
    public static final int INIT_META_CREATE_NAMESPACES_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static InitMetaState valueOf(int value) {
      return forNumber(value);
    }

    public static InitMetaState forNumber(int value) {
      switch (value) {
        case 1: return INIT_META_ASSIGN_META;
        case 2: return INIT_META_CREATE_NAMESPACES;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<InitMetaState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        InitMetaState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<InitMetaState>() {
            public InitMetaState findValueByNumber(int number) {
              return InitMetaState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(24);
    }

    private static final InitMetaState[] VALUES = values();

    public static InitMetaState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private InitMetaState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.InitMetaState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RecoverStandbyState}
   */
  public enum RecoverStandbyState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>RENAME_SYNC_REPLICATION_WALS_DIR = 1;</code>
     */
    RENAME_SYNC_REPLICATION_WALS_DIR(1),
    /**
     * <code>REGISTER_PEER_TO_WORKER_STORAGE = 2;</code>
     */
    REGISTER_PEER_TO_WORKER_STORAGE(2),
    /**
     * <code>DISPATCH_WALS = 3;</code>
     */
    DISPATCH_WALS(3),
    /**
     * <code>UNREGISTER_PEER_FROM_WORKER_STORAGE = 4;</code>
     */
    UNREGISTER_PEER_FROM_WORKER_STORAGE(4),
    /**
     * <code>SNAPSHOT_SYNC_REPLICATION_WALS_DIR = 5;</code>
     */
    SNAPSHOT_SYNC_REPLICATION_WALS_DIR(5),
    ;

    /**
     * <code>RENAME_SYNC_REPLICATION_WALS_DIR = 1;</code>
     */
    public static final int RENAME_SYNC_REPLICATION_WALS_DIR_VALUE = 1;
    /**
     * <code>REGISTER_PEER_TO_WORKER_STORAGE = 2;</code>
     */
    public static final int REGISTER_PEER_TO_WORKER_STORAGE_VALUE = 2;
    /**
     * <code>DISPATCH_WALS = 3;</code>
     */
    public static final int DISPATCH_WALS_VALUE = 3;
    /**
     * <code>UNREGISTER_PEER_FROM_WORKER_STORAGE = 4;</code>
     */
    public static final int UNREGISTER_PEER_FROM_WORKER_STORAGE_VALUE = 4;
    /**
     * <code>SNAPSHOT_SYNC_REPLICATION_WALS_DIR = 5;</code>
     */
    public static final int SNAPSHOT_SYNC_REPLICATION_WALS_DIR_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RecoverStandbyState valueOf(int value) {
      return forNumber(value);
    }

    public static RecoverStandbyState forNumber(int value) {
      switch (value) {
        case 1: return RENAME_SYNC_REPLICATION_WALS_DIR;
        case 2: return REGISTER_PEER_TO_WORKER_STORAGE;
        case 3: return DISPATCH_WALS;
        case 4: return UNREGISTER_PEER_FROM_WORKER_STORAGE;
        case 5: return SNAPSHOT_SYNC_REPLICATION_WALS_DIR;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RecoverStandbyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RecoverStandbyState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RecoverStandbyState>() {
            public RecoverStandbyState findValueByNumber(int number) {
              return RecoverStandbyState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(25);
    }

    private static final RecoverStandbyState[] VALUES = values();

    public static RecoverStandbyState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RecoverStandbyState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RecoverStandbyState)
  }

  /**
   * Protobuf enum {@code hbase.pb.SyncReplicationReplayWALState}
   */
  public enum SyncReplicationReplayWALState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ASSIGN_WORKER = 1;</code>
     */
    ASSIGN_WORKER(1),
    /**
     * <code>DISPATCH_WALS_TO_WORKER = 2;</code>
     */
    DISPATCH_WALS_TO_WORKER(2),
    /**
     * <code>RELEASE_WORKER = 3;</code>
     */
    RELEASE_WORKER(3),
    ;

    /**
     * <code>ASSIGN_WORKER = 1;</code>
     */
    public static final int ASSIGN_WORKER_VALUE = 1;
    /**
     * <code>DISPATCH_WALS_TO_WORKER = 2;</code>
     */
    public static final int DISPATCH_WALS_TO_WORKER_VALUE = 2;
    /**
     * <code>RELEASE_WORKER = 3;</code>
     */
    public static final int RELEASE_WORKER_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SyncReplicationReplayWALState valueOf(int value) {
      return forNumber(value);
    }

    public static SyncReplicationReplayWALState forNumber(int value) {
      switch (value) {
        case 1: return ASSIGN_WORKER;
        case 2: return DISPATCH_WALS_TO_WORKER;
        case 3: return RELEASE_WORKER;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SyncReplicationReplayWALState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        SyncReplicationReplayWALState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SyncReplicationReplayWALState>() {
            public SyncReplicationReplayWALState findValueByNumber(int number) {
              return SyncReplicationReplayWALState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(26);
    }

    private static final SyncReplicationReplayWALState[] VALUES = values();

    public static SyncReplicationReplayWALState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private SyncReplicationReplayWALState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.SyncReplicationReplayWALState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RegionStateTransitionState}
   */
  public enum RegionStateTransitionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE = 1;</code>
     */
    REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE(1),
    /**
     * <code>REGION_STATE_TRANSITION_OPEN = 2;</code>
     */
    REGION_STATE_TRANSITION_OPEN(2),
    /**
     * <code>REGION_STATE_TRANSITION_CONFIRM_OPENED = 3;</code>
     */
    REGION_STATE_TRANSITION_CONFIRM_OPENED(3),
    /**
     * <code>REGION_STATE_TRANSITION_CLOSE = 4;</code>
     */
    REGION_STATE_TRANSITION_CLOSE(4),
    /**
     * <code>REGION_STATE_TRANSITION_CONFIRM_CLOSED = 5;</code>
     */
    REGION_STATE_TRANSITION_CONFIRM_CLOSED(5),
    ;

    /**
     * <code>REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE = 1;</code>
     */
    public static final int REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE_VALUE = 1;
    /**
     * <code>REGION_STATE_TRANSITION_OPEN = 2;</code>
     */
    public static final int REGION_STATE_TRANSITION_OPEN_VALUE = 2;
    /**
     * <code>REGION_STATE_TRANSITION_CONFIRM_OPENED = 3;</code>
     */
    public static final int REGION_STATE_TRANSITION_CONFIRM_OPENED_VALUE = 3;
    /**
     * <code>REGION_STATE_TRANSITION_CLOSE = 4;</code>
     */
    public static final int REGION_STATE_TRANSITION_CLOSE_VALUE = 4;
    /**
     * <code>REGION_STATE_TRANSITION_CONFIRM_CLOSED = 5;</code>
     */
    public static final int REGION_STATE_TRANSITION_CONFIRM_CLOSED_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RegionStateTransitionState valueOf(int value) {
      return forNumber(value);
    }

    public static RegionStateTransitionState forNumber(int value) {
      switch (value) {
        case 1: return REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE;
        case 2: return REGION_STATE_TRANSITION_OPEN;
        case 3: return REGION_STATE_TRANSITION_CONFIRM_OPENED;
        case 4: return REGION_STATE_TRANSITION_CLOSE;
        case 5: return REGION_STATE_TRANSITION_CONFIRM_CLOSED;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionStateTransitionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RegionStateTransitionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionStateTransitionState>() {
            public RegionStateTransitionState findValueByNumber(int number) {
              return RegionStateTransitionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(27);
    }

    private static final RegionStateTransitionState[] VALUES = values();

    public static RegionStateTransitionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RegionStateTransitionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RegionStateTransitionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RegionTransitionType}
   */
  public enum RegionTransitionType
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ASSIGN = 1;</code>
     */
    ASSIGN(1),
    /**
     * <code>UNASSIGN = 2;</code>
     */
    UNASSIGN(2),
    /**
     * <code>MOVE = 3;</code>
     */
    MOVE(3),
    /**
     * <code>REOPEN = 4;</code>
     */
    REOPEN(4),
    ;

    /**
     * <code>ASSIGN = 1;</code>
     */
    public static final int ASSIGN_VALUE = 1;
    /**
     * <code>UNASSIGN = 2;</code>
     */
    public static final int UNASSIGN_VALUE = 2;
    /**
     * <code>MOVE = 3;</code>
     */
    public static final int MOVE_VALUE = 3;
    /**
     * <code>REOPEN = 4;</code>
     */
    public static final int REOPEN_VALUE = 4;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RegionTransitionType valueOf(int value) {
      return forNumber(value);
    }

    public static RegionTransitionType forNumber(int value) {
      switch (value) {
        case 1: return ASSIGN;
        case 2: return UNASSIGN;
        case 3: return MOVE;
        case 4: return REOPEN;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionTransitionType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RegionTransitionType> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionTransitionType>() {
            public RegionTransitionType findValueByNumber(int number) {
              return RegionTransitionType.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(28);
    }

    private static final RegionTransitionType[] VALUES = values();

    public static RegionTransitionType valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RegionTransitionType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RegionTransitionType)
  }

  /**
   * Protobuf enum {@code hbase.pb.RegionRemoteProcedureBaseState}
   */
  public enum RegionRemoteProcedureBaseState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REGION_REMOTE_PROCEDURE_DISPATCH = 1;</code>
     */
    REGION_REMOTE_PROCEDURE_DISPATCH(1),
    /**
     * <code>REGION_REMOTE_PROCEDURE_REPORT_SUCCEED = 2;</code>
     */
    REGION_REMOTE_PROCEDURE_REPORT_SUCCEED(2),
    /**
     * <code>REGION_REMOTE_PROCEDURE_DISPATCH_FAIL = 3;</code>
     */
    REGION_REMOTE_PROCEDURE_DISPATCH_FAIL(3),
    /**
     * <code>REGION_REMOTE_PROCEDURE_SERVER_CRASH = 4;</code>
     */
    REGION_REMOTE_PROCEDURE_SERVER_CRASH(4),
    ;

    /**
     * <code>REGION_REMOTE_PROCEDURE_DISPATCH = 1;</code>
     */
    public static final int REGION_REMOTE_PROCEDURE_DISPATCH_VALUE = 1;
    /**
     * <code>REGION_REMOTE_PROCEDURE_REPORT_SUCCEED = 2;</code>
     */
    public static final int REGION_REMOTE_PROCEDURE_REPORT_SUCCEED_VALUE = 2;
    /**
     * <code>REGION_REMOTE_PROCEDURE_DISPATCH_FAIL = 3;</code>
     */
    public static final int REGION_REMOTE_PROCEDURE_DISPATCH_FAIL_VALUE = 3;
    /**
     * <code>REGION_REMOTE_PROCEDURE_SERVER_CRASH = 4;</code>
     */
    public static final int REGION_REMOTE_PROCEDURE_SERVER_CRASH_VALUE = 4;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RegionRemoteProcedureBaseState valueOf(int value) {
      return forNumber(value);
    }

    public static RegionRemoteProcedureBaseState forNumber(int value) {
      switch (value) {
        case 1: return REGION_REMOTE_PROCEDURE_DISPATCH;
        case 2: return REGION_REMOTE_PROCEDURE_REPORT_SUCCEED;
        case 3: return REGION_REMOTE_PROCEDURE_DISPATCH_FAIL;
        case 4: return REGION_REMOTE_PROCEDURE_SERVER_CRASH;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionRemoteProcedureBaseState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RegionRemoteProcedureBaseState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionRemoteProcedureBaseState>() {
            public RegionRemoteProcedureBaseState findValueByNumber(int number) {
              return RegionRemoteProcedureBaseState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(29);
    }

    private static final RegionRemoteProcedureBaseState[] VALUES = values();

    public static RegionRemoteProcedureBaseState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RegionRemoteProcedureBaseState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RegionRemoteProcedureBaseState)
  }

  /**
   * Protobuf enum {@code hbase.pb.SwitchRpcThrottleState}
   */
  public enum SwitchRpcThrottleState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>UPDATE_SWITCH_RPC_THROTTLE_STORAGE = 1;</code>
     */
    UPDATE_SWITCH_RPC_THROTTLE_STORAGE(1),
    /**
     * <code>SWITCH_RPC_THROTTLE_ON_RS = 2;</code>
     */
    SWITCH_RPC_THROTTLE_ON_RS(2),
    /**
     * <code>POST_SWITCH_RPC_THROTTLE = 3;</code>
     */
    POST_SWITCH_RPC_THROTTLE(3),
    ;

    /**
     * <code>UPDATE_SWITCH_RPC_THROTTLE_STORAGE = 1;</code>
     */
    public static final int UPDATE_SWITCH_RPC_THROTTLE_STORAGE_VALUE = 1;
    /**
     * <code>SWITCH_RPC_THROTTLE_ON_RS = 2;</code>
     */
    public static final int SWITCH_RPC_THROTTLE_ON_RS_VALUE = 2;
    /**
     * <code>POST_SWITCH_RPC_THROTTLE = 3;</code>
     */
    public static final int POST_SWITCH_RPC_THROTTLE_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SwitchRpcThrottleState valueOf(int value) {
      return forNumber(value);
    }

    public static SwitchRpcThrottleState forNumber(int value) {
      switch (value) {
        case 1: return UPDATE_SWITCH_RPC_THROTTLE_STORAGE;
        case 2: return SWITCH_RPC_THROTTLE_ON_RS;
        case 3: return POST_SWITCH_RPC_THROTTLE;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SwitchRpcThrottleState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        SwitchRpcThrottleState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SwitchRpcThrottleState>() {
            public SwitchRpcThrottleState findValueByNumber(int number) {
              return SwitchRpcThrottleState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(30);
    }

    private static final SwitchRpcThrottleState[] VALUES = values();

    public static SwitchRpcThrottleState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private SwitchRpcThrottleState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.SwitchRpcThrottleState)
  }

  /**
   * Protobuf enum {@code hbase.pb.SplitWALState}
   */
  public enum SplitWALState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ACQUIRE_SPLIT_WAL_WORKER = 1;</code>
     */
    ACQUIRE_SPLIT_WAL_WORKER(1),
    /**
     * <code>DISPATCH_WAL_TO_WORKER = 2;</code>
     */
    DISPATCH_WAL_TO_WORKER(2),
    /**
     * <code>RELEASE_SPLIT_WORKER = 3;</code>
     */
    RELEASE_SPLIT_WORKER(3),
    ;

    /**
     * <code>ACQUIRE_SPLIT_WAL_WORKER = 1;</code>
     */
    public static final int ACQUIRE_SPLIT_WAL_WORKER_VALUE = 1;
    /**
     * <code>DISPATCH_WAL_TO_WORKER = 2;</code>
     */
    public static final int DISPATCH_WAL_TO_WORKER_VALUE = 2;
    /**
     * <code>RELEASE_SPLIT_WORKER = 3;</code>
     */
    public static final int RELEASE_SPLIT_WORKER_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SplitWALState valueOf(int value) {
      return forNumber(value);
    }

    public static SplitWALState forNumber(int value) {
      switch (value) {
        case 1: return ACQUIRE_SPLIT_WAL_WORKER;
        case 2: return DISPATCH_WAL_TO_WORKER;
        case 3: return RELEASE_SPLIT_WORKER;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SplitWALState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        SplitWALState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SplitWALState>() {
            public SplitWALState findValueByNumber(int number) {
              return SplitWALState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(31);
    }

    private static final SplitWALState[] VALUES = values();

    public static SplitWALState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private SplitWALState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.SplitWALState)
  }

  public interface CreateTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CreateTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    boolean hasTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.CreateTableStateData}
   */
  @javax.annotation.Generated("proto") public  static final class CreateTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CreateTableStateData)
      CreateTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CreateTableStateData.newBuilder() to construct.
    private CreateTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CreateTableStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CreateTableStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableSchema_.toBuilder();
              }
              tableSchema_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableSchema_);
                tableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableSchema() == other.hasTableSchema());
      if (hasTableSchema()) {
        result = result && getTableSchema()
            .equals(other.getTableSchema());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CreateTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CreateTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableSchemaBuilder_ == null) {
          result.tableSchema_ = tableSchema_;
        } else {
          result.tableSchema_ = tableSchemaBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableSchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableSchema().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableSchema_ != null &&
              tableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            tableSchema_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.newBuilder(tableSchema_).mergeFrom(value).buildPartial();
          } else {
            tableSchema_ = value;
          }
          onChanged();
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder clearTableSchema() {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
          onChanged();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getTableSchema(),
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CreateTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CreateTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CreateTableStateData>() {
      public CreateTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new CreateTableStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateTableStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    boolean hasModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder();

    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     */
    boolean hasDeleteColumnFamilyInModify();
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     */
    boolean getDeleteColumnFamilyInModify();

    /**
     * <code>optional bool should_check_descriptor = 5;</code>
     */
    boolean hasShouldCheckDescriptor();
    /**
     * <code>optional bool should_check_descriptor = 5;</code>
     */
    boolean getShouldCheckDescriptor();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyTableStateData}
   */
  @javax.annotation.Generated("proto") public  static final class ModifyTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyTableStateData)
      ModifyTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyTableStateData.newBuilder() to construct.
    private ModifyTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyTableStateData() {
      deleteColumnFamilyInModify_ = false;
      shouldCheckDescriptor_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModifyTableStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = modifiedTableSchema_.toBuilder();
              }
              modifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(modifiedTableSchema_);
                modifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              deleteColumnFamilyInModify_ = input.readBool();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              shouldCheckDescriptor_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }

    public static final int MODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public boolean hasModifiedTableSchema() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }

    public static final int DELETE_COLUMN_FAMILY_IN_MODIFY_FIELD_NUMBER = 4;
    private boolean deleteColumnFamilyInModify_;
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     */
    public boolean hasDeleteColumnFamilyInModify() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     */
    public boolean getDeleteColumnFamilyInModify() {
      return deleteColumnFamilyInModify_;
    }

    public static final int SHOULD_CHECK_DESCRIPTOR_FIELD_NUMBER = 5;
    private boolean shouldCheckDescriptor_;
    /**
     * <code>optional bool should_check_descriptor = 5;</code>
     */
    public boolean hasShouldCheckDescriptor() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool should_check_descriptor = 5;</code>
     */
    public boolean getShouldCheckDescriptor() {
      return shouldCheckDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasModifiedTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasDeleteColumnFamilyInModify()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getModifiedTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getUnmodifiedTableSchema());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getModifiedTableSchema());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBool(4, deleteColumnFamilyInModify_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(5, shouldCheckDescriptor_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getUnmodifiedTableSchema());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getModifiedTableSchema());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, deleteColumnFamilyInModify_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, shouldCheckDescriptor_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasUnmodifiedTableSchema() == other.hasUnmodifiedTableSchema());
      if (hasUnmodifiedTableSchema()) {
        result = result && getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema());
      }
      result = result && (hasModifiedTableSchema() == other.hasModifiedTableSchema());
      if (hasModifiedTableSchema()) {
        result = result && getModifiedTableSchema()
            .equals(other.getModifiedTableSchema());
      }
      result = result && (hasDeleteColumnFamilyInModify() == other.hasDeleteColumnFamilyInModify());
      if (hasDeleteColumnFamilyInModify()) {
        result = result && (getDeleteColumnFamilyInModify()
            == other.getDeleteColumnFamilyInModify());
      }
      result = result && (hasShouldCheckDescriptor() == other.hasShouldCheckDescriptor());
      if (hasShouldCheckDescriptor()) {
        result = result && (getShouldCheckDescriptor()
            == other.getShouldCheckDescriptor());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      if (hasModifiedTableSchema()) {
        hash = (37 * hash) + MODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getModifiedTableSchema().hashCode();
      }
      if (hasDeleteColumnFamilyInModify()) {
        hash = (37 * hash) + DELETE_COLUMN_FAMILY_IN_MODIFY_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getDeleteColumnFamilyInModify());
      }
      if (hasShouldCheckDescriptor()) {
        hash = (37 * hash) + SHOULD_CHECK_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getShouldCheckDescriptor());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
          getModifiedTableSchemaFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = null;
        } else {
          modifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        deleteColumnFamilyInModify_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        shouldCheckDescriptor_ = false;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (unmodifiedTableSchemaBuilder_ == null) {
          result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
        } else {
          result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (modifiedTableSchemaBuilder_ == null) {
          result.modifiedTableSchema_ = modifiedTableSchema_;
        } else {
          result.modifiedTableSchema_ = modifiedTableSchemaBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.deleteColumnFamilyInModify_ = deleteColumnFamilyInModify_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.shouldCheckDescriptor_ = shouldCheckDescriptor_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        if (other.hasModifiedTableSchema()) {
          mergeModifiedTableSchema(other.getModifiedTableSchema());
        }
        if (other.hasDeleteColumnFamilyInModify()) {
          setDeleteColumnFamilyInModify(other.getDeleteColumnFamilyInModify());
        }
        if (other.hasShouldCheckDescriptor()) {
          setShouldCheckDescriptor(other.getShouldCheckDescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasModifiedTableSchema()) {
          return false;
        }
        if (!hasDeleteColumnFamilyInModify()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            return false;
          }
        }
        if (!getModifiedTableSchema().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              unmodifiedTableSchema_ != null &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getUnmodifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> modifiedTableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public boolean hasModifiedTableSchema() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        } else {
          return modifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modifiedTableSchema_ = value;
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder mergeModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              modifiedTableSchema_ != null &&
              modifiedTableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            modifiedTableSchema_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.newBuilder(modifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            modifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder clearModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = null;
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getModifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getModifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
        if (modifiedTableSchemaBuilder_ != null) {
          return modifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return modifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getModifiedTableSchemaFieldBuilder() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getModifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          modifiedTableSchema_ = null;
        }
        return modifiedTableSchemaBuilder_;
      }

      private boolean deleteColumnFamilyInModify_ ;
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       */
      public boolean hasDeleteColumnFamilyInModify() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       */
      public boolean getDeleteColumnFamilyInModify() {
        return deleteColumnFamilyInModify_;
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       */
      public Builder setDeleteColumnFamilyInModify(boolean value) {
        bitField0_ |= 0x00000008;
        deleteColumnFamilyInModify_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       */
      public Builder clearDeleteColumnFamilyInModify() {
        bitField0_ = (bitField0_ & ~0x00000008);
        deleteColumnFamilyInModify_ = false;
        onChanged();
        return this;
      }

      private boolean shouldCheckDescriptor_ ;
      /**
       * <code>optional bool should_check_descriptor = 5;</code>
       */
      public boolean hasShouldCheckDescriptor() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool should_check_descriptor = 5;</code>
       */
      public boolean getShouldCheckDescriptor() {
        return shouldCheckDescriptor_;
      }
      /**
       * <code>optional bool should_check_descriptor = 5;</code>
       */
      public Builder setShouldCheckDescriptor(boolean value) {
        bitField0_ |= 0x00000010;
        shouldCheckDescriptor_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_check_descriptor = 5;</code>
       */
      public Builder clearShouldCheckDescriptor() {
        bitField0_ = (bitField0_ & ~0x00000010);
        shouldCheckDescriptor_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ModifyTableStateData>() {
      public ModifyTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new ModifyTableStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TruncateTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.TruncateTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required bool preserve_splits = 2;</code>
     */
    boolean hasPreserveSplits();
    /**
     * <code>required bool preserve_splits = 2;</code>
     */
    boolean getPreserveSplits();

    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    boolean hasTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    boolean hasTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.TruncateTableStateData}
   */
  @javax.annotation.Generated("proto") public  static final class TruncateTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.TruncateTableStateData)
      TruncateTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TruncateTableStateData.newBuilder() to construct.
    private TruncateTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TruncateTableStateData() {
      preserveSplits_ = false;
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private TruncateTableStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              preserveSplits_ = input.readBool();
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = tableSchema_.toBuilder();
              }
              tableSchema_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableSchema_);
                tableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000010;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int PRESERVE_SPLITS_FIELD_NUMBER = 2;
    private boolean preserveSplits_;
    /**
     * <code>required bool preserve_splits = 2;</code>
     */
    public boolean hasPreserveSplits() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bool preserve_splits = 2;</code>
     */
    public boolean getPreserveSplits() {
      return preserveSplits_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasPreserveSplits()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasTableName()) {
        if (!getTableName().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasTableSchema()) {
        if (!getTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, preserveSplits_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getTableName());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(5, regionInfo_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, preserveSplits_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTableName());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, regionInfo_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasPreserveSplits() == other.hasPreserveSplits());
      if (hasPreserveSplits()) {
        result = result && (getPreserveSplits()
            == other.getPreserveSplits());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasTableSchema() == other.hasTableSchema());
      if (hasTableSchema()) {
        result = result && getTableSchema()
            .equals(other.getTableSchema());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasPreserveSplits()) {
        hash = (37 * hash) + PRESERVE_SPLITS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getPreserveSplits());
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TruncateTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.TruncateTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        preserveSplits_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.preserveSplits_ = preserveSplits_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (tableSchemaBuilder_ == null) {
          result.tableSchema_ = tableSchema_;
        } else {
          result.tableSchema_ = tableSchemaBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasPreserveSplits()) {
          setPreserveSplits(other.getPreserveSplits());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000010);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasPreserveSplits()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (hasTableName()) {
          if (!getTableName().isInitialized()) {
            return false;
          }
        }
        if (hasTableSchema()) {
          if (!getTableSchema().isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private boolean preserveSplits_ ;
      /**
       * <code>required bool preserve_splits = 2;</code>
       */
      public boolean hasPreserveSplits() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       */
      public boolean getPreserveSplits() {
        return preserveSplits_;
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       */
      public Builder setPreserveSplits(boolean value) {
        bitField0_ |= 0x00000002;
        preserveSplits_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       */
      public Builder clearPreserveSplits() {
        bitField0_ = (bitField0_ & ~0x00000002);
        preserveSplits_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              tableSchema_ != null &&
              tableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            tableSchema_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.newBuilder(tableSchema_).mergeFrom(value).buildPartial();
          } else {
            tableSchema_ = value;
          }
          onChanged();
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder clearTableSchema() {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
          onChanged();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getTableSchema(),
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.TruncateTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TruncateTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<TruncateTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<TruncateTableStateData>() {
      public TruncateTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new TruncateTableStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<TruncateTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<TruncateTableStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DeleteTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DeleteTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteTableStateData}
   */
  @javax.annotation.Generated("proto") public  static final class DeleteTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DeleteTableStateData)
      DeleteTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DeleteTableStateData.newBuilder() to construct.
    private DeleteTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DeleteTableStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DeleteTableStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DeleteTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DeleteTableStateData>() {
      public DeleteTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new DeleteTableStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteTableStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CreateNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CreateNamespaceStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CreateNamespaceStateData}
   */
  @javax.annotation.Generated("proto") public  static final class CreateNamespaceStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CreateNamespaceStateData)
      CreateNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CreateNamespaceStateData.newBuilder() to construct.
    private CreateNamespaceStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CreateNamespaceStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CreateNamespaceStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceDescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getNamespaceDescriptor().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getNamespaceDescriptor());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNamespaceDescriptor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) obj;

      boolean result = true;
      result = result && (hasNamespaceDescriptor() == other.hasNamespaceDescriptor());
      if (hasNamespaceDescriptor()) {
        result = result && getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CreateNamespaceStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CreateNamespaceStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (namespaceDescriptorBuilder_ == null) {
          result.namespaceDescriptor_ = namespaceDescriptor_;
        } else {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasNamespaceDescriptor()) {
          return false;
        }
        if (!getNamespaceDescriptor().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              namespaceDescriptor_ != null &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CreateNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CreateNamespaceStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateNamespaceStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CreateNamespaceStateData>() {
      public CreateNamespaceStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new CreateNamespaceStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateNamespaceStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyNamespaceStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();

    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    boolean hasUnmodifiedNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyNamespaceStateData}
   */
  @javax.annotation.Generated("proto") public  static final class ModifyNamespaceStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyNamespaceStateData)
      ModifyNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyNamespaceStateData.newBuilder() to construct.
    private ModifyNamespaceStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyNamespaceStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModifyNamespaceStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = unmodifiedNamespaceDescriptor_.toBuilder();
              }
              unmodifiedNamespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedNamespaceDescriptor_);
                unmodifiedNamespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    public static final int UNMODIFIED_NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor unmodifiedNamespaceDescriptor_;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    public boolean hasUnmodifiedNamespaceDescriptor() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor() {
      return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder() {
      return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceDescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getNamespaceDescriptor().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedNamespaceDescriptor()) {
        if (!getUnmodifiedNamespaceDescriptor().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getNamespaceDescriptor());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getUnmodifiedNamespaceDescriptor());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNamespaceDescriptor());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getUnmodifiedNamespaceDescriptor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) obj;

      boolean result = true;
      result = result && (hasNamespaceDescriptor() == other.hasNamespaceDescriptor());
      if (hasNamespaceDescriptor()) {
        result = result && getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor());
      }
      result = result && (hasUnmodifiedNamespaceDescriptor() == other.hasUnmodifiedNamespaceDescriptor());
      if (hasUnmodifiedNamespaceDescriptor()) {
        result = result && getUnmodifiedNamespaceDescriptor()
            .equals(other.getUnmodifiedNamespaceDescriptor());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      if (hasUnmodifiedNamespaceDescriptor()) {
        hash = (37 * hash) + UNMODIFIED_NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyNamespaceStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyNamespaceStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
          getUnmodifiedNamespaceDescriptorFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = null;
        } else {
          unmodifiedNamespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (namespaceDescriptorBuilder_ == null) {
          result.namespaceDescriptor_ = namespaceDescriptor_;
        } else {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          result.unmodifiedNamespaceDescriptor_ = unmodifiedNamespaceDescriptor_;
        } else {
          result.unmodifiedNamespaceDescriptor_ = unmodifiedNamespaceDescriptorBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        if (other.hasUnmodifiedNamespaceDescriptor()) {
          mergeUnmodifiedNamespaceDescriptor(other.getUnmodifiedNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasNamespaceDescriptor()) {
          return false;
        }
        if (!getNamespaceDescriptor().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedNamespaceDescriptor()) {
          if (!getUnmodifiedNamespaceDescriptor().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              namespaceDescriptor_ != null &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor unmodifiedNamespaceDescriptor_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> unmodifiedNamespaceDescriptorBuilder_;
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public boolean hasUnmodifiedNamespaceDescriptor() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
        } else {
          return unmodifiedNamespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder setUnmodifiedNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedNamespaceDescriptor_ = value;
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder setUnmodifiedNamespaceDescriptor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder mergeUnmodifiedNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              unmodifiedNamespaceDescriptor_ != null &&
              unmodifiedNamespaceDescriptor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            unmodifiedNamespaceDescriptor_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(unmodifiedNamespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedNamespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder clearUnmodifiedNamespaceDescriptor() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = null;
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getUnmodifiedNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getUnmodifiedNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder() {
        if (unmodifiedNamespaceDescriptorBuilder_ != null) {
          return unmodifiedNamespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedNamespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getUnmodifiedNamespaceDescriptorFieldBuilder() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getUnmodifiedNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          unmodifiedNamespaceDescriptor_ = null;
        }
        return unmodifiedNamespaceDescriptorBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyNamespaceStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyNamespaceStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ModifyNamespaceStateData>() {
      public ModifyNamespaceStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new ModifyNamespaceStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyNamespaceStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DeleteNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DeleteNamespaceStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string namespace_name = 1;</code>
     */
    boolean hasNamespaceName();
    /**
     * <code>required string namespace_name = 1;</code>
     */
    java.lang.String getNamespaceName();
    /**
     * <code>required string namespace_name = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getNamespaceNameBytes();

    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteNamespaceStateData}
   */
  @javax.annotation.Generated("proto") public  static final class DeleteNamespaceStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DeleteNamespaceStateData)
      DeleteNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DeleteNamespaceStateData.newBuilder() to construct.
    private DeleteNamespaceStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DeleteNamespaceStateData() {
      namespaceName_ = "";
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DeleteNamespaceStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              namespaceName_ = bs;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object namespaceName_;
    /**
     * <code>required string namespace_name = 1;</code>
     */
    public boolean hasNamespaceName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string namespace_name = 1;</code>
     */
    public java.lang.String getNamespaceName() {
      java.lang.Object ref = namespaceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          namespaceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string namespace_name = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getNamespaceNameBytes() {
      java.lang.Object ref = namespaceName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        namespaceName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, namespaceName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getNamespaceDescriptor());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, namespaceName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getNamespaceDescriptor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) obj;

      boolean result = true;
      result = result && (hasNamespaceName() == other.hasNamespaceName());
      if (hasNamespaceName()) {
        result = result && getNamespaceName()
            .equals(other.getNamespaceName());
      }
      result = result && (hasNamespaceDescriptor() == other.hasNamespaceDescriptor());
      if (hasNamespaceDescriptor()) {
        result = result && getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceName()) {
        hash = (37 * hash) + NAMESPACE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceName().hashCode();
      }
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteNamespaceStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DeleteNamespaceStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        namespaceName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.namespaceName_ = namespaceName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (namespaceDescriptorBuilder_ == null) {
          result.namespaceDescriptor_ = namespaceDescriptor_;
        } else {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceName()) {
          bitField0_ |= 0x00000001;
          namespaceName_ = other.namespaceName_;
          onChanged();
        }
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasNamespaceName()) {
          return false;
        }
        if (hasNamespaceDescriptor()) {
          if (!getNamespaceDescriptor().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object namespaceName_ = "";
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public boolean hasNamespaceName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public java.lang.String getNamespaceName() {
        java.lang.Object ref = namespaceName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            namespaceName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getNamespaceNameBytes() {
        java.lang.Object ref = namespaceName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          namespaceName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public Builder setNamespaceName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        namespaceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public Builder clearNamespaceName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        namespaceName_ = getDefaultInstance().getNamespaceName();
        onChanged();
        return this;
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public Builder setNamespaceNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        namespaceName_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              namespaceDescriptor_ != null &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteNamespaceStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteNamespaceStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DeleteNamespaceStateData>() {
      public DeleteNamespaceStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new DeleteNamespaceStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteNamespaceStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface EnableTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.EnableTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <pre>
     * not used any more, always false
     * </pre>
     *
     * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
     */
    @java.lang.Deprecated boolean hasSkipTableStateCheck();
    /**
     * <pre>
     * not used any more, always false
     * </pre>
     *
     * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
     */
    @java.lang.Deprecated boolean getSkipTableStateCheck();
  }
  /**
   * Protobuf type {@code hbase.pb.EnableTableStateData}
   */
  @javax.annotation.Generated("proto") public  static final class EnableTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.EnableTableStateData)
      EnableTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use EnableTableStateData.newBuilder() to construct.
    private EnableTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private EnableTableStateData() {
      skipTableStateCheck_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private EnableTableStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              skipTableStateCheck_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int SKIP_TABLE_STATE_CHECK_FIELD_NUMBER = 3;
    private boolean skipTableStateCheck_;
    /**
     * <pre>
     * not used any more, always false
     * </pre>
     *
     * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
     */
    @java.lang.Deprecated public boolean hasSkipTableStateCheck() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <pre>
     * not used any more, always false
     * </pre>
     *
     * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
     */
    @java.lang.Deprecated public boolean getSkipTableStateCheck() {
      return skipTableStateCheck_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSkipTableStateCheck()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, skipTableStateCheck_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, skipTableStateCheck_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasSkipTableStateCheck() == other.hasSkipTableStateCheck());
      if (hasSkipTableStateCheck()) {
        result = result && (getSkipTableStateCheck()
            == other.getSkipTableStateCheck());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasSkipTableStateCheck()) {
        hash = (37 * hash) + SKIP_TABLE_STATE_CHECK_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getSkipTableStateCheck());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.EnableTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.EnableTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        skipTableStateCheck_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.skipTableStateCheck_ = skipTableStateCheck_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasSkipTableStateCheck()) {
          setSkipTableStateCheck(other.getSkipTableStateCheck());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasSkipTableStateCheck()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private boolean skipTableStateCheck_ ;
      /**
       * <pre>
       * not used any more, always false
       * </pre>
       *
       * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public boolean hasSkipTableStateCheck() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <pre>
       * not used any more, always false
       * </pre>
       *
       * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public boolean getSkipTableStateCheck() {
        return skipTableStateCheck_;
      }
      /**
       * <pre>
       * not used any more, always false
       * </pre>
       *
       * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder setSkipTableStateCheck(boolean value) {
        bitField0_ |= 0x00000004;
        skipTableStateCheck_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * not used any more, always false
       * </pre>
       *
       * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder clearSkipTableStateCheck() {
        bitField0_ = (bitField0_ & ~0x00000004);
        skipTableStateCheck_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.EnableTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.EnableTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnableTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<EnableTableStateData>() {
      public EnableTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new EnableTableStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnableTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnableTableStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DisableTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DisableTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    boolean hasSkipTableStateCheck();
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    boolean getSkipTableStateCheck();
  }
  /**
   * Protobuf type {@code hbase.pb.DisableTableStateData}
   */
  @javax.annotation.Generated("proto") public  static final class DisableTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DisableTableStateData)
      DisableTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DisableTableStateData.newBuilder() to construct.
    private DisableTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DisableTableStateData() {
      skipTableStateCheck_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DisableTableStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              skipTableStateCheck_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int SKIP_TABLE_STATE_CHECK_FIELD_NUMBER = 3;
    private boolean skipTableStateCheck_;
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    public boolean hasSkipTableStateCheck() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    public boolean getSkipTableStateCheck() {
      return skipTableStateCheck_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSkipTableStateCheck()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, skipTableStateCheck_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, skipTableStateCheck_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasSkipTableStateCheck() == other.hasSkipTableStateCheck());
      if (hasSkipTableStateCheck()) {
        result = result && (getSkipTableStateCheck()
            == other.getSkipTableStateCheck());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasSkipTableStateCheck()) {
        hash = (37 * hash) + SKIP_TABLE_STATE_CHECK_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getSkipTableStateCheck());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DisableTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DisableTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        skipTableStateCheck_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.skipTableStateCheck_ = skipTableStateCheck_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasSkipTableStateCheck()) {
          setSkipTableStateCheck(other.getSkipTableStateCheck());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasSkipTableStateCheck()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private boolean skipTableStateCheck_ ;
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public boolean hasSkipTableStateCheck() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public boolean getSkipTableStateCheck() {
        return skipTableStateCheck_;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public Builder setSkipTableStateCheck(boolean value) {
        bitField0_ |= 0x00000004;
        skipTableStateCheck_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public Builder clearSkipTableStateCheck() {
        bitField0_ = (bitField0_ & ~0x00000004);
        skipTableStateCheck_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DisableTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DisableTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisableTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DisableTableStateData>() {
      public DisableTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new DisableTableStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisableTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisableTableStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RestoreParentToChildRegionsPairOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RestoreParentToChildRegionsPair)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string parent_region_name = 1;</code>
     */
    boolean hasParentRegionName();
    /**
     * <code>required string parent_region_name = 1;</code>
     */
    java.lang.String getParentRegionName();
    /**
     * <code>required string parent_region_name = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getParentRegionNameBytes();

    /**
     * <code>required string child1_region_name = 2;</code>
     */
    boolean hasChild1RegionName();
    /**
     * <code>required string child1_region_name = 2;</code>
     */
    java.lang.String getChild1RegionName();
    /**
     * <code>required string child1_region_name = 2;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getChild1RegionNameBytes();

    /**
     * <code>required string child2_region_name = 3;</code>
     */
    boolean hasChild2RegionName();
    /**
     * <code>required string child2_region_name = 3;</code>
     */
    java.lang.String getChild2RegionName();
    /**
     * <code>required string child2_region_name = 3;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getChild2RegionNameBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.RestoreParentToChildRegionsPair}
   */
  @javax.annotation.Generated("proto") public  static final class RestoreParentToChildRegionsPair extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RestoreParentToChildRegionsPair)
      RestoreParentToChildRegionsPairOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RestoreParentToChildRegionsPair.newBuilder() to construct.
    private RestoreParentToChildRegionsPair(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RestoreParentToChildRegionsPair() {
      parentRegionName_ = "";
      child1RegionName_ = "";
      child2RegionName_ = "";
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RestoreParentToChildRegionsPair(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              parentRegionName_ = bs;
              break;
            }
            case 18: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              child1RegionName_ = bs;
              break;
            }
            case 26: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              child2RegionName_ = bs;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder.class);
    }

    private int bitField0_;
    public static final int PARENT_REGION_NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object parentRegionName_;
    /**
     * <code>required string parent_region_name = 1;</code>
     */
    public boolean hasParentRegionName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string parent_region_name = 1;</code>
     */
    public java.lang.String getParentRegionName() {
      java.lang.Object ref = parentRegionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          parentRegionName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string parent_region_name = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getParentRegionNameBytes() {
      java.lang.Object ref = parentRegionName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        parentRegionName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CHILD1_REGION_NAME_FIELD_NUMBER = 2;
    private volatile java.lang.Object child1RegionName_;
    /**
     * <code>required string child1_region_name = 2;</code>
     */
    public boolean hasChild1RegionName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required string child1_region_name = 2;</code>
     */
    public java.lang.String getChild1RegionName() {
      java.lang.Object ref = child1RegionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          child1RegionName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string child1_region_name = 2;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getChild1RegionNameBytes() {
      java.lang.Object ref = child1RegionName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        child1RegionName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CHILD2_REGION_NAME_FIELD_NUMBER = 3;
    private volatile java.lang.Object child2RegionName_;
    /**
     * <code>required string child2_region_name = 3;</code>
     */
    public boolean hasChild2RegionName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required string child2_region_name = 3;</code>
     */
    public java.lang.String getChild2RegionName() {
      java.lang.Object ref = child2RegionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          child2RegionName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string child2_region_name = 3;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getChild2RegionNameBytes() {
      java.lang.Object ref = child2RegionName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        child2RegionName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasParentRegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasChild1RegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasChild2RegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, parentRegionName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, child1RegionName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, child2RegionName_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, parentRegionName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, child1RegionName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(3, child2RegionName_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair) obj;

      boolean result = true;
      result = result && (hasParentRegionName() == other.hasParentRegionName());
      if (hasParentRegionName()) {
        result = result && getParentRegionName()
            .equals(other.getParentRegionName());
      }
      result = result && (hasChild1RegionName() == other.hasChild1RegionName());
      if (hasChild1RegionName()) {
        result = result && getChild1RegionName()
            .equals(other.getChild1RegionName());
      }
      result = result && (hasChild2RegionName() == other.hasChild2RegionName());
      if (hasChild2RegionName()) {
        result = result && getChild2RegionName()
            .equals(other.getChild2RegionName());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasParentRegionName()) {
        hash = (37 * hash) + PARENT_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getParentRegionName().hashCode();
      }
      if (hasChild1RegionName()) {
        hash = (37 * hash) + CHILD1_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getChild1RegionName().hashCode();
      }
      if (hasChild2RegionName()) {
        hash = (37 * hash) + CHILD2_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getChild2RegionName().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RestoreParentToChildRegionsPair}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RestoreParentToChildRegionsPair)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        parentRegionName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        child1RegionName_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        child2RegionName_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.parentRegionName_ = parentRegionName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.child1RegionName_ = child1RegionName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.child2RegionName_ = child2RegionName_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance()) return this;
        if (other.hasParentRegionName()) {
          bitField0_ |= 0x00000001;
          parentRegionName_ = other.parentRegionName_;
          onChanged();
        }
        if (other.hasChild1RegionName()) {
          bitField0_ |= 0x00000002;
          child1RegionName_ = other.child1RegionName_;
          onChanged();
        }
        if (other.hasChild2RegionName()) {
          bitField0_ |= 0x00000004;
          child2RegionName_ = other.child2RegionName_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasParentRegionName()) {
          return false;
        }
        if (!hasChild1RegionName()) {
          return false;
        }
        if (!hasChild2RegionName()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object parentRegionName_ = "";
      /**
       * <code>required string parent_region_name = 1;</code>
       */
      public boolean hasParentRegionName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       */
      public java.lang.String getParentRegionName() {
        java.lang.Object ref = parentRegionName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            parentRegionName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getParentRegionNameBytes() {
        java.lang.Object ref = parentRegionName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          parentRegionName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       */
      public Builder setParentRegionName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        parentRegionName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       */
      public Builder clearParentRegionName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        parentRegionName_ = getDefaultInstance().getParentRegionName();
        onChanged();
        return this;
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       */
      public Builder setParentRegionNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        parentRegionName_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object child1RegionName_ = "";
      /**
       * <code>required string child1_region_name = 2;</code>
       */
      public boolean hasChild1RegionName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       */
      public java.lang.String getChild1RegionName() {
        java.lang.Object ref = child1RegionName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            child1RegionName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getChild1RegionNameBytes() {
        java.lang.Object ref = child1RegionName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          child1RegionName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       */
      public Builder setChild1RegionName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        child1RegionName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       */
      public Builder clearChild1RegionName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        child1RegionName_ = getDefaultInstance().getChild1RegionName();
        onChanged();
        return this;
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       */
      public Builder setChild1RegionNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        child1RegionName_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object child2RegionName_ = "";
      /**
       * <code>required string child2_region_name = 3;</code>
       */
      public boolean hasChild2RegionName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       */
      public java.lang.String getChild2RegionName() {
        java.lang.Object ref = child2RegionName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            child2RegionName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getChild2RegionNameBytes() {
        java.lang.Object ref = child2RegionName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          child2RegionName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       */
      public Builder setChild2RegionName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        child2RegionName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       */
      public Builder clearChild2RegionName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        child2RegionName_ = getDefaultInstance().getChild2RegionName();
        onChanged();
        return this;
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       */
      public Builder setChild2RegionNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        child2RegionName_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RestoreParentToChildRegionsPair)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RestoreParentToChildRegionsPair)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreParentToChildRegionsPair>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RestoreParentToChildRegionsPair>() {
      public RestoreParentToChildRegionsPair parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RestoreParentToChildRegionsPair(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreParentToChildRegionsPair> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreParentToChildRegionsPair> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloneSnapshotStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CloneSnapshotStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    boolean hasSnapshot();
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot();
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     */
    boolean hasTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> 
        getParentToChildRegionsPairListList();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index);
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    int getParentToChildRegionsPairListCount();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
        getParentToChildRegionsPairListOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.CloneSnapshotStateData}
   */
  @javax.annotation.Generated("proto") public  static final class CloneSnapshotStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CloneSnapshotStateData)
      CloneSnapshotStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloneSnapshotStateData.newBuilder() to construct.
    private CloneSnapshotStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloneSnapshotStateData() {
      regionInfo_ = java.util.Collections.emptyList();
      parentToChildRegionsPairList_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CloneSnapshotStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = snapshot_.toBuilder();
              }
              snapshot_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(snapshot_);
                snapshot_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = tableSchema_.toBuilder();
              }
              tableSchema_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableSchema_);
                tableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000008;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                parentToChildRegionsPairList_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair>();
                mutable_bitField0_ |= 0x00000010;
              }
              parentToChildRegionsPairList_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          parentToChildRegionsPairList_ = java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int SNAPSHOT_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot_;
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    public boolean hasSnapshot() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot() {
      return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
    }
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder() {
      return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
    }

    public static final int TABLE_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     */
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    public static final int PARENT_TO_CHILD_REGIONS_PAIR_LIST_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> parentToChildRegionsPairList_;
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> getParentToChildRegionsPairListList() {
      return parentToChildRegionsPairList_;
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
        getParentToChildRegionsPairListOrBuilderList() {
      return parentToChildRegionsPairList_;
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    public int getParentToChildRegionsPairListCount() {
      return parentToChildRegionsPairList_.size();
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index) {
      return parentToChildRegionsPairList_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
        int index) {
      return parentToChildRegionsPairList_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSnapshot()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getSnapshot().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getParentToChildRegionsPairListCount(); i++) {
        if (!getParentToChildRegionsPairList(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getSnapshot());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(4, regionInfo_.get(i));
      }
      for (int i = 0; i < parentToChildRegionsPairList_.size(); i++) {
        output.writeMessage(5, parentToChildRegionsPairList_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getSnapshot());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionInfo_.get(i));
      }
      for (int i = 0; i < parentToChildRegionsPairList_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, parentToChildRegionsPairList_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasSnapshot() == other.hasSnapshot());
      if (hasSnapshot()) {
        result = result && getSnapshot()
            .equals(other.getSnapshot());
      }
      result = result && (hasTableSchema() == other.hasTableSchema());
      if (hasTableSchema()) {
        result = result && getTableSchema()
            .equals(other.getTableSchema());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result && getParentToChildRegionsPairListList()
          .equals(other.getParentToChildRegionsPairListList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasSnapshot()) {
        hash = (37 * hash) + SNAPSHOT_FIELD_NUMBER;
        hash = (53 * hash) + getSnapshot().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      if (getParentToChildRegionsPairListCount() > 0) {
        hash = (37 * hash) + PARENT_TO_CHILD_REGIONS_PAIR_LIST_FIELD_NUMBER;
        hash = (53 * hash) + getParentToChildRegionsPairListList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CloneSnapshotStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CloneSnapshotStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getSnapshotFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
          getParentToChildRegionsPairListFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (snapshotBuilder_ == null) {
          snapshot_ = null;
        } else {
          snapshotBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          regionInfoBuilder_.clear();
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairList_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          parentToChildRegionsPairListBuilder_.clear();
        }
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (snapshotBuilder_ == null) {
          result.snapshot_ = snapshot_;
        } else {
          result.snapshot_ = snapshotBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (tableSchemaBuilder_ == null) {
          result.tableSchema_ = tableSchema_;
        } else {
          result.tableSchema_ = tableSchemaBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            parentToChildRegionsPairList_ = java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.parentToChildRegionsPairList_ = parentToChildRegionsPairList_;
        } else {
          result.parentToChildRegionsPairList_ = parentToChildRegionsPairListBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasSnapshot()) {
          mergeSnapshot(other.getSnapshot());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000008);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (!other.parentToChildRegionsPairList_.isEmpty()) {
            if (parentToChildRegionsPairList_.isEmpty()) {
              parentToChildRegionsPairList_ = other.parentToChildRegionsPairList_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureParentToChildRegionsPairListIsMutable();
              parentToChildRegionsPairList_.addAll(other.parentToChildRegionsPairList_);
            }
            onChanged();
          }
        } else {
          if (!other.parentToChildRegionsPairList_.isEmpty()) {
            if (parentToChildRegionsPairListBuilder_.isEmpty()) {
              parentToChildRegionsPairListBuilder_.dispose();
              parentToChildRegionsPairListBuilder_ = null;
              parentToChildRegionsPairList_ = other.parentToChildRegionsPairList_;
              bitField0_ = (bitField0_ & ~0x00000010);
              parentToChildRegionsPairListBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getParentToChildRegionsPairListFieldBuilder() : null;
            } else {
              parentToChildRegionsPairListBuilder_.addAllMessages(other.parentToChildRegionsPairList_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasSnapshot()) {
          return false;
        }
        if (!hasTableSchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getSnapshot().isInitialized()) {
          return false;
        }
        if (!getTableSchema().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getParentToChildRegionsPairListCount(); i++) {
          if (!getParentToChildRegionsPairList(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder> snapshotBuilder_;
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public boolean hasSnapshot() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot() {
        if (snapshotBuilder_ == null) {
          return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
        } else {
          return snapshotBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder setSnapshot(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription value) {
        if (snapshotBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          snapshot_ = value;
          onChanged();
        } else {
          snapshotBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder setSnapshot(
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder builderForValue) {
        if (snapshotBuilder_ == null) {
          snapshot_ = builderForValue.build();
          onChanged();
        } else {
          snapshotBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder mergeSnapshot(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription value) {
        if (snapshotBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              snapshot_ != null &&
              snapshot_ != org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance()) {
            snapshot_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.newBuilder(snapshot_).mergeFrom(value).buildPartial();
          } else {
            snapshot_ = value;
          }
          onChanged();
        } else {
          snapshotBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder clearSnapshot() {
        if (snapshotBuilder_ == null) {
          snapshot_ = null;
          onChanged();
        } else {
          snapshotBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder getSnapshotBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getSnapshotFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder() {
        if (snapshotBuilder_ != null) {
          return snapshotBuilder_.getMessageOrBuilder();
        } else {
          return snapshot_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
        }
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder> 
          getSnapshotFieldBuilder() {
        if (snapshotBuilder_ == null) {
          snapshotBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder>(
                  getSnapshot(),
                  getParentForChildren(),
                  isClean());
          snapshot_ = null;
        }
        return snapshotBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              tableSchema_ != null &&
              tableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            tableSchema_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.newBuilder(tableSchema_).mergeFrom(value).buildPartial();
          } else {
            tableSchema_ = value;
          }
          onChanged();
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public Builder clearTableSchema() {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
          onChanged();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getTableSchema(),
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000008;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> parentToChildRegionsPairList_ =
        java.util.Collections.emptyList();
      private void ensureParentToChildRegionsPairListIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          parentToChildRegionsPairList_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair>(parentToChildRegionsPairList_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> parentToChildRegionsPairListBuilder_;

      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> getParentToChildRegionsPairListList() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        } else {
          return parentToChildRegionsPairListBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public int getParentToChildRegionsPairListCount() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.size();
        } else {
          return parentToChildRegionsPairListBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.get(index);
        } else {
          return parentToChildRegionsPairListBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder setParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.set(index, value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder setParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.set(index, builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addParentToChildRegionsPairList(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(index, value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addParentToChildRegionsPairList(
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(index, builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addAllParentToChildRegionsPairList(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> values) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, parentToChildRegionsPairList_);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder clearParentToChildRegionsPairList() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairList_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder removeParentToChildRegionsPairList(int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.remove(index);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder getParentToChildRegionsPairListBuilder(
          int index) {
        return getParentToChildRegionsPairListFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
          int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.get(index);  } else {
          return parentToChildRegionsPairListBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
           getParentToChildRegionsPairListOrBuilderList() {
        if (parentToChildRegionsPairListBuilder_ != null) {
          return parentToChildRegionsPairListBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder addParentToChildRegionsPairListBuilder() {
        return getParentToChildRegionsPairListFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder addParentToChildRegionsPairListBuilder(
          int index) {
        return getParentToChildRegionsPairListFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder> 
           getParentToChildRegionsPairListBuilderList() {
        return getParentToChildRegionsPairListFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
          getParentToChildRegionsPairListFieldBuilder() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairListBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder>(
                  parentToChildRegionsPairList_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          parentToChildRegionsPairList_ = null;
        }
        return parentToChildRegionsPairListBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CloneSnapshotStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CloneSnapshotStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloneSnapshotStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CloneSnapshotStateData>() {
      public CloneSnapshotStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new CloneSnapshotStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloneSnapshotStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloneSnapshotStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RestoreSnapshotStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RestoreSnapshotStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    boolean hasSnapshot();
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot();
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    boolean hasModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoForRestoreList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRestore(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    int getRegionInfoForRestoreCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForRestoreOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRestoreOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoForRemoveList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRemove(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    int getRegionInfoForRemoveCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForRemoveOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRemoveOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoForAddList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForAdd(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    int getRegionInfoForAddCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForAddOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForAddOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> 
        getParentToChildRegionsPairListList();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index);
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    int getParentToChildRegionsPairListCount();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
        getParentToChildRegionsPairListOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.RestoreSnapshotStateData}
   */
  @javax.annotation.Generated("proto") public  static final class RestoreSnapshotStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RestoreSnapshotStateData)
      RestoreSnapshotStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RestoreSnapshotStateData.newBuilder() to construct.
    private RestoreSnapshotStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RestoreSnapshotStateData() {
      regionInfoForRestore_ = java.util.Collections.emptyList();
      regionInfoForRemove_ = java.util.Collections.emptyList();
      regionInfoForAdd_ = java.util.Collections.emptyList();
      parentToChildRegionsPairList_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RestoreSnapshotStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = snapshot_.toBuilder();
              }
              snapshot_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(snapshot_);
                snapshot_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = modifiedTableSchema_.toBuilder();
              }
              modifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(modifiedTableSchema_);
                modifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                regionInfoForRestore_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000008;
              }
              regionInfoForRestore_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                regionInfoForRemove_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000010;
              }
              regionInfoForRemove_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                regionInfoForAdd_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000020;
              }
              regionInfoForAdd_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                parentToChildRegionsPairList_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair>();
                mutable_bitField0_ |= 0x00000040;
              }
              parentToChildRegionsPairList_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          regionInfoForRestore_ = java.util.Collections.unmodifiableList(regionInfoForRestore_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          regionInfoForRemove_ = java.util.Collections.unmodifiableList(regionInfoForRemove_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          regionInfoForAdd_ = java.util.Collections.unmodifiableList(regionInfoForAdd_);
        }
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          parentToChildRegionsPairList_ = java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int SNAPSHOT_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot_;
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    public boolean hasSnapshot() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot() {
      return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
    }
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder() {
      return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
    }

    public static final int MODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public boolean hasModifiedTableSchema() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }

    public static final int REGION_INFO_FOR_RESTORE_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForRestore_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForRestoreList() {
      return regionInfoForRestore_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForRestoreOrBuilderList() {
      return regionInfoForRestore_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    public int getRegionInfoForRestoreCount() {
      return regionInfoForRestore_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRestore(int index) {
      return regionInfoForRestore_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRestoreOrBuilder(
        int index) {
      return regionInfoForRestore_.get(index);
    }

    public static final int REGION_INFO_FOR_REMOVE_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForRemove_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForRemoveList() {
      return regionInfoForRemove_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForRemoveOrBuilderList() {
      return regionInfoForRemove_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    public int getRegionInfoForRemoveCount() {
      return regionInfoForRemove_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRemove(int index) {
      return regionInfoForRemove_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRemoveOrBuilder(
        int index) {
      return regionInfoForRemove_.get(index);
    }

    public static final int REGION_INFO_FOR_ADD_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForAdd_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForAddList() {
      return regionInfoForAdd_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForAddOrBuilderList() {
      return regionInfoForAdd_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    public int getRegionInfoForAddCount() {
      return regionInfoForAdd_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForAdd(int index) {
      return regionInfoForAdd_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForAddOrBuilder(
        int index) {
      return regionInfoForAdd_.get(index);
    }

    public static final int PARENT_TO_CHILD_REGIONS_PAIR_LIST_FIELD_NUMBER = 7;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> parentToChildRegionsPairList_;
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> getParentToChildRegionsPairListList() {
      return parentToChildRegionsPairList_;
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
        getParentToChildRegionsPairListOrBuilderList() {
      return parentToChildRegionsPairList_;
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    public int getParentToChildRegionsPairListCount() {
      return parentToChildRegionsPairList_.size();
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index) {
      return parentToChildRegionsPairList_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
        int index) {
      return parentToChildRegionsPairList_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSnapshot()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasModifiedTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getSnapshot().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getModifiedTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoForRestoreCount(); i++) {
        if (!getRegionInfoForRestore(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionInfoForRemoveCount(); i++) {
        if (!getRegionInfoForRemove(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionInfoForAddCount(); i++) {
        if (!getRegionInfoForAdd(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getParentToChildRegionsPairListCount(); i++) {
        if (!getParentToChildRegionsPairList(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getSnapshot());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getModifiedTableSchema());
      }
      for (int i = 0; i < regionInfoForRestore_.size(); i++) {
        output.writeMessage(4, regionInfoForRestore_.get(i));
      }
      for (int i = 0; i < regionInfoForRemove_.size(); i++) {
        output.writeMessage(5, regionInfoForRemove_.get(i));
      }
      for (int i = 0; i < regionInfoForAdd_.size(); i++) {
        output.writeMessage(6, regionInfoForAdd_.get(i));
      }
      for (int i = 0; i < parentToChildRegionsPairList_.size(); i++) {
        output.writeMessage(7, parentToChildRegionsPairList_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getSnapshot());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getModifiedTableSchema());
      }
      for (int i = 0; i < regionInfoForRestore_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionInfoForRestore_.get(i));
      }
      for (int i = 0; i < regionInfoForRemove_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, regionInfoForRemove_.get(i));
      }
      for (int i = 0; i < regionInfoForAdd_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, regionInfoForAdd_.get(i));
      }
      for (int i = 0; i < parentToChildRegionsPairList_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, parentToChildRegionsPairList_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasSnapshot() == other.hasSnapshot());
      if (hasSnapshot()) {
        result = result && getSnapshot()
            .equals(other.getSnapshot());
      }
      result = result && (hasModifiedTableSchema() == other.hasModifiedTableSchema());
      if (hasModifiedTableSchema()) {
        result = result && getModifiedTableSchema()
            .equals(other.getModifiedTableSchema());
      }
      result = result && getRegionInfoForRestoreList()
          .equals(other.getRegionInfoForRestoreList());
      result = result && getRegionInfoForRemoveList()
          .equals(other.getRegionInfoForRemoveList());
      result = result && getRegionInfoForAddList()
          .equals(other.getRegionInfoForAddList());
      result = result && getParentToChildRegionsPairListList()
          .equals(other.getParentToChildRegionsPairListList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasSnapshot()) {
        hash = (37 * hash) + SNAPSHOT_FIELD_NUMBER;
        hash = (53 * hash) + getSnapshot().hashCode();
      }
      if (hasModifiedTableSchema()) {
        hash = (37 * hash) + MODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getModifiedTableSchema().hashCode();
      }
      if (getRegionInfoForRestoreCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FOR_RESTORE_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoForRestoreList().hashCode();
      }
      if (getRegionInfoForRemoveCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FOR_REMOVE_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoForRemoveList().hashCode();
      }
      if (getRegionInfoForAddCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FOR_ADD_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoForAddList().hashCode();
      }
      if (getParentToChildRegionsPairListCount() > 0) {
        hash = (37 * hash) + PARENT_TO_CHILD_REGIONS_PAIR_LIST_FIELD_NUMBER;
        hash = (53 * hash) + getParentToChildRegionsPairListList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RestoreSnapshotStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RestoreSnapshotStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getSnapshotFieldBuilder();
          getModifiedTableSchemaFieldBuilder();
          getRegionInfoForRestoreFieldBuilder();
          getRegionInfoForRemoveFieldBuilder();
          getRegionInfoForAddFieldBuilder();
          getParentToChildRegionsPairListFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (snapshotBuilder_ == null) {
          snapshot_ = null;
        } else {
          snapshotBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = null;
        } else {
          modifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (regionInfoForRestoreBuilder_ == null) {
          regionInfoForRestore_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          regionInfoForRestoreBuilder_.clear();
        }
        if (regionInfoForRemoveBuilder_ == null) {
          regionInfoForRemove_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          regionInfoForRemoveBuilder_.clear();
        }
        if (regionInfoForAddBuilder_ == null) {
          regionInfoForAdd_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          regionInfoForAddBuilder_.clear();
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairList_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          parentToChildRegionsPairListBuilder_.clear();
        }
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (snapshotBuilder_ == null) {
          result.snapshot_ = snapshot_;
        } else {
          result.snapshot_ = snapshotBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (modifiedTableSchemaBuilder_ == null) {
          result.modifiedTableSchema_ = modifiedTableSchema_;
        } else {
          result.modifiedTableSchema_ = modifiedTableSchemaBuilder_.build();
        }
        if (regionInfoForRestoreBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            regionInfoForRestore_ = java.util.Collections.unmodifiableList(regionInfoForRestore_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.regionInfoForRestore_ = regionInfoForRestore_;
        } else {
          result.regionInfoForRestore_ = regionInfoForRestoreBuilder_.build();
        }
        if (regionInfoForRemoveBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            regionInfoForRemove_ = java.util.Collections.unmodifiableList(regionInfoForRemove_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.regionInfoForRemove_ = regionInfoForRemove_;
        } else {
          result.regionInfoForRemove_ = regionInfoForRemoveBuilder_.build();
        }
        if (regionInfoForAddBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            regionInfoForAdd_ = java.util.Collections.unmodifiableList(regionInfoForAdd_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.regionInfoForAdd_ = regionInfoForAdd_;
        } else {
          result.regionInfoForAdd_ = regionInfoForAddBuilder_.build();
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            parentToChildRegionsPairList_ = java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.parentToChildRegionsPairList_ = parentToChildRegionsPairList_;
        } else {
          result.parentToChildRegionsPairList_ = parentToChildRegionsPairListBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasSnapshot()) {
          mergeSnapshot(other.getSnapshot());
        }
        if (other.hasModifiedTableSchema()) {
          mergeModifiedTableSchema(other.getModifiedTableSchema());
        }
        if (regionInfoForRestoreBuilder_ == null) {
          if (!other.regionInfoForRestore_.isEmpty()) {
            if (regionInfoForRestore_.isEmpty()) {
              regionInfoForRestore_ = other.regionInfoForRestore_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureRegionInfoForRestoreIsMutable();
              regionInfoForRestore_.addAll(other.regionInfoForRestore_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfoForRestore_.isEmpty()) {
            if (regionInfoForRestoreBuilder_.isEmpty()) {
              regionInfoForRestoreBuilder_.dispose();
              regionInfoForRestoreBuilder_ = null;
              regionInfoForRestore_ = other.regionInfoForRestore_;
              bitField0_ = (bitField0_ & ~0x00000008);
              regionInfoForRestoreBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoForRestoreFieldBuilder() : null;
            } else {
              regionInfoForRestoreBuilder_.addAllMessages(other.regionInfoForRestore_);
            }
          }
        }
        if (regionInfoForRemoveBuilder_ == null) {
          if (!other.regionInfoForRemove_.isEmpty()) {
            if (regionInfoForRemove_.isEmpty()) {
              regionInfoForRemove_ = other.regionInfoForRemove_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureRegionInfoForRemoveIsMutable();
              regionInfoForRemove_.addAll(other.regionInfoForRemove_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfoForRemove_.isEmpty()) {
            if (regionInfoForRemoveBuilder_.isEmpty()) {
              regionInfoForRemoveBuilder_.dispose();
              regionInfoForRemoveBuilder_ = null;
              regionInfoForRemove_ = other.regionInfoForRemove_;
              bitField0_ = (bitField0_ & ~0x00000010);
              regionInfoForRemoveBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoForRemoveFieldBuilder() : null;
            } else {
              regionInfoForRemoveBuilder_.addAllMessages(other.regionInfoForRemove_);
            }
          }
        }
        if (regionInfoForAddBuilder_ == null) {
          if (!other.regionInfoForAdd_.isEmpty()) {
            if (regionInfoForAdd_.isEmpty()) {
              regionInfoForAdd_ = other.regionInfoForAdd_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureRegionInfoForAddIsMutable();
              regionInfoForAdd_.addAll(other.regionInfoForAdd_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfoForAdd_.isEmpty()) {
            if (regionInfoForAddBuilder_.isEmpty()) {
              regionInfoForAddBuilder_.dispose();
              regionInfoForAddBuilder_ = null;
              regionInfoForAdd_ = other.regionInfoForAdd_;
              bitField0_ = (bitField0_ & ~0x00000020);
              regionInfoForAddBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoForAddFieldBuilder() : null;
            } else {
              regionInfoForAddBuilder_.addAllMessages(other.regionInfoForAdd_);
            }
          }
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (!other.parentToChildRegionsPairList_.isEmpty()) {
            if (parentToChildRegionsPairList_.isEmpty()) {
              parentToChildRegionsPairList_ = other.parentToChildRegionsPairList_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureParentToChildRegionsPairListIsMutable();
              parentToChildRegionsPairList_.addAll(other.parentToChildRegionsPairList_);
            }
            onChanged();
          }
        } else {
          if (!other.parentToChildRegionsPairList_.isEmpty()) {
            if (parentToChildRegionsPairListBuilder_.isEmpty()) {
              parentToChildRegionsPairListBuilder_.dispose();
              parentToChildRegionsPairListBuilder_ = null;
              parentToChildRegionsPairList_ = other.parentToChildRegionsPairList_;
              bitField0_ = (bitField0_ & ~0x00000040);
              parentToChildRegionsPairListBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getParentToChildRegionsPairListFieldBuilder() : null;
            } else {
              parentToChildRegionsPairListBuilder_.addAllMessages(other.parentToChildRegionsPairList_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasSnapshot()) {
          return false;
        }
        if (!hasModifiedTableSchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getSnapshot().isInitialized()) {
          return false;
        }
        if (!getModifiedTableSchema().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoForRestoreCount(); i++) {
          if (!getRegionInfoForRestore(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionInfoForRemoveCount(); i++) {
          if (!getRegionInfoForRemove(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionInfoForAddCount(); i++) {
          if (!getRegionInfoForAdd(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getParentToChildRegionsPairListCount(); i++) {
          if (!getParentToChildRegionsPairList(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder> snapshotBuilder_;
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public boolean hasSnapshot() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot() {
        if (snapshotBuilder_ == null) {
          return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
        } else {
          return snapshotBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder setSnapshot(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription value) {
        if (snapshotBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          snapshot_ = value;
          onChanged();
        } else {
          snapshotBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder setSnapshot(
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder builderForValue) {
        if (snapshotBuilder_ == null) {
          snapshot_ = builderForValue.build();
          onChanged();
        } else {
          snapshotBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder mergeSnapshot(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription value) {
        if (snapshotBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              snapshot_ != null &&
              snapshot_ != org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance()) {
            snapshot_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.newBuilder(snapshot_).mergeFrom(value).buildPartial();
          } else {
            snapshot_ = value;
          }
          onChanged();
        } else {
          snapshotBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder clearSnapshot() {
        if (snapshotBuilder_ == null) {
          snapshot_ = null;
          onChanged();
        } else {
          snapshotBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder getSnapshotBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getSnapshotFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder() {
        if (snapshotBuilder_ != null) {
          return snapshotBuilder_.getMessageOrBuilder();
        } else {
          return snapshot_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
        }
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder> 
          getSnapshotFieldBuilder() {
        if (snapshotBuilder_ == null) {
          snapshotBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder>(
                  getSnapshot(),
                  getParentForChildren(),
                  isClean());
          snapshot_ = null;
        }
        return snapshotBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> modifiedTableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public boolean hasModifiedTableSchema() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        } else {
          return modifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modifiedTableSchema_ = value;
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder mergeModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              modifiedTableSchema_ != null &&
              modifiedTableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            modifiedTableSchema_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.newBuilder(modifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            modifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder clearModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = null;
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getModifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getModifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
        if (modifiedTableSchemaBuilder_ != null) {
          return modifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return modifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getModifiedTableSchemaFieldBuilder() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getModifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          modifiedTableSchema_ = null;
        }
        return modifiedTableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForRestore_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoForRestoreIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          regionInfoForRestore_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfoForRestore_);
          bitField0_ |= 0x00000008;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoForRestoreBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForRestoreList() {
        if (regionInfoForRestoreBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfoForRestore_);
        } else {
          return regionInfoForRestoreBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public int getRegionInfoForRestoreCount() {
        if (regionInfoForRestoreBuilder_ == null) {
          return regionInfoForRestore_.size();
        } else {
          return regionInfoForRestoreBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRestore(int index) {
        if (regionInfoForRestoreBuilder_ == null) {
          return regionInfoForRestore_.get(index);
        } else {
          return regionInfoForRestoreBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder setRegionInfoForRestore(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRestoreBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.set(index, value);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder setRegionInfoForRestore(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addRegionInfoForRestore(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRestoreBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.add(value);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addRegionInfoForRestore(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRestoreBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.add(index, value);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addRegionInfoForRestore(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addRegionInfoForRestore(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addAllRegionInfoForRestore(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfoForRestore_);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder clearRegionInfoForRestore() {
        if (regionInfoForRestoreBuilder_ == null) {
          regionInfoForRestore_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder removeRegionInfoForRestore(int index) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.remove(index);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoForRestoreBuilder(
          int index) {
        return getRegionInfoForRestoreFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRestoreOrBuilder(
          int index) {
        if (regionInfoForRestoreBuilder_ == null) {
          return regionInfoForRestore_.get(index);  } else {
          return regionInfoForRestoreBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoForRestoreOrBuilderList() {
        if (regionInfoForRestoreBuilder_ != null) {
          return regionInfoForRestoreBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfoForRestore_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForRestoreBuilder() {
        return getRegionInfoForRestoreFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForRestoreBuilder(
          int index) {
        return getRegionInfoForRestoreFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoForRestoreBuilderList() {
        return getRegionInfoForRestoreFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoForRestoreFieldBuilder() {
        if (regionInfoForRestoreBuilder_ == null) {
          regionInfoForRestoreBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfoForRestore_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          regionInfoForRestore_ = null;
        }
        return regionInfoForRestoreBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForRemove_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoForRemoveIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          regionInfoForRemove_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfoForRemove_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoForRemoveBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForRemoveList() {
        if (regionInfoForRemoveBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfoForRemove_);
        } else {
          return regionInfoForRemoveBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public int getRegionInfoForRemoveCount() {
        if (regionInfoForRemoveBuilder_ == null) {
          return regionInfoForRemove_.size();
        } else {
          return regionInfoForRemoveBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRemove(int index) {
        if (regionInfoForRemoveBuilder_ == null) {
          return regionInfoForRemove_.get(index);
        } else {
          return regionInfoForRemoveBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder setRegionInfoForRemove(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRemoveBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.set(index, value);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder setRegionInfoForRemove(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addRegionInfoForRemove(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRemoveBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.add(value);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addRegionInfoForRemove(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRemoveBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.add(index, value);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addRegionInfoForRemove(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addRegionInfoForRemove(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addAllRegionInfoForRemove(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfoForRemove_);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder clearRegionInfoForRemove() {
        if (regionInfoForRemoveBuilder_ == null) {
          regionInfoForRemove_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder removeRegionInfoForRemove(int index) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.remove(index);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoForRemoveBuilder(
          int index) {
        return getRegionInfoForRemoveFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRemoveOrBuilder(
          int index) {
        if (regionInfoForRemoveBuilder_ == null) {
          return regionInfoForRemove_.get(index);  } else {
          return regionInfoForRemoveBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoForRemoveOrBuilderList() {
        if (regionInfoForRemoveBuilder_ != null) {
          return regionInfoForRemoveBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfoForRemove_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForRemoveBuilder() {
        return getRegionInfoForRemoveFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForRemoveBuilder(
          int index) {
        return getRegionInfoForRemoveFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoForRemoveBuilderList() {
        return getRegionInfoForRemoveFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoForRemoveFieldBuilder() {
        if (regionInfoForRemoveBuilder_ == null) {
          regionInfoForRemoveBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfoForRemove_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          regionInfoForRemove_ = null;
        }
        return regionInfoForRemoveBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForAdd_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoForAddIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          regionInfoForAdd_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfoForAdd_);
          bitField0_ |= 0x00000020;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoForAddBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForAddList() {
        if (regionInfoForAddBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfoForAdd_);
        } else {
          return regionInfoForAddBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public int getRegionInfoForAddCount() {
        if (regionInfoForAddBuilder_ == null) {
          return regionInfoForAdd_.size();
        } else {
          return regionInfoForAddBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForAdd(int index) {
        if (regionInfoForAddBuilder_ == null) {
          return regionInfoForAdd_.get(index);
        } else {
          return regionInfoForAddBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder setRegionInfoForAdd(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForAddBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.set(index, value);
          onChanged();
        } else {
          regionInfoForAddBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder setRegionInfoForAdd(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForAddBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addRegionInfoForAdd(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForAddBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.add(value);
          onChanged();
        } else {
          regionInfoForAddBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addRegionInfoForAdd(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForAddBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.add(index, value);
          onChanged();
        } else {
          regionInfoForAddBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addRegionInfoForAdd(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoForAddBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addRegionInfoForAdd(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForAddBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addAllRegionInfoForAdd(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfoForAdd_);
          onChanged();
        } else {
          regionInfoForAddBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder clearRegionInfoForAdd() {
        if (regionInfoForAddBuilder_ == null) {
          regionInfoForAdd_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          regionInfoForAddBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder removeRegionInfoForAdd(int index) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.remove(index);
          onChanged();
        } else {
          regionInfoForAddBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoForAddBuilder(
          int index) {
        return getRegionInfoForAddFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForAddOrBuilder(
          int index) {
        if (regionInfoForAddBuilder_ == null) {
          return regionInfoForAdd_.get(index);  } else {
          return regionInfoForAddBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoForAddOrBuilderList() {
        if (regionInfoForAddBuilder_ != null) {
          return regionInfoForAddBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfoForAdd_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForAddBuilder() {
        return getRegionInfoForAddFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForAddBuilder(
          int index) {
        return getRegionInfoForAddFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoForAddBuilderList() {
        return getRegionInfoForAddFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoForAddFieldBuilder() {
        if (regionInfoForAddBuilder_ == null) {
          regionInfoForAddBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfoForAdd_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          regionInfoForAdd_ = null;
        }
        return regionInfoForAddBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> parentToChildRegionsPairList_ =
        java.util.Collections.emptyList();
      private void ensureParentToChildRegionsPairListIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          parentToChildRegionsPairList_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair>(parentToChildRegionsPairList_);
          bitField0_ |= 0x00000040;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> parentToChildRegionsPairListBuilder_;

      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> getParentToChildRegionsPairListList() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        } else {
          return parentToChildRegionsPairListBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public int getParentToChildRegionsPairListCount() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.size();
        } else {
          return parentToChildRegionsPairListBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.get(index);
        } else {
          return parentToChildRegionsPairListBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder setParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.set(index, value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder setParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.set(index, builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addParentToChildRegionsPairList(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(index, value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addParentToChildRegionsPairList(
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(index, builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addAllParentToChildRegionsPairList(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> values) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, parentToChildRegionsPairList_);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder clearParentToChildRegionsPairList() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairList_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder removeParentToChildRegionsPairList(int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.remove(index);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder getParentToChildRegionsPairListBuilder(
          int index) {
        return getParentToChildRegionsPairListFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
          int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.get(index);  } else {
          return parentToChildRegionsPairListBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
           getParentToChildRegionsPairListOrBuilderList() {
        if (parentToChildRegionsPairListBuilder_ != null) {
          return parentToChildRegionsPairListBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder addParentToChildRegionsPairListBuilder() {
        return getParentToChildRegionsPairListFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder addParentToChildRegionsPairListBuilder(
          int index) {
        return getParentToChildRegionsPairListFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder> 
           getParentToChildRegionsPairListBuilderList() {
        return getParentToChildRegionsPairListFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
          getParentToChildRegionsPairListFieldBuilder() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairListBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder>(
                  parentToChildRegionsPairList_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          parentToChildRegionsPairList_ = null;
        }
        return parentToChildRegionsPairListBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RestoreSnapshotStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RestoreSnapshotStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreSnapshotStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RestoreSnapshotStateData>() {
      public RestoreSnapshotStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RestoreSnapshotStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreSnapshotStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreSnapshotStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DispatchMergingRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DispatchMergingRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);

    /**
     * <code>optional bool forcible = 4;</code>
     */
    boolean hasForcible();
    /**
     * <code>optional bool forcible = 4;</code>
     */
    boolean getForcible();
  }
  /**
   * Protobuf type {@code hbase.pb.DispatchMergingRegionsStateData}
   */
  @javax.annotation.Generated("proto") public  static final class DispatchMergingRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DispatchMergingRegionsStateData)
      DispatchMergingRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DispatchMergingRegionsStateData.newBuilder() to construct.
    private DispatchMergingRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DispatchMergingRegionsStateData() {
      regionInfo_ = java.util.Collections.emptyList();
      forcible_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DispatchMergingRegionsStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 32: {
              bitField0_ |= 0x00000004;
              forcible_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    public static final int FORCIBLE_FIELD_NUMBER = 4;
    private boolean forcible_;
    /**
     * <code>optional bool forcible = 4;</code>
     */
    public boolean hasForcible() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool forcible = 4;</code>
     */
    public boolean getForcible() {
      return forcible_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(4, forcible_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, forcible_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result && (hasForcible() == other.hasForcible());
      if (hasForcible()) {
        result = result && (getForcible()
            == other.getForcible());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      if (hasForcible()) {
        hash = (37 * hash) + FORCIBLE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForcible());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DispatchMergingRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DispatchMergingRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionInfoBuilder_.clear();
        }
        forcible_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        result.forcible_ = forcible_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        if (other.hasForcible()) {
          setForcible(other.getForcible());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private boolean forcible_ ;
      /**
       * <code>optional bool forcible = 4;</code>
       */
      public boolean hasForcible() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional bool forcible = 4;</code>
       */
      public boolean getForcible() {
        return forcible_;
      }
      /**
       * <code>optional bool forcible = 4;</code>
       */
      public Builder setForcible(boolean value) {
        bitField0_ |= 0x00000008;
        forcible_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool forcible = 4;</code>
       */
      public Builder clearForcible() {
        bitField0_ = (bitField0_ & ~0x00000008);
        forcible_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DispatchMergingRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DispatchMergingRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DispatchMergingRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DispatchMergingRegionsStateData>() {
      public DispatchMergingRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new DispatchMergingRegionsStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DispatchMergingRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DispatchMergingRegionsStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SplitTableRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SplitTableRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     */
    boolean hasParentRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentRegionInfoOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getChildRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getChildRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    int getChildRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getChildRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getChildRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.SplitTableRegionStateData}
   */
  @javax.annotation.Generated("proto") public  static final class SplitTableRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SplitTableRegionStateData)
      SplitTableRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SplitTableRegionStateData.newBuilder() to construct.
    private SplitTableRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SplitTableRegionStateData() {
      childRegionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SplitTableRegionStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = parentRegionInfo_.toBuilder();
              }
              parentRegionInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(parentRegionInfo_);
                parentRegionInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                childRegionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              childRegionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          childRegionInfo_ = java.util.Collections.unmodifiableList(childRegionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int PARENT_REGION_INFO_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentRegionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     */
    public boolean hasParentRegionInfo() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentRegionInfo() {
      return parentRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentRegionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentRegionInfoOrBuilder() {
      return parentRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentRegionInfo_;
    }

    public static final int CHILD_REGION_INFO_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> childRegionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getChildRegionInfoList() {
      return childRegionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getChildRegionInfoOrBuilderList() {
      return childRegionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    public int getChildRegionInfoCount() {
      return childRegionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getChildRegionInfo(int index) {
      return childRegionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getChildRegionInfoOrBuilder(
        int index) {
      return childRegionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasParentRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getParentRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getChildRegionInfoCount(); i++) {
        if (!getChildRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getParentRegionInfo());
      }
      for (int i = 0; i < childRegionInfo_.size(); i++) {
        output.writeMessage(3, childRegionInfo_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getParentRegionInfo());
      }
      for (int i = 0; i < childRegionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, childRegionInfo_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasParentRegionInfo() == other.hasParentRegionInfo());
      if (hasParentRegionInfo()) {
        result = result && getParentRegionInfo()
            .equals(other.getParentRegionInfo());
      }
      result = result && getChildRegionInfoList()
          .equals(other.getChildRegionInfoList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasParentRegionInfo()) {
        hash = (37 * hash) + PARENT_REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getParentRegionInfo().hashCode();
      }
      if (getChildRegionInfoCount() > 0) {
        hash = (37 * hash) + CHILD_REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getChildRegionInfoList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SplitTableRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SplitTableRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getParentRegionInfoFieldBuilder();
          getChildRegionInfoFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (parentRegionInfoBuilder_ == null) {
          parentRegionInfo_ = null;
        } else {
          parentRegionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (childRegionInfoBuilder_ == null) {
          childRegionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          childRegionInfoBuilder_.clear();
        }
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (parentRegionInfoBuilder_ == null) {
          result.parentRegionInfo_ = parentRegionInfo_;
        } else {
          result.parentRegionInfo_ = parentRegionInfoBuilder_.build();
        }
        if (childRegionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            childRegionInfo_ = java.util.Collections.unmodifiableList(childRegionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.childRegionInfo_ = childRegionInfo_;
        } else {
          result.childRegionInfo_ = childRegionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasParentRegionInfo()) {
          mergeParentRegionInfo(other.getParentRegionInfo());
        }
        if (childRegionInfoBuilder_ == null) {
          if (!other.childRegionInfo_.isEmpty()) {
            if (childRegionInfo_.isEmpty()) {
              childRegionInfo_ = other.childRegionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureChildRegionInfoIsMutable();
              childRegionInfo_.addAll(other.childRegionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.childRegionInfo_.isEmpty()) {
            if (childRegionInfoBuilder_.isEmpty()) {
              childRegionInfoBuilder_.dispose();
              childRegionInfoBuilder_ = null;
              childRegionInfo_ = other.childRegionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              childRegionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getChildRegionInfoFieldBuilder() : null;
            } else {
              childRegionInfoBuilder_.addAllMessages(other.childRegionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasParentRegionInfo()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getParentRegionInfo().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getChildRegionInfoCount(); i++) {
          if (!getChildRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentRegionInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> parentRegionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public boolean hasParentRegionInfo() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentRegionInfo() {
        if (parentRegionInfoBuilder_ == null) {
          return parentRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentRegionInfo_;
        } else {
          return parentRegionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public Builder setParentRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          parentRegionInfo_ = value;
          onChanged();
        } else {
          parentRegionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public Builder setParentRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentRegionInfoBuilder_ == null) {
          parentRegionInfo_ = builderForValue.build();
          onChanged();
        } else {
          parentRegionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public Builder mergeParentRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentRegionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              parentRegionInfo_ != null &&
              parentRegionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            parentRegionInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(parentRegionInfo_).mergeFrom(value).buildPartial();
          } else {
            parentRegionInfo_ = value;
          }
          onChanged();
        } else {
          parentRegionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public Builder clearParentRegionInfo() {
        if (parentRegionInfoBuilder_ == null) {
          parentRegionInfo_ = null;
          onChanged();
        } else {
          parentRegionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getParentRegionInfoBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getParentRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentRegionInfoOrBuilder() {
        if (parentRegionInfoBuilder_ != null) {
          return parentRegionInfoBuilder_.getMessageOrBuilder();
        } else {
          return parentRegionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentRegionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getParentRegionInfoFieldBuilder() {
        if (parentRegionInfoBuilder_ == null) {
          parentRegionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getParentRegionInfo(),
                  getParentForChildren(),
                  isClean());
          parentRegionInfo_ = null;
        }
        return parentRegionInfoBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> childRegionInfo_ =
        java.util.Collections.emptyList();
      private void ensureChildRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          childRegionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(childRegionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> childRegionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getChildRegionInfoList() {
        if (childRegionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(childRegionInfo_);
        } else {
          return childRegionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public int getChildRegionInfoCount() {
        if (childRegionInfoBuilder_ == null) {
          return childRegionInfo_.size();
        } else {
          return childRegionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getChildRegionInfo(int index) {
        if (childRegionInfoBuilder_ == null) {
          return childRegionInfo_.get(index);
        } else {
          return childRegionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder setChildRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (childRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.set(index, value);
          onChanged();
        } else {
          childRegionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder setChildRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          childRegionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addChildRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (childRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.add(value);
          onChanged();
        } else {
          childRegionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addChildRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (childRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.add(index, value);
          onChanged();
        } else {
          childRegionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addChildRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          childRegionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addChildRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          childRegionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addAllChildRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, childRegionInfo_);
          onChanged();
        } else {
          childRegionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder clearChildRegionInfo() {
        if (childRegionInfoBuilder_ == null) {
          childRegionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          childRegionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder removeChildRegionInfo(int index) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.remove(index);
          onChanged();
        } else {
          childRegionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getChildRegionInfoBuilder(
          int index) {
        return getChildRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getChildRegionInfoOrBuilder(
          int index) {
        if (childRegionInfoBuilder_ == null) {
          return childRegionInfo_.get(index);  } else {
          return childRegionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getChildRegionInfoOrBuilderList() {
        if (childRegionInfoBuilder_ != null) {
          return childRegionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(childRegionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addChildRegionInfoBuilder() {
        return getChildRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addChildRegionInfoBuilder(
          int index) {
        return getChildRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getChildRegionInfoBuilderList() {
        return getChildRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getChildRegionInfoFieldBuilder() {
        if (childRegionInfoBuilder_ == null) {
          childRegionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  childRegionInfo_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          childRegionInfo_ = null;
        }
        return childRegionInfoBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SplitTableRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SplitTableRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitTableRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SplitTableRegionStateData>() {
      public SplitTableRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new SplitTableRegionStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitTableRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitTableRegionStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MergeTableRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MergeTableRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);

    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     */
    boolean hasMergedRegionInfo();
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedRegionInfo();
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedRegionInfoOrBuilder();

    /**
     * <code>optional bool forcible = 4 [default = false];</code>
     */
    boolean hasForcible();
    /**
     * <code>optional bool forcible = 4 [default = false];</code>
     */
    boolean getForcible();
  }
  /**
   * Protobuf type {@code hbase.pb.MergeTableRegionsStateData}
   */
  @javax.annotation.Generated("proto") public  static final class MergeTableRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MergeTableRegionsStateData)
      MergeTableRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MergeTableRegionsStateData.newBuilder() to construct.
    private MergeTableRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MergeTableRegionsStateData() {
      regionInfo_ = java.util.Collections.emptyList();
      forcible_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private MergeTableRegionsStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000002;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = mergedRegionInfo_.toBuilder();
              }
              mergedRegionInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(mergedRegionInfo_);
                mergedRegionInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000004;
              forcible_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    public static final int MERGED_REGION_INFO_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedRegionInfo_;
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     */
    public boolean hasMergedRegionInfo() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedRegionInfo() {
      return mergedRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedRegionInfo_;
    }
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedRegionInfoOrBuilder() {
      return mergedRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedRegionInfo_;
    }

    public static final int FORCIBLE_FIELD_NUMBER = 4;
    private boolean forcible_;
    /**
     * <code>optional bool forcible = 4 [default = false];</code>
     */
    public boolean hasForcible() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool forcible = 4 [default = false];</code>
     */
    public boolean getForcible() {
      return forcible_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasMergedRegionInfo()) {
        if (!getMergedRegionInfo().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getUserInfo());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(2, regionInfo_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(3, getMergedRegionInfo());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(4, forcible_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, regionInfo_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getMergedRegionInfo());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, forcible_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result && (hasMergedRegionInfo() == other.hasMergedRegionInfo());
      if (hasMergedRegionInfo()) {
        result = result && getMergedRegionInfo()
            .equals(other.getMergedRegionInfo());
      }
      result = result && (hasForcible() == other.hasForcible());
      if (hasForcible()) {
        result = result && (getForcible()
            == other.getForcible());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      if (hasMergedRegionInfo()) {
        hash = (37 * hash) + MERGED_REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getMergedRegionInfo().hashCode();
      }
      if (hasForcible()) {
        hash = (37 * hash) + FORCIBLE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForcible());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MergeTableRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MergeTableRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getRegionInfoFieldBuilder();
          getMergedRegionInfoFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          regionInfoBuilder_.clear();
        }
        if (mergedRegionInfoBuilder_ == null) {
          mergedRegionInfo_ = null;
        } else {
          mergedRegionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        forcible_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        if (mergedRegionInfoBuilder_ == null) {
          result.mergedRegionInfo_ = mergedRegionInfo_;
        } else {
          result.mergedRegionInfo_ = mergedRegionInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        result.forcible_ = forcible_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000002);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        if (other.hasMergedRegionInfo()) {
          mergeMergedRegionInfo(other.getMergedRegionInfo());
        }
        if (other.hasForcible()) {
          setForcible(other.getForcible());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        if (hasMergedRegionInfo()) {
          if (!getMergedRegionInfo().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedRegionInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> mergedRegionInfoBuilder_;
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public boolean hasMergedRegionInfo() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedRegionInfo() {
        if (mergedRegionInfoBuilder_ == null) {
          return mergedRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedRegionInfo_;
        } else {
          return mergedRegionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public Builder setMergedRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mergedRegionInfo_ = value;
          onChanged();
        } else {
          mergedRegionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public Builder setMergedRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (mergedRegionInfoBuilder_ == null) {
          mergedRegionInfo_ = builderForValue.build();
          onChanged();
        } else {
          mergedRegionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public Builder mergeMergedRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedRegionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              mergedRegionInfo_ != null &&
              mergedRegionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            mergedRegionInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(mergedRegionInfo_).mergeFrom(value).buildPartial();
          } else {
            mergedRegionInfo_ = value;
          }
          onChanged();
        } else {
          mergedRegionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public Builder clearMergedRegionInfo() {
        if (mergedRegionInfoBuilder_ == null) {
          mergedRegionInfo_ = null;
          onChanged();
        } else {
          mergedRegionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getMergedRegionInfoBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getMergedRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedRegionInfoOrBuilder() {
        if (mergedRegionInfoBuilder_ != null) {
          return mergedRegionInfoBuilder_.getMessageOrBuilder();
        } else {
          return mergedRegionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedRegionInfo_;
        }
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getMergedRegionInfoFieldBuilder() {
        if (mergedRegionInfoBuilder_ == null) {
          mergedRegionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getMergedRegionInfo(),
                  getParentForChildren(),
                  isClean());
          mergedRegionInfo_ = null;
        }
        return mergedRegionInfoBuilder_;
      }

      private boolean forcible_ ;
      /**
       * <code>optional bool forcible = 4 [default = false];</code>
       */
      public boolean hasForcible() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional bool forcible = 4 [default = false];</code>
       */
      public boolean getForcible() {
        return forcible_;
      }
      /**
       * <code>optional bool forcible = 4 [default = false];</code>
       */
      public Builder setForcible(boolean value) {
        bitField0_ |= 0x00000008;
        forcible_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool forcible = 4 [default = false];</code>
       */
      public Builder clearForcible() {
        bitField0_ = (bitField0_ & ~0x00000008);
        forcible_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MergeTableRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MergeTableRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MergeTableRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MergeTableRegionsStateData>() {
      public MergeTableRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new MergeTableRegionsStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MergeTableRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MergeTableRegionsStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ServerCrashStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ServerCrashStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    boolean hasServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder();

    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionsOnCrashedServerList();
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index);
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    int getRegionsOnCrashedServerCount();
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsOnCrashedServerOrBuilderList();
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionsAssignedList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    int getRegionsAssignedCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsAssignedOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
        int index);

    /**
     * <code>optional bool carrying_meta = 5;</code>
     */
    boolean hasCarryingMeta();
    /**
     * <code>optional bool carrying_meta = 5;</code>
     */
    boolean getCarryingMeta();

    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     */
    boolean hasShouldSplitWal();
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     */
    boolean getShouldSplitWal();
  }
  /**
   * Protobuf type {@code hbase.pb.ServerCrashStateData}
   */
  @javax.annotation.Generated("proto") public  static final class ServerCrashStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ServerCrashStateData)
      ServerCrashStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ServerCrashStateData.newBuilder() to construct.
    private ServerCrashStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ServerCrashStateData() {
      regionsOnCrashedServer_ = java.util.Collections.emptyList();
      regionsAssigned_ = java.util.Collections.emptyList();
      carryingMeta_ = false;
      shouldSplitWal_ = true;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ServerCrashStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = serverName_.toBuilder();
              }
              serverName_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(serverName_);
                serverName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                regionsOnCrashedServer_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000002;
              }
              regionsOnCrashedServer_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                regionsAssigned_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionsAssigned_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 40: {
              bitField0_ |= 0x00000002;
              carryingMeta_ = input.readBool();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000004;
              shouldSplitWal_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          regionsOnCrashedServer_ = java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          regionsAssigned_ = java.util.Collections.unmodifiableList(regionsAssigned_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.Builder.class);
    }

    private int bitField0_;
    public static final int SERVER_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    public boolean hasServerName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }

    public static final int REGIONS_ON_CRASHED_SERVER_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionsOnCrashedServer_;
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionsOnCrashedServerList() {
      return regionsOnCrashedServer_;
    }
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsOnCrashedServerOrBuilderList() {
      return regionsOnCrashedServer_;
    }
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public int getRegionsOnCrashedServerCount() {
      return regionsOnCrashedServer_.size();
    }
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index) {
      return regionsOnCrashedServer_.get(index);
    }
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
        int index) {
      return regionsOnCrashedServer_.get(index);
    }

    public static final int REGIONS_ASSIGNED_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionsAssigned_;
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionsAssignedList() {
      return regionsAssigned_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsAssignedOrBuilderList() {
      return regionsAssigned_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public int getRegionsAssignedCount() {
      return regionsAssigned_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index) {
      return regionsAssigned_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
        int index) {
      return regionsAssigned_.get(index);
    }

    public static final int CARRYING_META_FIELD_NUMBER = 5;
    private boolean carryingMeta_;
    /**
     * <code>optional bool carrying_meta = 5;</code>
     */
    public boolean hasCarryingMeta() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool carrying_meta = 5;</code>
     */
    public boolean getCarryingMeta() {
      return carryingMeta_;
    }

    public static final int SHOULD_SPLIT_WAL_FIELD_NUMBER = 6;
    private boolean shouldSplitWal_;
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     */
    public boolean hasShouldSplitWal() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     */
    public boolean getShouldSplitWal() {
      return shouldSplitWal_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasServerName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServerName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionsOnCrashedServerCount(); i++) {
        if (!getRegionsOnCrashedServer(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionsAssignedCount(); i++) {
        if (!getRegionsAssigned(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getServerName());
      }
      for (int i = 0; i < regionsOnCrashedServer_.size(); i++) {
        output.writeMessage(3, regionsOnCrashedServer_.get(i));
      }
      for (int i = 0; i < regionsAssigned_.size(); i++) {
        output.writeMessage(4, regionsAssigned_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(5, carryingMeta_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(6, shouldSplitWal_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getServerName());
      }
      for (int i = 0; i < regionsOnCrashedServer_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionsOnCrashedServer_.get(i));
      }
      for (int i = 0; i < regionsAssigned_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionsAssigned_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, carryingMeta_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, shouldSplitWal_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) obj;

      boolean result = true;
      result = result && (hasServerName() == other.hasServerName());
      if (hasServerName()) {
        result = result && getServerName()
            .equals(other.getServerName());
      }
      result = result && getRegionsOnCrashedServerList()
          .equals(other.getRegionsOnCrashedServerList());
      result = result && getRegionsAssignedList()
          .equals(other.getRegionsAssignedList());
      result = result && (hasCarryingMeta() == other.hasCarryingMeta());
      if (hasCarryingMeta()) {
        result = result && (getCarryingMeta()
            == other.getCarryingMeta());
      }
      result = result && (hasShouldSplitWal() == other.hasShouldSplitWal());
      if (hasShouldSplitWal()) {
        result = result && (getShouldSplitWal()
            == other.getShouldSplitWal());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasServerName()) {
        hash = (37 * hash) + SERVER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServerName().hashCode();
      }
      if (getRegionsOnCrashedServerCount() > 0) {
        hash = (37 * hash) + REGIONS_ON_CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsOnCrashedServerList().hashCode();
      }
      if (getRegionsAssignedCount() > 0) {
        hash = (37 * hash) + REGIONS_ASSIGNED_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsAssignedList().hashCode();
      }
      if (hasCarryingMeta()) {
        hash = (37 * hash) + CARRYING_META_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getCarryingMeta());
      }
      if (hasShouldSplitWal()) {
        hash = (37 * hash) + SHOULD_SPLIT_WAL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getShouldSplitWal());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ServerCrashStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ServerCrashStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServerNameFieldBuilder();
          getRegionsOnCrashedServerFieldBuilder();
          getRegionsAssignedFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (serverNameBuilder_ == null) {
          serverName_ = null;
        } else {
          serverNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServer_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          regionsOnCrashedServerBuilder_.clear();
        }
        if (regionsAssignedBuilder_ == null) {
          regionsAssigned_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionsAssignedBuilder_.clear();
        }
        carryingMeta_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        shouldSplitWal_ = true;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (serverNameBuilder_ == null) {
          result.serverName_ = serverName_;
        } else {
          result.serverName_ = serverNameBuilder_.build();
        }
        if (regionsOnCrashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            regionsOnCrashedServer_ = java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.regionsOnCrashedServer_ = regionsOnCrashedServer_;
        } else {
          result.regionsOnCrashedServer_ = regionsOnCrashedServerBuilder_.build();
        }
        if (regionsAssignedBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            regionsAssigned_ = java.util.Collections.unmodifiableList(regionsAssigned_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionsAssigned_ = regionsAssigned_;
        } else {
          result.regionsAssigned_ = regionsAssignedBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000002;
        }
        result.carryingMeta_ = carryingMeta_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        result.shouldSplitWal_ = shouldSplitWal_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.getDefaultInstance()) return this;
        if (other.hasServerName()) {
          mergeServerName(other.getServerName());
        }
        if (regionsOnCrashedServerBuilder_ == null) {
          if (!other.regionsOnCrashedServer_.isEmpty()) {
            if (regionsOnCrashedServer_.isEmpty()) {
              regionsOnCrashedServer_ = other.regionsOnCrashedServer_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureRegionsOnCrashedServerIsMutable();
              regionsOnCrashedServer_.addAll(other.regionsOnCrashedServer_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsOnCrashedServer_.isEmpty()) {
            if (regionsOnCrashedServerBuilder_.isEmpty()) {
              regionsOnCrashedServerBuilder_.dispose();
              regionsOnCrashedServerBuilder_ = null;
              regionsOnCrashedServer_ = other.regionsOnCrashedServer_;
              bitField0_ = (bitField0_ & ~0x00000002);
              regionsOnCrashedServerBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionsOnCrashedServerFieldBuilder() : null;
            } else {
              regionsOnCrashedServerBuilder_.addAllMessages(other.regionsOnCrashedServer_);
            }
          }
        }
        if (regionsAssignedBuilder_ == null) {
          if (!other.regionsAssigned_.isEmpty()) {
            if (regionsAssigned_.isEmpty()) {
              regionsAssigned_ = other.regionsAssigned_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionsAssignedIsMutable();
              regionsAssigned_.addAll(other.regionsAssigned_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsAssigned_.isEmpty()) {
            if (regionsAssignedBuilder_.isEmpty()) {
              regionsAssignedBuilder_.dispose();
              regionsAssignedBuilder_ = null;
              regionsAssigned_ = other.regionsAssigned_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionsAssignedBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionsAssignedFieldBuilder() : null;
            } else {
              regionsAssignedBuilder_.addAllMessages(other.regionsAssigned_);
            }
          }
        }
        if (other.hasCarryingMeta()) {
          setCarryingMeta(other.getCarryingMeta());
        }
        if (other.hasShouldSplitWal()) {
          setShouldSplitWal(other.getShouldSplitWal());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasServerName()) {
          return false;
        }
        if (!getServerName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionsOnCrashedServerCount(); i++) {
          if (!getRegionsOnCrashedServer(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionsAssignedCount(); i++) {
          if (!getRegionsAssigned(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverNameBuilder_;
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public boolean hasServerName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
        if (serverNameBuilder_ == null) {
          return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        } else {
          return serverNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverName_ = value;
          onChanged();
        } else {
          serverNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          serverName_ = builderForValue.build();
          onChanged();
        } else {
          serverNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder mergeServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              serverName_ != null &&
              serverName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            serverName_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(serverName_).mergeFrom(value).buildPartial();
          } else {
            serverName_ = value;
          }
          onChanged();
        } else {
          serverNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder clearServerName() {
        if (serverNameBuilder_ == null) {
          serverName_ = null;
          onChanged();
        } else {
          serverNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getServerNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
        if (serverNameBuilder_ != null) {
          return serverNameBuilder_.getMessageOrBuilder();
        } else {
          return serverName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerNameFieldBuilder() {
        if (serverNameBuilder_ == null) {
          serverNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getServerName(),
                  getParentForChildren(),
                  isClean());
          serverName_ = null;
        }
        return serverNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionsOnCrashedServer_ =
        java.util.Collections.emptyList();
      private void ensureRegionsOnCrashedServerIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          regionsOnCrashedServer_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionsOnCrashedServer_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionsOnCrashedServerBuilder_;

      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionsOnCrashedServerList() {
        if (regionsOnCrashedServerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        } else {
          return regionsOnCrashedServerBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public int getRegionsOnCrashedServerCount() {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.size();
        } else {
          return regionsOnCrashedServerBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.get(index);
        } else {
          return regionsOnCrashedServerBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder setRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.set(index, value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder setRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(index, value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addAllRegionsOnCrashedServer(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionsOnCrashedServer_);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder clearRegionsOnCrashedServer() {
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServer_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder removeRegionsOnCrashedServer(int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.remove(index);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionsOnCrashedServerBuilder(
          int index) {
        return getRegionsOnCrashedServerFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
          int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.get(index);  } else {
          return regionsOnCrashedServerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionsOnCrashedServerOrBuilderList() {
        if (regionsOnCrashedServerBuilder_ != null) {
          return regionsOnCrashedServerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsOnCrashedServerBuilder() {
        return getRegionsOnCrashedServerFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsOnCrashedServerBuilder(
          int index) {
        return getRegionsOnCrashedServerFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionsOnCrashedServerBuilderList() {
        return getRegionsOnCrashedServerFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionsOnCrashedServerFieldBuilder() {
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionsOnCrashedServer_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          regionsOnCrashedServer_ = null;
        }
        return regionsOnCrashedServerBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionsAssigned_ =
        java.util.Collections.emptyList();
      private void ensureRegionsAssignedIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          regionsAssigned_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionsAssigned_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionsAssignedBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionsAssignedList() {
        if (regionsAssignedBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsAssigned_);
        } else {
          return regionsAssignedBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public int getRegionsAssignedCount() {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.size();
        } else {
          return regionsAssignedBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index) {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.get(index);
        } else {
          return regionsAssignedBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder setRegionsAssigned(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.set(index, value);
          onChanged();
        } else {
          regionsAssignedBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder setRegionsAssigned(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(value);
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(index, value);
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addAllRegionsAssigned(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionsAssigned_);
          onChanged();
        } else {
          regionsAssignedBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder clearRegionsAssigned() {
        if (regionsAssignedBuilder_ == null) {
          regionsAssigned_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionsAssignedBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder removeRegionsAssigned(int index) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.remove(index);
          onChanged();
        } else {
          regionsAssignedBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionsAssignedBuilder(
          int index) {
        return getRegionsAssignedFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
          int index) {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.get(index);  } else {
          return regionsAssignedBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionsAssignedOrBuilderList() {
        if (regionsAssignedBuilder_ != null) {
          return regionsAssignedBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsAssigned_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsAssignedBuilder() {
        return getRegionsAssignedFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsAssignedBuilder(
          int index) {
        return getRegionsAssignedFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionsAssignedBuilderList() {
        return getRegionsAssignedFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionsAssignedFieldBuilder() {
        if (regionsAssignedBuilder_ == null) {
          regionsAssignedBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionsAssigned_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          regionsAssigned_ = null;
        }
        return regionsAssignedBuilder_;
      }

      private boolean carryingMeta_ ;
      /**
       * <code>optional bool carrying_meta = 5;</code>
       */
      public boolean hasCarryingMeta() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       */
      public boolean getCarryingMeta() {
        return carryingMeta_;
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       */
      public Builder setCarryingMeta(boolean value) {
        bitField0_ |= 0x00000008;
        carryingMeta_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       */
      public Builder clearCarryingMeta() {
        bitField0_ = (bitField0_ & ~0x00000008);
        carryingMeta_ = false;
        onChanged();
        return this;
      }

      private boolean shouldSplitWal_ = true;
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       */
      public boolean hasShouldSplitWal() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       */
      public boolean getShouldSplitWal() {
        return shouldSplitWal_;
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       */
      public Builder setShouldSplitWal(boolean value) {
        bitField0_ |= 0x00000010;
        shouldSplitWal_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       */
      public Builder clearShouldSplitWal() {
        bitField0_ = (bitField0_ & ~0x00000010);
        shouldSplitWal_ = true;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ServerCrashStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ServerCrashStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerCrashStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ServerCrashStateData>() {
      public ServerCrashStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new ServerCrashStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerCrashStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerCrashStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RecoverMetaStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RecoverMetaStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     */
    boolean hasFailedMetaServer();
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFailedMetaServer();
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFailedMetaServerOrBuilder();

    /**
     * <code>optional bool should_split_wal = 2 [default = true];</code>
     */
    boolean hasShouldSplitWal();
    /**
     * <code>optional bool should_split_wal = 2 [default = true];</code>
     */
    boolean getShouldSplitWal();

    /**
     * <code>optional int32 replica_id = 3 [default = 0];</code>
     */
    boolean hasReplicaId();
    /**
     * <code>optional int32 replica_id = 3 [default = 0];</code>
     */
    int getReplicaId();
  }
  /**
   * Protobuf type {@code hbase.pb.RecoverMetaStateData}
   */
  @javax.annotation.Generated("proto") public  static final class RecoverMetaStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RecoverMetaStateData)
      RecoverMetaStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RecoverMetaStateData.newBuilder() to construct.
    private RecoverMetaStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecoverMetaStateData() {
      shouldSplitWal_ = true;
      replicaId_ = 0;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RecoverMetaStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = failedMetaServer_.toBuilder();
              }
              failedMetaServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(failedMetaServer_);
                failedMetaServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              shouldSplitWal_ = input.readBool();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              replicaId_ = input.readInt32();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.Builder.class);
    }

    private int bitField0_;
    public static final int FAILED_META_SERVER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName failedMetaServer_;
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     */
    public boolean hasFailedMetaServer() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFailedMetaServer() {
      return failedMetaServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : failedMetaServer_;
    }
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFailedMetaServerOrBuilder() {
      return failedMetaServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : failedMetaServer_;
    }

    public static final int SHOULD_SPLIT_WAL_FIELD_NUMBER = 2;
    private boolean shouldSplitWal_;
    /**
     * <code>optional bool should_split_wal = 2 [default = true];</code>
     */
    public boolean hasShouldSplitWal() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool should_split_wal = 2 [default = true];</code>
     */
    public boolean getShouldSplitWal() {
      return shouldSplitWal_;
    }

    public static final int REPLICA_ID_FIELD_NUMBER = 3;
    private int replicaId_;
    /**
     * <code>optional int32 replica_id = 3 [default = 0];</code>
     */
    public boolean hasReplicaId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 replica_id = 3 [default = 0];</code>
     */
    public int getReplicaId() {
      return replicaId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasFailedMetaServer()) {
        if (!getFailedMetaServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getFailedMetaServer());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, shouldSplitWal_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, replicaId_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFailedMetaServer());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, shouldSplitWal_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, replicaId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData) obj;

      boolean result = true;
      result = result && (hasFailedMetaServer() == other.hasFailedMetaServer());
      if (hasFailedMetaServer()) {
        result = result && getFailedMetaServer()
            .equals(other.getFailedMetaServer());
      }
      result = result && (hasShouldSplitWal() == other.hasShouldSplitWal());
      if (hasShouldSplitWal()) {
        result = result && (getShouldSplitWal()
            == other.getShouldSplitWal());
      }
      result = result && (hasReplicaId() == other.hasReplicaId());
      if (hasReplicaId()) {
        result = result && (getReplicaId()
            == other.getReplicaId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFailedMetaServer()) {
        hash = (37 * hash) + FAILED_META_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getFailedMetaServer().hashCode();
      }
      if (hasShouldSplitWal()) {
        hash = (37 * hash) + SHOULD_SPLIT_WAL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getShouldSplitWal());
      }
      if (hasReplicaId()) {
        hash = (37 * hash) + REPLICA_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReplicaId();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RecoverMetaStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RecoverMetaStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getFailedMetaServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (failedMetaServerBuilder_ == null) {
          failedMetaServer_ = null;
        } else {
          failedMetaServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        shouldSplitWal_ = true;
        bitField0_ = (bitField0_ & ~0x00000002);
        replicaId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (failedMetaServerBuilder_ == null) {
          result.failedMetaServer_ = failedMetaServer_;
        } else {
          result.failedMetaServer_ = failedMetaServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.shouldSplitWal_ = shouldSplitWal_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.replicaId_ = replicaId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.getDefaultInstance()) return this;
        if (other.hasFailedMetaServer()) {
          mergeFailedMetaServer(other.getFailedMetaServer());
        }
        if (other.hasShouldSplitWal()) {
          setShouldSplitWal(other.getShouldSplitWal());
        }
        if (other.hasReplicaId()) {
          setReplicaId(other.getReplicaId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasFailedMetaServer()) {
          if (!getFailedMetaServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName failedMetaServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> failedMetaServerBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public boolean hasFailedMetaServer() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFailedMetaServer() {
        if (failedMetaServerBuilder_ == null) {
          return failedMetaServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : failedMetaServer_;
        } else {
          return failedMetaServerBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public Builder setFailedMetaServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (failedMetaServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          failedMetaServer_ = value;
          onChanged();
        } else {
          failedMetaServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public Builder setFailedMetaServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (failedMetaServerBuilder_ == null) {
          failedMetaServer_ = builderForValue.build();
          onChanged();
        } else {
          failedMetaServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public Builder mergeFailedMetaServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (failedMetaServerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              failedMetaServer_ != null &&
              failedMetaServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            failedMetaServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(failedMetaServer_).mergeFrom(value).buildPartial();
          } else {
            failedMetaServer_ = value;
          }
          onChanged();
        } else {
          failedMetaServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public Builder clearFailedMetaServer() {
        if (failedMetaServerBuilder_ == null) {
          failedMetaServer_ = null;
          onChanged();
        } else {
          failedMetaServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getFailedMetaServerBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFailedMetaServerFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFailedMetaServerOrBuilder() {
        if (failedMetaServerBuilder_ != null) {
          return failedMetaServerBuilder_.getMessageOrBuilder();
        } else {
          return failedMetaServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : failedMetaServer_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getFailedMetaServerFieldBuilder() {
        if (failedMetaServerBuilder_ == null) {
          failedMetaServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getFailedMetaServer(),
                  getParentForChildren(),
                  isClean());
          failedMetaServer_ = null;
        }
        return failedMetaServerBuilder_;
      }

      private boolean shouldSplitWal_ = true;
      /**
       * <code>optional bool should_split_wal = 2 [default = true];</code>
       */
      public boolean hasShouldSplitWal() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool should_split_wal = 2 [default = true];</code>
       */
      public boolean getShouldSplitWal() {
        return shouldSplitWal_;
      }
      /**
       * <code>optional bool should_split_wal = 2 [default = true];</code>
       */
      public Builder setShouldSplitWal(boolean value) {
        bitField0_ |= 0x00000002;
        shouldSplitWal_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_split_wal = 2 [default = true];</code>
       */
      public Builder clearShouldSplitWal() {
        bitField0_ = (bitField0_ & ~0x00000002);
        shouldSplitWal_ = true;
        onChanged();
        return this;
      }

      private int replicaId_ ;
      /**
       * <code>optional int32 replica_id = 3 [default = 0];</code>
       */
      public boolean hasReplicaId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 replica_id = 3 [default = 0];</code>
       */
      public int getReplicaId() {
        return replicaId_;
      }
      /**
       * <code>optional int32 replica_id = 3 [default = 0];</code>
       */
      public Builder setReplicaId(int value) {
        bitField0_ |= 0x00000004;
        replicaId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 replica_id = 3 [default = 0];</code>
       */
      public Builder clearReplicaId() {
        bitField0_ = (bitField0_ & ~0x00000004);
        replicaId_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RecoverMetaStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RecoverMetaStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverMetaStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RecoverMetaStateData>() {
      public RecoverMetaStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RecoverMetaStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverMetaStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverMetaStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AssignRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.AssignRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     */
    boolean hasTransitionState();
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState();

    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    boolean hasRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();

    /**
     * <code>optional bool force_new_plan = 3 [default = false];</code>
     */
    boolean hasForceNewPlan();
    /**
     * <code>optional bool force_new_plan = 3 [default = false];</code>
     */
    boolean getForceNewPlan();

    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     */
    boolean hasTargetServer();
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 5;</code>
     */
    boolean hasAttempt();
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 5;</code>
     */
    int getAttempt();
  }
  /**
   * Protobuf type {@code hbase.pb.AssignRegionStateData}
   */
  @javax.annotation.Generated("proto") public  static final class AssignRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.AssignRegionStateData)
      AssignRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use AssignRegionStateData.newBuilder() to construct.
    private AssignRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AssignRegionStateData() {
      transitionState_ = 1;
      forceNewPlan_ = false;
      attempt_ = 0;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private AssignRegionStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState value = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                transitionState_ = rawValue;
              }
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = regionInfo_.toBuilder();
              }
              regionInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(regionInfo_);
                regionInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              forceNewPlan_ = input.readBool();
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = targetServer_.toBuilder();
              }
              targetServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(targetServer_);
                targetServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              attempt_ = input.readInt32();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TRANSITION_STATE_FIELD_NUMBER = 1;
    private int transitionState_;
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     */
    public boolean hasTransitionState() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.valueOf(transitionState_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.REGION_TRANSITION_QUEUE : result;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    public static final int FORCE_NEW_PLAN_FIELD_NUMBER = 3;
    private boolean forceNewPlan_;
    /**
     * <code>optional bool force_new_plan = 3 [default = false];</code>
     */
    public boolean hasForceNewPlan() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool force_new_plan = 3 [default = false];</code>
     */
    public boolean getForceNewPlan() {
      return forceNewPlan_;
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     */
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int ATTEMPT_FIELD_NUMBER = 5;
    private int attempt_;
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 5;</code>
     */
    public boolean hasAttempt() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 5;</code>
     */
    public int getAttempt() {
      return attempt_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTransitionState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasTargetServer()) {
        if (!getTargetServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, transitionState_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getRegionInfo());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, forceNewPlan_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, getTargetServer());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt32(5, attempt_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, transitionState_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getRegionInfo());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, forceNewPlan_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getTargetServer());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, attempt_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData) obj;

      boolean result = true;
      result = result && (hasTransitionState() == other.hasTransitionState());
      if (hasTransitionState()) {
        result = result && transitionState_ == other.transitionState_;
      }
      result = result && (hasRegionInfo() == other.hasRegionInfo());
      if (hasRegionInfo()) {
        result = result && getRegionInfo()
            .equals(other.getRegionInfo());
      }
      result = result && (hasForceNewPlan() == other.hasForceNewPlan());
      if (hasForceNewPlan()) {
        result = result && (getForceNewPlan()
            == other.getForceNewPlan());
      }
      result = result && (hasTargetServer() == other.hasTargetServer());
      if (hasTargetServer()) {
        result = result && getTargetServer()
            .equals(other.getTargetServer());
      }
      result = result && (hasAttempt() == other.hasAttempt());
      if (hasAttempt()) {
        result = result && (getAttempt()
            == other.getAttempt());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTransitionState()) {
        hash = (37 * hash) + TRANSITION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + transitionState_;
      }
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      if (hasForceNewPlan()) {
        hash = (37 * hash) + FORCE_NEW_PLAN_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForceNewPlan());
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasAttempt()) {
        hash = (37 * hash) + ATTEMPT_FIELD_NUMBER;
        hash = (53 * hash) + getAttempt();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.AssignRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.AssignRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
          getTargetServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        transitionState_ = 1;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = null;
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        forceNewPlan_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        attempt_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.transitionState_ = transitionState_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (regionInfoBuilder_ == null) {
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.forceNewPlan_ = forceNewPlan_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (targetServerBuilder_ == null) {
          result.targetServer_ = targetServer_;
        } else {
          result.targetServer_ = targetServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.attempt_ = attempt_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.getDefaultInstance()) return this;
        if (other.hasTransitionState()) {
          setTransitionState(other.getTransitionState());
        }
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        if (other.hasForceNewPlan()) {
          setForceNewPlan(other.getForceNewPlan());
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasAttempt()) {
          setAttempt(other.getAttempt());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasTransitionState()) {
          return false;
        }
        if (!hasRegionInfo()) {
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          return false;
        }
        if (hasTargetServer()) {
          if (!getTargetServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int transitionState_ = 1;
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       */
      public boolean hasTransitionState() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.valueOf(transitionState_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.REGION_TRANSITION_QUEUE : result;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       */
      public Builder setTransitionState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        transitionState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       */
      public Builder clearTransitionState() {
        bitField0_ = (bitField0_ & ~0x00000001);
        transitionState_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              regionInfo_ != null &&
              regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            regionInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(regionInfo_).mergeFrom(value).buildPartial();
          } else {
            regionInfo_ = value;
          }
          onChanged();
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = null;
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private boolean forceNewPlan_ ;
      /**
       * <code>optional bool force_new_plan = 3 [default = false];</code>
       */
      public boolean hasForceNewPlan() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bool force_new_plan = 3 [default = false];</code>
       */
      public boolean getForceNewPlan() {
        return forceNewPlan_;
      }
      /**
       * <code>optional bool force_new_plan = 3 [default = false];</code>
       */
      public Builder setForceNewPlan(boolean value) {
        bitField0_ |= 0x00000004;
        forceNewPlan_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool force_new_plan = 3 [default = false];</code>
       */
      public Builder clearForceNewPlan() {
        bitField0_ = (bitField0_ & ~0x00000004);
        forceNewPlan_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
          onChanged();
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
          onChanged();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              targetServer_ != null &&
              targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            targetServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(targetServer_).mergeFrom(value).buildPartial();
          } else {
            targetServer_ = value;
          }
          onChanged();
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public Builder clearTargetServer() {
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
          onChanged();
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private int attempt_ ;
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 5;</code>
       */
      public boolean hasAttempt() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 5;</code>
       */
      public int getAttempt() {
        return attempt_;
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 5;</code>
       */
      public Builder setAttempt(int value) {
        bitField0_ |= 0x00000010;
        attempt_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 5;</code>
       */
      public Builder clearAttempt() {
        bitField0_ = (bitField0_ & ~0x00000010);
        attempt_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.AssignRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.AssignRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<AssignRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<AssignRegionStateData>() {
      public AssignRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new AssignRegionStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<AssignRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<AssignRegionStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UnassignRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.UnassignRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     */
    boolean hasTransitionState();
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState();

    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    boolean hasRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();

    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    boolean hasDestinationServer();
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer();
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder();

    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     */
    boolean hasHostingServer();
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getHostingServer();
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getHostingServerOrBuilder();

    /**
     * <code>optional bool force = 4 [default = false];</code>
     */
    boolean hasForce();
    /**
     * <code>optional bool force = 4 [default = false];</code>
     */
    boolean getForce();

    /**
     * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
     */
    boolean hasRemoveAfterUnassigning();
    /**
     * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
     */
    boolean getRemoveAfterUnassigning();

    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 7;</code>
     */
    boolean hasAttempt();
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 7;</code>
     */
    int getAttempt();
  }
  /**
   * Protobuf type {@code hbase.pb.UnassignRegionStateData}
   */
  @javax.annotation.Generated("proto") public  static final class UnassignRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.UnassignRegionStateData)
      UnassignRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use UnassignRegionStateData.newBuilder() to construct.
    private UnassignRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UnassignRegionStateData() {
      transitionState_ = 1;
      force_ = false;
      removeAfterUnassigning_ = false;
      attempt_ = 0;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private UnassignRegionStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState value = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                transitionState_ = rawValue;
              }
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = regionInfo_.toBuilder();
              }
              regionInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(regionInfo_);
                regionInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = destinationServer_.toBuilder();
              }
              destinationServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(destinationServer_);
                destinationServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000010;
              force_ = input.readBool();
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = hostingServer_.toBuilder();
              }
              hostingServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(hostingServer_);
                hostingServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              removeAfterUnassigning_ = input.readBool();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              attempt_ = input.readInt32();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TRANSITION_STATE_FIELD_NUMBER = 1;
    private int transitionState_;
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     */
    public boolean hasTransitionState() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.valueOf(transitionState_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.REGION_TRANSITION_QUEUE : result;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    public static final int DESTINATION_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_;
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    public boolean hasDestinationServer() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }

    public static final int HOSTING_SERVER_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName hostingServer_;
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     */
    public boolean hasHostingServer() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getHostingServer() {
      return hostingServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : hostingServer_;
    }
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getHostingServerOrBuilder() {
      return hostingServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : hostingServer_;
    }

    public static final int FORCE_FIELD_NUMBER = 4;
    private boolean force_;
    /**
     * <code>optional bool force = 4 [default = false];</code>
     */
    public boolean hasForce() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool force = 4 [default = false];</code>
     */
    public boolean getForce() {
      return force_;
    }

    public static final int REMOVE_AFTER_UNASSIGNING_FIELD_NUMBER = 6;
    private boolean removeAfterUnassigning_;
    /**
     * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
     */
    public boolean hasRemoveAfterUnassigning() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
     */
    public boolean getRemoveAfterUnassigning() {
      return removeAfterUnassigning_;
    }

    public static final int ATTEMPT_FIELD_NUMBER = 7;
    private int attempt_;
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 7;</code>
     */
    public boolean hasAttempt() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 7;</code>
     */
    public int getAttempt() {
      return attempt_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTransitionState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasDestinationServer()) {
        if (!getDestinationServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasHostingServer()) {
        if (!getHostingServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, transitionState_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getRegionInfo());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getDestinationServer());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(4, force_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(5, getHostingServer());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBool(6, removeAfterUnassigning_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeInt32(7, attempt_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, transitionState_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getRegionInfo());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getDestinationServer());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, force_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getHostingServer());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, removeAfterUnassigning_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(7, attempt_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData) obj;

      boolean result = true;
      result = result && (hasTransitionState() == other.hasTransitionState());
      if (hasTransitionState()) {
        result = result && transitionState_ == other.transitionState_;
      }
      result = result && (hasRegionInfo() == other.hasRegionInfo());
      if (hasRegionInfo()) {
        result = result && getRegionInfo()
            .equals(other.getRegionInfo());
      }
      result = result && (hasDestinationServer() == other.hasDestinationServer());
      if (hasDestinationServer()) {
        result = result && getDestinationServer()
            .equals(other.getDestinationServer());
      }
      result = result && (hasHostingServer() == other.hasHostingServer());
      if (hasHostingServer()) {
        result = result && getHostingServer()
            .equals(other.getHostingServer());
      }
      result = result && (hasForce() == other.hasForce());
      if (hasForce()) {
        result = result && (getForce()
            == other.getForce());
      }
      result = result && (hasRemoveAfterUnassigning() == other.hasRemoveAfterUnassigning());
      if (hasRemoveAfterUnassigning()) {
        result = result && (getRemoveAfterUnassigning()
            == other.getRemoveAfterUnassigning());
      }
      result = result && (hasAttempt() == other.hasAttempt());
      if (hasAttempt()) {
        result = result && (getAttempt()
            == other.getAttempt());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTransitionState()) {
        hash = (37 * hash) + TRANSITION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + transitionState_;
      }
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      if (hasDestinationServer()) {
        hash = (37 * hash) + DESTINATION_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getDestinationServer().hashCode();
      }
      if (hasHostingServer()) {
        hash = (37 * hash) + HOSTING_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getHostingServer().hashCode();
      }
      if (hasForce()) {
        hash = (37 * hash) + FORCE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForce());
      }
      if (hasRemoveAfterUnassigning()) {
        hash = (37 * hash) + REMOVE_AFTER_UNASSIGNING_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRemoveAfterUnassigning());
      }
      if (hasAttempt()) {
        hash = (37 * hash) + ATTEMPT_FIELD_NUMBER;
        hash = (53 * hash) + getAttempt();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UnassignRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.UnassignRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
          getDestinationServerFieldBuilder();
          getHostingServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        transitionState_ = 1;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = null;
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (destinationServerBuilder_ == null) {
          destinationServer_ = null;
        } else {
          destinationServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (hostingServerBuilder_ == null) {
          hostingServer_ = null;
        } else {
          hostingServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        force_ = false;
        bitField0_ = (bitField0_ & ~0x00000010);
        removeAfterUnassigning_ = false;
        bitField0_ = (bitField0_ & ~0x00000020);
        attempt_ = 0;
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.transitionState_ = transitionState_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (regionInfoBuilder_ == null) {
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (destinationServerBuilder_ == null) {
          result.destinationServer_ = destinationServer_;
        } else {
          result.destinationServer_ = destinationServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (hostingServerBuilder_ == null) {
          result.hostingServer_ = hostingServer_;
        } else {
          result.hostingServer_ = hostingServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.force_ = force_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.removeAfterUnassigning_ = removeAfterUnassigning_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.attempt_ = attempt_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.getDefaultInstance()) return this;
        if (other.hasTransitionState()) {
          setTransitionState(other.getTransitionState());
        }
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        if (other.hasDestinationServer()) {
          mergeDestinationServer(other.getDestinationServer());
        }
        if (other.hasHostingServer()) {
          mergeHostingServer(other.getHostingServer());
        }
        if (other.hasForce()) {
          setForce(other.getForce());
        }
        if (other.hasRemoveAfterUnassigning()) {
          setRemoveAfterUnassigning(other.getRemoveAfterUnassigning());
        }
        if (other.hasAttempt()) {
          setAttempt(other.getAttempt());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasTransitionState()) {
          return false;
        }
        if (!hasRegionInfo()) {
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          return false;
        }
        if (hasDestinationServer()) {
          if (!getDestinationServer().isInitialized()) {
            return false;
          }
        }
        if (hasHostingServer()) {
          if (!getHostingServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int transitionState_ = 1;
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       */
      public boolean hasTransitionState() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.valueOf(transitionState_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.REGION_TRANSITION_QUEUE : result;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       */
      public Builder setTransitionState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        transitionState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       */
      public Builder clearTransitionState() {
        bitField0_ = (bitField0_ & ~0x00000001);
        transitionState_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              regionInfo_ != null &&
              regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            regionInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(regionInfo_).mergeFrom(value).buildPartial();
          } else {
            regionInfo_ = value;
          }
          onChanged();
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = null;
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> destinationServerBuilder_;
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public boolean hasDestinationServer() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
        if (destinationServerBuilder_ == null) {
          return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        } else {
          return destinationServerBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder setDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          destinationServer_ = value;
          onChanged();
        } else {
          destinationServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder setDestinationServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (destinationServerBuilder_ == null) {
          destinationServer_ = builderForValue.build();
          onChanged();
        } else {
          destinationServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder mergeDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              destinationServer_ != null &&
              destinationServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            destinationServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(destinationServer_).mergeFrom(value).buildPartial();
          } else {
            destinationServer_ = value;
          }
          onChanged();
        } else {
          destinationServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder clearDestinationServer() {
        if (destinationServerBuilder_ == null) {
          destinationServer_ = null;
          onChanged();
        } else {
          destinationServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getDestinationServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getDestinationServerFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
        if (destinationServerBuilder_ != null) {
          return destinationServerBuilder_.getMessageOrBuilder();
        } else {
          return destinationServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        }
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getDestinationServerFieldBuilder() {
        if (destinationServerBuilder_ == null) {
          destinationServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getDestinationServer(),
                  getParentForChildren(),
                  isClean());
          destinationServer_ = null;
        }
        return destinationServerBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName hostingServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> hostingServerBuilder_;
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public boolean hasHostingServer() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getHostingServer() {
        if (hostingServerBuilder_ == null) {
          return hostingServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : hostingServer_;
        } else {
          return hostingServerBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public Builder setHostingServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (hostingServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          hostingServer_ = value;
          onChanged();
        } else {
          hostingServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public Builder setHostingServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (hostingServerBuilder_ == null) {
          hostingServer_ = builderForValue.build();
          onChanged();
        } else {
          hostingServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public Builder mergeHostingServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (hostingServerBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              hostingServer_ != null &&
              hostingServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            hostingServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(hostingServer_).mergeFrom(value).buildPartial();
          } else {
            hostingServer_ = value;
          }
          onChanged();
        } else {
          hostingServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public Builder clearHostingServer() {
        if (hostingServerBuilder_ == null) {
          hostingServer_ = null;
          onChanged();
        } else {
          hostingServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getHostingServerBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getHostingServerFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getHostingServerOrBuilder() {
        if (hostingServerBuilder_ != null) {
          return hostingServerBuilder_.getMessageOrBuilder();
        } else {
          return hostingServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : hostingServer_;
        }
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getHostingServerFieldBuilder() {
        if (hostingServerBuilder_ == null) {
          hostingServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getHostingServer(),
                  getParentForChildren(),
                  isClean());
          hostingServer_ = null;
        }
        return hostingServerBuilder_;
      }

      private boolean force_ ;
      /**
       * <code>optional bool force = 4 [default = false];</code>
       */
      public boolean hasForce() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool force = 4 [default = false];</code>
       */
      public boolean getForce() {
        return force_;
      }
      /**
       * <code>optional bool force = 4 [default = false];</code>
       */
      public Builder setForce(boolean value) {
        bitField0_ |= 0x00000010;
        force_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool force = 4 [default = false];</code>
       */
      public Builder clearForce() {
        bitField0_ = (bitField0_ & ~0x00000010);
        force_ = false;
        onChanged();
        return this;
      }

      private boolean removeAfterUnassigning_ ;
      /**
       * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
       */
      public boolean hasRemoveAfterUnassigning() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
       */
      public boolean getRemoveAfterUnassigning() {
        return removeAfterUnassigning_;
      }
      /**
       * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
       */
      public Builder setRemoveAfterUnassigning(boolean value) {
        bitField0_ |= 0x00000020;
        removeAfterUnassigning_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
       */
      public Builder clearRemoveAfterUnassigning() {
        bitField0_ = (bitField0_ & ~0x00000020);
        removeAfterUnassigning_ = false;
        onChanged();
        return this;
      }

      private int attempt_ ;
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 7;</code>
       */
      public boolean hasAttempt() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 7;</code>
       */
      public int getAttempt() {
        return attempt_;
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 7;</code>
       */
      public Builder setAttempt(int value) {
        bitField0_ |= 0x00000040;
        attempt_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 7;</code>
       */
      public Builder clearAttempt() {
        bitField0_ = (bitField0_ & ~0x00000040);
        attempt_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.UnassignRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UnassignRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<UnassignRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<UnassignRegionStateData>() {
      public UnassignRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new UnassignRegionStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<UnassignRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<UnassignRegionStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MoveRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MoveRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     */
    boolean hasRegionInfo();
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();

    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     */
    boolean hasSourceServer();
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getSourceServer();
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getSourceServerOrBuilder();

    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    boolean hasDestinationServer();
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer();
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.MoveRegionStateData}
   */
  @javax.annotation.Generated("proto") public  static final class MoveRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MoveRegionStateData)
      MoveRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MoveRegionStateData.newBuilder() to construct.
    private MoveRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MoveRegionStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private MoveRegionStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = regionInfo_.toBuilder();
              }
              regionInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(regionInfo_);
                regionInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = sourceServer_.toBuilder();
              }
              sourceServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(sourceServer_);
                sourceServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = destinationServer_.toBuilder();
              }
              destinationServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(destinationServer_);
                destinationServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     */
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    public static final int SOURCE_SERVER_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName sourceServer_;
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     */
    public boolean hasSourceServer() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getSourceServer() {
      return sourceServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : sourceServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getSourceServerOrBuilder() {
      return sourceServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : sourceServer_;
    }

    public static final int DESTINATION_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_;
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    public boolean hasDestinationServer() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasSourceServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasRegionInfo()) {
        if (!getRegionInfo().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getSourceServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasDestinationServer()) {
        if (!getDestinationServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getRegionInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getSourceServer());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getDestinationServer());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegionInfo());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getSourceServer());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getDestinationServer());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData) obj;

      boolean result = true;
      result = result && (hasRegionInfo() == other.hasRegionInfo());
      if (hasRegionInfo()) {
        result = result && getRegionInfo()
            .equals(other.getRegionInfo());
      }
      result = result && (hasSourceServer() == other.hasSourceServer());
      if (hasSourceServer()) {
        result = result && getSourceServer()
            .equals(other.getSourceServer());
      }
      result = result && (hasDestinationServer() == other.hasDestinationServer());
      if (hasDestinationServer()) {
        result = result && getDestinationServer()
            .equals(other.getDestinationServer());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      if (hasSourceServer()) {
        hash = (37 * hash) + SOURCE_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getSourceServer().hashCode();
      }
      if (hasDestinationServer()) {
        hash = (37 * hash) + DESTINATION_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getDestinationServer().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MoveRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MoveRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
          getSourceServerFieldBuilder();
          getDestinationServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (regionInfoBuilder_ == null) {
          regionInfo_ = null;
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (sourceServerBuilder_ == null) {
          sourceServer_ = null;
        } else {
          sourceServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (destinationServerBuilder_ == null) {
          destinationServer_ = null;
        } else {
          destinationServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionInfoBuilder_ == null) {
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (sourceServerBuilder_ == null) {
          result.sourceServer_ = sourceServer_;
        } else {
          result.sourceServer_ = sourceServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (destinationServerBuilder_ == null) {
          result.destinationServer_ = destinationServer_;
        } else {
          result.destinationServer_ = destinationServerBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.getDefaultInstance()) return this;
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        if (other.hasSourceServer()) {
          mergeSourceServer(other.getSourceServer());
        }
        if (other.hasDestinationServer()) {
          mergeDestinationServer(other.getDestinationServer());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasSourceServer()) {
          return false;
        }
        if (hasRegionInfo()) {
          if (!getRegionInfo().isInitialized()) {
            return false;
          }
        }
        if (!getSourceServer().isInitialized()) {
          return false;
        }
        if (hasDestinationServer()) {
          if (!getDestinationServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              regionInfo_ != null &&
              regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            regionInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(regionInfo_).mergeFrom(value).buildPartial();
          } else {
            regionInfo_ = value;
          }
          onChanged();
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = null;
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName sourceServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> sourceServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public boolean hasSourceServer() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getSourceServer() {
        if (sourceServerBuilder_ == null) {
          return sourceServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : sourceServer_;
        } else {
          return sourceServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public Builder setSourceServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (sourceServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          sourceServer_ = value;
          onChanged();
        } else {
          sourceServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public Builder setSourceServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (sourceServerBuilder_ == null) {
          sourceServer_ = builderForValue.build();
          onChanged();
        } else {
          sourceServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public Builder mergeSourceServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (sourceServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              sourceServer_ != null &&
              sourceServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            sourceServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(sourceServer_).mergeFrom(value).buildPartial();
          } else {
            sourceServer_ = value;
          }
          onChanged();
        } else {
          sourceServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public Builder clearSourceServer() {
        if (sourceServerBuilder_ == null) {
          sourceServer_ = null;
          onChanged();
        } else {
          sourceServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getSourceServerBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getSourceServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getSourceServerOrBuilder() {
        if (sourceServerBuilder_ != null) {
          return sourceServerBuilder_.getMessageOrBuilder();
        } else {
          return sourceServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : sourceServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getSourceServerFieldBuilder() {
        if (sourceServerBuilder_ == null) {
          sourceServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getSourceServer(),
                  getParentForChildren(),
                  isClean());
          sourceServer_ = null;
        }
        return sourceServerBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> destinationServerBuilder_;
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public boolean hasDestinationServer() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
        if (destinationServerBuilder_ == null) {
          return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        } else {
          return destinationServerBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder setDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          destinationServer_ = value;
          onChanged();
        } else {
          destinationServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder setDestinationServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (destinationServerBuilder_ == null) {
          destinationServer_ = builderForValue.build();
          onChanged();
        } else {
          destinationServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder mergeDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              destinationServer_ != null &&
              destinationServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            destinationServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(destinationServer_).mergeFrom(value).buildPartial();
          } else {
            destinationServer_ = value;
          }
          onChanged();
        } else {
          destinationServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder clearDestinationServer() {
        if (destinationServerBuilder_ == null) {
          destinationServer_ = null;
          onChanged();
        } else {
          destinationServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getDestinationServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getDestinationServerFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
        if (destinationServerBuilder_ != null) {
          return destinationServerBuilder_.getMessageOrBuilder();
        } else {
          return destinationServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        }
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getDestinationServerFieldBuilder() {
        if (destinationServerBuilder_ == null) {
          destinationServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getDestinationServer(),
                  getParentForChildren(),
                  isClean());
          destinationServer_ = null;
        }
        return destinationServerBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MoveRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MoveRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MoveRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MoveRegionStateData>() {
      public MoveRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new MoveRegionStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MoveRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MoveRegionStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GCRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GCRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    boolean hasRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GCRegionStateData}
   */
  @javax.annotation.Generated("proto") public  static final class GCRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GCRegionStateData)
      GCRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GCRegionStateData.newBuilder() to construct.
    private GCRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GCRegionStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GCRegionStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = regionInfo_.toBuilder();
              }
              regionInfo_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(regionInfo_);
                regionInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getRegionInfo());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegionInfo());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData) obj;

      boolean result = true;
      result = result && (hasRegionInfo() == other.hasRegionInfo());
      if (hasRegionInfo()) {
        result = result && getRegionInfo()
            .equals(other.getRegionInfo());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GCRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GCRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (regionInfoBuilder_ == null) {
          regionInfo_ = null;
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionInfoBuilder_ == null) {
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.getDefaultInstance()) return this;
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegionInfo()) {
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              regionInfo_ != null &&
              regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            regionInfo_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(regionInfo_).mergeFrom(value).buildPartial();
          } else {
            regionInfo_ = value;
          }
          onChanged();
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = null;
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GCRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GCRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GCRegionStateData>() {
      public GCRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new GCRegionStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCRegionStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  @java.lang.Deprecated public interface GCMergedRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GCMergedRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     */
    boolean hasParentA();
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentA();
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentAOrBuilder();

    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     */
    boolean hasParentB();
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentB();
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentBOrBuilder();

    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     */
    boolean hasMergedChild();
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild();
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GCMergedRegionsStateData}
   */
  @java.lang.Deprecated @javax.annotation.Generated("proto") public  static final class GCMergedRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GCMergedRegionsStateData)
      GCMergedRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GCMergedRegionsStateData.newBuilder() to construct.
    private GCMergedRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GCMergedRegionsStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GCMergedRegionsStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = parentA_.toBuilder();
              }
              parentA_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(parentA_);
                parentA_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = parentB_.toBuilder();
              }
              parentB_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(parentB_);
                parentB_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = mergedChild_.toBuilder();
              }
              mergedChild_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(mergedChild_);
                mergedChild_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PARENT_A_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentA_;
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     */
    public boolean hasParentA() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentA() {
      return parentA_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentA_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentAOrBuilder() {
      return parentA_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentA_;
    }

    public static final int PARENT_B_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentB_;
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     */
    public boolean hasParentB() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentB() {
      return parentB_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentB_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentBOrBuilder() {
      return parentB_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentB_;
    }

    public static final int MERGED_CHILD_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedChild_;
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     */
    public boolean hasMergedChild() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild() {
      return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder() {
      return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasParentA()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasParentB()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMergedChild()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getParentA().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getParentB().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getMergedChild().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getParentA());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getParentB());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getMergedChild());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getParentA());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getParentB());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getMergedChild());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData) obj;

      boolean result = true;
      result = result && (hasParentA() == other.hasParentA());
      if (hasParentA()) {
        result = result && getParentA()
            .equals(other.getParentA());
      }
      result = result && (hasParentB() == other.hasParentB());
      if (hasParentB()) {
        result = result && getParentB()
            .equals(other.getParentB());
      }
      result = result && (hasMergedChild() == other.hasMergedChild());
      if (hasMergedChild()) {
        result = result && getMergedChild()
            .equals(other.getMergedChild());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasParentA()) {
        hash = (37 * hash) + PARENT_A_FIELD_NUMBER;
        hash = (53 * hash) + getParentA().hashCode();
      }
      if (hasParentB()) {
        hash = (37 * hash) + PARENT_B_FIELD_NUMBER;
        hash = (53 * hash) + getParentB().hashCode();
      }
      if (hasMergedChild()) {
        hash = (37 * hash) + MERGED_CHILD_FIELD_NUMBER;
        hash = (53 * hash) + getMergedChild().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GCMergedRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GCMergedRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getParentAFieldBuilder();
          getParentBFieldBuilder();
          getMergedChildFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (parentABuilder_ == null) {
          parentA_ = null;
        } else {
          parentABuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (parentBBuilder_ == null) {
          parentB_ = null;
        } else {
          parentBBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (mergedChildBuilder_ == null) {
          mergedChild_ = null;
        } else {
          mergedChildBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (parentABuilder_ == null) {
          result.parentA_ = parentA_;
        } else {
          result.parentA_ = parentABuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (parentBBuilder_ == null) {
          result.parentB_ = parentB_;
        } else {
          result.parentB_ = parentBBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (mergedChildBuilder_ == null) {
          result.mergedChild_ = mergedChild_;
        } else {
          result.mergedChild_ = mergedChildBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.getDefaultInstance()) return this;
        if (other.hasParentA()) {
          mergeParentA(other.getParentA());
        }
        if (other.hasParentB()) {
          mergeParentB(other.getParentB());
        }
        if (other.hasMergedChild()) {
          mergeMergedChild(other.getMergedChild());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasParentA()) {
          return false;
        }
        if (!hasParentB()) {
          return false;
        }
        if (!hasMergedChild()) {
          return false;
        }
        if (!getParentA().isInitialized()) {
          return false;
        }
        if (!getParentB().isInitialized()) {
          return false;
        }
        if (!getMergedChild().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentA_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> parentABuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public boolean hasParentA() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentA() {
        if (parentABuilder_ == null) {
          return parentA_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentA_;
        } else {
          return parentABuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public Builder setParentA(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentABuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          parentA_ = value;
          onChanged();
        } else {
          parentABuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public Builder setParentA(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentABuilder_ == null) {
          parentA_ = builderForValue.build();
          onChanged();
        } else {
          parentABuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public Builder mergeParentA(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentABuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              parentA_ != null &&
              parentA_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            parentA_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(parentA_).mergeFrom(value).buildPartial();
          } else {
            parentA_ = value;
          }
          onChanged();
        } else {
          parentABuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public Builder clearParentA() {
        if (parentABuilder_ == null) {
          parentA_ = null;
          onChanged();
        } else {
          parentABuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getParentABuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getParentAFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentAOrBuilder() {
        if (parentABuilder_ != null) {
          return parentABuilder_.getMessageOrBuilder();
        } else {
          return parentA_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentA_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getParentAFieldBuilder() {
        if (parentABuilder_ == null) {
          parentABuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getParentA(),
                  getParentForChildren(),
                  isClean());
          parentA_ = null;
        }
        return parentABuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentB_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> parentBBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public boolean hasParentB() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentB() {
        if (parentBBuilder_ == null) {
          return parentB_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentB_;
        } else {
          return parentBBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public Builder setParentB(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentBBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          parentB_ = value;
          onChanged();
        } else {
          parentBBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public Builder setParentB(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentBBuilder_ == null) {
          parentB_ = builderForValue.build();
          onChanged();
        } else {
          parentBBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public Builder mergeParentB(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentBBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              parentB_ != null &&
              parentB_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            parentB_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(parentB_).mergeFrom(value).buildPartial();
          } else {
            parentB_ = value;
          }
          onChanged();
        } else {
          parentBBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public Builder clearParentB() {
        if (parentBBuilder_ == null) {
          parentB_ = null;
          onChanged();
        } else {
          parentBBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getParentBBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getParentBFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentBOrBuilder() {
        if (parentBBuilder_ != null) {
          return parentBBuilder_.getMessageOrBuilder();
        } else {
          return parentB_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentB_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getParentBFieldBuilder() {
        if (parentBBuilder_ == null) {
          parentBBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getParentB(),
                  getParentForChildren(),
                  isClean());
          parentB_ = null;
        }
        return parentBBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedChild_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> mergedChildBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public boolean hasMergedChild() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild() {
        if (mergedChildBuilder_ == null) {
          return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
        } else {
          return mergedChildBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public Builder setMergedChild(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedChildBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mergedChild_ = value;
          onChanged();
        } else {
          mergedChildBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public Builder setMergedChild(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (mergedChildBuilder_ == null) {
          mergedChild_ = builderForValue.build();
          onChanged();
        } else {
          mergedChildBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public Builder mergeMergedChild(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedChildBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              mergedChild_ != null &&
              mergedChild_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            mergedChild_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(mergedChild_).mergeFrom(value).buildPartial();
          } else {
            mergedChild_ = value;
          }
          onChanged();
        } else {
          mergedChildBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public Builder clearMergedChild() {
        if (mergedChildBuilder_ == null) {
          mergedChild_ = null;
          onChanged();
        } else {
          mergedChildBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getMergedChildBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getMergedChildFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder() {
        if (mergedChildBuilder_ != null) {
          return mergedChildBuilder_.getMessageOrBuilder();
        } else {
          return mergedChild_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getMergedChildFieldBuilder() {
        if (mergedChildBuilder_ == null) {
          mergedChildBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getMergedChild(),
                  getParentForChildren(),
                  isClean());
          mergedChild_ = null;
        }
        return mergedChildBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GCMergedRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GCMergedRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMergedRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GCMergedRegionsStateData>() {
      public GCMergedRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new GCMergedRegionsStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMergedRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMergedRegionsStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GCMultipleMergedRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GCMultipleMergedRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getParentsList();
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParents(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    int getParentsCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getParentsOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentsOrBuilder(
        int index);

    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     */
    boolean hasMergedChild();
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild();
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GCMultipleMergedRegionsStateData}
   */
  @javax.annotation.Generated("proto") public  static final class GCMultipleMergedRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GCMultipleMergedRegionsStateData)
      GCMultipleMergedRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GCMultipleMergedRegionsStateData.newBuilder() to construct.
    private GCMultipleMergedRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GCMultipleMergedRegionsStateData() {
      parents_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GCMultipleMergedRegionsStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                parents_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000001;
              }
              parents_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = mergedChild_.toBuilder();
              }
              mergedChild_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(mergedChild_);
                mergedChild_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          parents_ = java.util.Collections.unmodifiableList(parents_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PARENTS_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> parents_;
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getParentsList() {
      return parents_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getParentsOrBuilderList() {
      return parents_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    public int getParentsCount() {
      return parents_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParents(int index) {
      return parents_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentsOrBuilder(
        int index) {
      return parents_.get(index);
    }

    public static final int MERGED_CHILD_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedChild_;
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     */
    public boolean hasMergedChild() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild() {
      return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder() {
      return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasMergedChild()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getParentsCount(); i++) {
        if (!getParents(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getMergedChild().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < parents_.size(); i++) {
        output.writeMessage(1, parents_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(2, getMergedChild());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < parents_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, parents_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getMergedChild());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData) obj;

      boolean result = true;
      result = result && getParentsList()
          .equals(other.getParentsList());
      result = result && (hasMergedChild() == other.hasMergedChild());
      if (hasMergedChild()) {
        result = result && getMergedChild()
            .equals(other.getMergedChild());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getParentsCount() > 0) {
        hash = (37 * hash) + PARENTS_FIELD_NUMBER;
        hash = (53 * hash) + getParentsList().hashCode();
      }
      if (hasMergedChild()) {
        hash = (37 * hash) + MERGED_CHILD_FIELD_NUMBER;
        hash = (53 * hash) + getMergedChild().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GCMultipleMergedRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GCMultipleMergedRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getParentsFieldBuilder();
          getMergedChildFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (parentsBuilder_ == null) {
          parents_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          parentsBuilder_.clear();
        }
        if (mergedChildBuilder_ == null) {
          mergedChild_ = null;
        } else {
          mergedChildBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (parentsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            parents_ = java.util.Collections.unmodifiableList(parents_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.parents_ = parents_;
        } else {
          result.parents_ = parentsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        if (mergedChildBuilder_ == null) {
          result.mergedChild_ = mergedChild_;
        } else {
          result.mergedChild_ = mergedChildBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.getDefaultInstance()) return this;
        if (parentsBuilder_ == null) {
          if (!other.parents_.isEmpty()) {
            if (parents_.isEmpty()) {
              parents_ = other.parents_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureParentsIsMutable();
              parents_.addAll(other.parents_);
            }
            onChanged();
          }
        } else {
          if (!other.parents_.isEmpty()) {
            if (parentsBuilder_.isEmpty()) {
              parentsBuilder_.dispose();
              parentsBuilder_ = null;
              parents_ = other.parents_;
              bitField0_ = (bitField0_ & ~0x00000001);
              parentsBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getParentsFieldBuilder() : null;
            } else {
              parentsBuilder_.addAllMessages(other.parents_);
            }
          }
        }
        if (other.hasMergedChild()) {
          mergeMergedChild(other.getMergedChild());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasMergedChild()) {
          return false;
        }
        for (int i = 0; i < getParentsCount(); i++) {
          if (!getParents(i).isInitialized()) {
            return false;
          }
        }
        if (!getMergedChild().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> parents_ =
        java.util.Collections.emptyList();
      private void ensureParentsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          parents_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(parents_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> parentsBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getParentsList() {
        if (parentsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(parents_);
        } else {
          return parentsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public int getParentsCount() {
        if (parentsBuilder_ == null) {
          return parents_.size();
        } else {
          return parentsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParents(int index) {
        if (parentsBuilder_ == null) {
          return parents_.get(index);
        } else {
          return parentsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder setParents(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentsIsMutable();
          parents_.set(index, value);
          onChanged();
        } else {
          parentsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder setParents(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          parents_.set(index, builderForValue.build());
          onChanged();
        } else {
          parentsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addParents(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentsIsMutable();
          parents_.add(value);
          onChanged();
        } else {
          parentsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addParents(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentsIsMutable();
          parents_.add(index, value);
          onChanged();
        } else {
          parentsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addParents(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          parents_.add(builderForValue.build());
          onChanged();
        } else {
          parentsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addParents(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          parents_.add(index, builderForValue.build());
          onChanged();
        } else {
          parentsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addAllParents(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, parents_);
          onChanged();
        } else {
          parentsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder clearParents() {
        if (parentsBuilder_ == null) {
          parents_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          parentsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder removeParents(int index) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          parents_.remove(index);
          onChanged();
        } else {
          parentsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getParentsBuilder(
          int index) {
        return getParentsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentsOrBuilder(
          int index) {
        if (parentsBuilder_ == null) {
          return parents_.get(index);  } else {
          return parentsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getParentsOrBuilderList() {
        if (parentsBuilder_ != null) {
          return parentsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(parents_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addParentsBuilder() {
        return getParentsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addParentsBuilder(
          int index) {
        return getParentsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getParentsBuilderList() {
        return getParentsFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getParentsFieldBuilder() {
        if (parentsBuilder_ == null) {
          parentsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  parents_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          parents_ = null;
        }
        return parentsBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedChild_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> mergedChildBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public boolean hasMergedChild() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild() {
        if (mergedChildBuilder_ == null) {
          return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
        } else {
          return mergedChildBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public Builder setMergedChild(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedChildBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mergedChild_ = value;
          onChanged();
        } else {
          mergedChildBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public Builder setMergedChild(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (mergedChildBuilder_ == null) {
          mergedChild_ = builderForValue.build();
          onChanged();
        } else {
          mergedChildBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public Builder mergeMergedChild(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedChildBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              mergedChild_ != null &&
              mergedChild_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            mergedChild_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(mergedChild_).mergeFrom(value).buildPartial();
          } else {
            mergedChild_ = value;
          }
          onChanged();
        } else {
          mergedChildBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public Builder clearMergedChild() {
        if (mergedChildBuilder_ == null) {
          mergedChild_ = null;
          onChanged();
        } else {
          mergedChildBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getMergedChildBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMergedChildFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder() {
        if (mergedChildBuilder_ != null) {
          return mergedChildBuilder_.getMessageOrBuilder();
        } else {
          return mergedChild_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getMergedChildFieldBuilder() {
        if (mergedChildBuilder_ == null) {
          mergedChildBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getMergedChild(),
                  getParentForChildren(),
                  isClean());
          mergedChild_ = null;
        }
        return mergedChildBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GCMultipleMergedRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GCMultipleMergedRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMultipleMergedRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GCMultipleMergedRegionsStateData>() {
      public GCMultipleMergedRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new GCMultipleMergedRegionsStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMultipleMergedRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMultipleMergedRegionsStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PeerModificationStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.PeerModificationStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.PeerModificationStateData}
   */
  @javax.annotation.Generated("proto") public  static final class PeerModificationStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.PeerModificationStateData)
      PeerModificationStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PeerModificationStateData.newBuilder() to construct.
    private PeerModificationStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PeerModificationStateData() {
      peerId_ = "";
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PeerModificationStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              peerId_ = bs;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object peerId_;
    /**
     * <code>required string peer_id = 1;</code>
     */
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData) obj;

      boolean result = true;
      result = result && (hasPeerId() == other.hasPeerId());
      if (hasPeerId()) {
        result = result && getPeerId()
            .equals(other.getPeerId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.PeerModificationStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.PeerModificationStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        peerId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.peerId_ = peerId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          bitField0_ |= 0x00000001;
          peerId_ = other.peerId_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder clearPeerId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerId_ = getDefaultInstance().getPeerId();
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.PeerModificationStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.PeerModificationStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerModificationStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<PeerModificationStateData>() {
      public PeerModificationStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new PeerModificationStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerModificationStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerModificationStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RefreshPeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RefreshPeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();

    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     */
    boolean hasType();
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType();

    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <pre>
     ** We need multiple stages for sync replication state transition *
     * </pre>
     *
     * <code>optional uint32 stage = 4 [default = 0];</code>
     */
    boolean hasStage();
    /**
     * <pre>
     ** We need multiple stages for sync replication state transition *
     * </pre>
     *
     * <code>optional uint32 stage = 4 [default = 0];</code>
     */
    int getStage();
  }
  /**
   * Protobuf type {@code hbase.pb.RefreshPeerStateData}
   */
  @javax.annotation.Generated("proto") public  static final class RefreshPeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RefreshPeerStateData)
      RefreshPeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RefreshPeerStateData.newBuilder() to construct.
    private RefreshPeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RefreshPeerStateData() {
      peerId_ = "";
      type_ = 1;
      stage_ = 0;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RefreshPeerStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              peerId_ = bs;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType value = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                type_ = rawValue;
              }
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = targetServer_.toBuilder();
              }
              targetServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(targetServer_);
                targetServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              stage_ = input.readUInt32();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object peerId_;
    /**
     * <code>required string peer_id = 1;</code>
     */
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TYPE_FIELD_NUMBER = 2;
    private int type_;
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.valueOf(type_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.ADD_PEER : result;
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int STAGE_FIELD_NUMBER = 4;
    private int stage_;
    /**
     * <pre>
     ** We need multiple stages for sync replication state transition *
     * </pre>
     *
     * <code>optional uint32 stage = 4 [default = 0];</code>
     */
    public boolean hasStage() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <pre>
     ** We need multiple stages for sync replication state transition *
     * </pre>
     *
     * <code>optional uint32 stage = 4 [default = 0];</code>
     */
    public int getStage() {
      return stage_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, type_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getTargetServer());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(4, stage_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, type_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTargetServer());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, stage_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData) obj;

      boolean result = true;
      result = result && (hasPeerId() == other.hasPeerId());
      if (hasPeerId()) {
        result = result && getPeerId()
            .equals(other.getPeerId());
      }
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result && type_ == other.type_;
      }
      result = result && (hasTargetServer() == other.hasTargetServer());
      if (hasTargetServer()) {
        result = result && getTargetServer()
            .equals(other.getTargetServer());
      }
      result = result && (hasStage() == other.hasStage());
      if (hasStage()) {
        result = result && (getStage()
            == other.getStage());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasStage()) {
        hash = (37 * hash) + STAGE_FIELD_NUMBER;
        hash = (53 * hash) + getStage();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RefreshPeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RefreshPeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTargetServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        peerId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        stage_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.peerId_ = peerId_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (targetServerBuilder_ == null) {
          result.targetServer_ = targetServer_;
        } else {
          result.targetServer_ = targetServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.stage_ = stage_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          bitField0_ |= 0x00000001;
          peerId_ = other.peerId_;
          onChanged();
        }
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasStage()) {
          setStage(other.getStage());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        if (!hasType()) {
          return false;
        }
        if (!hasTargetServer()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder clearPeerId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerId_ = getDefaultInstance().getPeerId();
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }

      private int type_ = 1;
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.valueOf(type_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.ADD_PEER : result;
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       */
      public Builder setType(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        type_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
          onChanged();
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
          onChanged();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              targetServer_ != null &&
              targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            targetServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(targetServer_).mergeFrom(value).buildPartial();
          } else {
            targetServer_ = value;
          }
          onChanged();
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder clearTargetServer() {
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
          onChanged();
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private int stage_ ;
      /**
       * <pre>
       ** We need multiple stages for sync replication state transition *
       * </pre>
       *
       * <code>optional uint32 stage = 4 [default = 0];</code>
       */
      public boolean hasStage() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <pre>
       ** We need multiple stages for sync replication state transition *
       * </pre>
       *
       * <code>optional uint32 stage = 4 [default = 0];</code>
       */
      public int getStage() {
        return stage_;
      }
      /**
       * <pre>
       ** We need multiple stages for sync replication state transition *
       * </pre>
       *
       * <code>optional uint32 stage = 4 [default = 0];</code>
       */
      public Builder setStage(int value) {
        bitField0_ |= 0x00000008;
        stage_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       ** We need multiple stages for sync replication state transition *
       * </pre>
       *
       * <code>optional uint32 stage = 4 [default = 0];</code>
       */
      public Builder clearStage() {
        bitField0_ = (bitField0_ & ~0x00000008);
        stage_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RefreshPeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RefreshPeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RefreshPeerStateData>() {
      public RefreshPeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RefreshPeerStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RefreshPeerParameterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RefreshPeerParameter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();

    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     */
    boolean hasType();
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType();

    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <pre>
     ** We need multiple stages for sync replication state transition *
     * </pre>
     *
     * <code>optional uint32 stage = 4 [default = 0];</code>
     */
    boolean hasStage();
    /**
     * <pre>
     ** We need multiple stages for sync replication state transition *
     * </pre>
     *
     * <code>optional uint32 stage = 4 [default = 0];</code>
     */
    int getStage();
  }
  /**
   * Protobuf type {@code hbase.pb.RefreshPeerParameter}
   */
  @javax.annotation.Generated("proto") public  static final class RefreshPeerParameter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RefreshPeerParameter)
      RefreshPeerParameterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RefreshPeerParameter.newBuilder() to construct.
    private RefreshPeerParameter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RefreshPeerParameter() {
      peerId_ = "";
      type_ = 1;
      stage_ = 0;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RefreshPeerParameter(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              peerId_ = bs;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType value = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                type_ = rawValue;
              }
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = targetServer_.toBuilder();
              }
              targetServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(targetServer_);
                targetServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              stage_ = input.readUInt32();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object peerId_;
    /**
     * <code>required string peer_id = 1;</code>
     */
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TYPE_FIELD_NUMBER = 2;
    private int type_;
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.valueOf(type_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.ADD_PEER : result;
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int STAGE_FIELD_NUMBER = 4;
    private int stage_;
    /**
     * <pre>
     ** We need multiple stages for sync replication state transition *
     * </pre>
     *
     * <code>optional uint32 stage = 4 [default = 0];</code>
     */
    public boolean hasStage() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <pre>
     ** We need multiple stages for sync replication state transition *
     * </pre>
     *
     * <code>optional uint32 stage = 4 [default = 0];</code>
     */
    public int getStage() {
      return stage_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, type_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getTargetServer());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(4, stage_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, type_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTargetServer());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, stage_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter) obj;

      boolean result = true;
      result = result && (hasPeerId() == other.hasPeerId());
      if (hasPeerId()) {
        result = result && getPeerId()
            .equals(other.getPeerId());
      }
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result && type_ == other.type_;
      }
      result = result && (hasTargetServer() == other.hasTargetServer());
      if (hasTargetServer()) {
        result = result && getTargetServer()
            .equals(other.getTargetServer());
      }
      result = result && (hasStage() == other.hasStage());
      if (hasStage()) {
        result = result && (getStage()
            == other.getStage());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasStage()) {
        hash = (37 * hash) + STAGE_FIELD_NUMBER;
        hash = (53 * hash) + getStage();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RefreshPeerParameter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RefreshPeerParameter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTargetServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        peerId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        stage_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.peerId_ = peerId_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (targetServerBuilder_ == null) {
          result.targetServer_ = targetServer_;
        } else {
          result.targetServer_ = targetServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.stage_ = stage_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          bitField0_ |= 0x00000001;
          peerId_ = other.peerId_;
          onChanged();
        }
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasStage()) {
          setStage(other.getStage());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        if (!hasType()) {
          return false;
        }
        if (!hasTargetServer()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder clearPeerId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerId_ = getDefaultInstance().getPeerId();
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }

      private int type_ = 1;
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.valueOf(type_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.ADD_PEER : result;
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       */
      public Builder setType(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        type_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
          onChanged();
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
          onChanged();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              targetServer_ != null &&
              targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            targetServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(targetServer_).mergeFrom(value).buildPartial();
          } else {
            targetServer_ = value;
          }
          onChanged();
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder clearTargetServer() {
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
          onChanged();
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private int stage_ ;
      /**
       * <pre>
       ** We need multiple stages for sync replication state transition *
       * </pre>
       *
       * <code>optional uint32 stage = 4 [default = 0];</code>
       */
      public boolean hasStage() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <pre>
       ** We need multiple stages for sync replication state transition *
       * </pre>
       *
       * <code>optional uint32 stage = 4 [default = 0];</code>
       */
      public int getStage() {
        return stage_;
      }
      /**
       * <pre>
       ** We need multiple stages for sync replication state transition *
       * </pre>
       *
       * <code>optional uint32 stage = 4 [default = 0];</code>
       */
      public Builder setStage(int value) {
        bitField0_ |= 0x00000008;
        stage_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       ** We need multiple stages for sync replication state transition *
       * </pre>
       *
       * <code>optional uint32 stage = 4 [default = 0];</code>
       */
      public Builder clearStage() {
        bitField0_ = (bitField0_ & ~0x00000008);
        stage_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RefreshPeerParameter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RefreshPeerParameter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerParameter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RefreshPeerParameter>() {
      public RefreshPeerParameter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RefreshPeerParameter(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerParameter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerParameter> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PeerProcedureStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.PeerProcedureStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.PeerProcedureStateData}
   */
  @javax.annotation.Generated("proto") public  static final class PeerProcedureStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.PeerProcedureStateData)
      PeerProcedureStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PeerProcedureStateData.newBuilder() to construct.
    private PeerProcedureStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PeerProcedureStateData() {
      peerId_ = "";
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PeerProcedureStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              peerId_ = bs;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object peerId_;
    /**
     * <code>required string peer_id = 1;</code>
     */
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData) obj;

      boolean result = true;
      result = result && (hasPeerId() == other.hasPeerId());
      if (hasPeerId()) {
        result = result && getPeerId()
            .equals(other.getPeerId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.PeerProcedureStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.PeerProcedureStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        peerId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.peerId_ = peerId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          bitField0_ |= 0x00000001;
          peerId_ = other.peerId_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder clearPeerId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerId_ = getDefaultInstance().getPeerId();
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.PeerProcedureStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.PeerProcedureStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerProcedureStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<PeerProcedureStateData>() {
      public PeerProcedureStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new PeerProcedureStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerProcedureStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerProcedureStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AddPeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.AddPeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    boolean hasPeerConfig();
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig();
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder();

    /**
     * <code>required bool enabled = 2;</code>
     */
    boolean hasEnabled();
    /**
     * <code>required bool enabled = 2;</code>
     */
    boolean getEnabled();
  }
  /**
   * Protobuf type {@code hbase.pb.AddPeerStateData}
   */
  @javax.annotation.Generated("proto") public  static final class AddPeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.AddPeerStateData)
      AddPeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use AddPeerStateData.newBuilder() to construct.
    private AddPeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AddPeerStateData() {
      enabled_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private AddPeerStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = peerConfig_.toBuilder();
              }
              peerConfig_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(peerConfig_);
                peerConfig_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              enabled_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_CONFIG_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public boolean hasPeerConfig() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }

    public static final int ENABLED_FIELD_NUMBER = 2;
    private boolean enabled_;
    /**
     * <code>required bool enabled = 2;</code>
     */
    public boolean hasEnabled() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bool enabled = 2;</code>
     */
    public boolean getEnabled() {
      return enabled_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerConfig()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getPeerConfig().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getPeerConfig());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, enabled_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getPeerConfig());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, enabled_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData) obj;

      boolean result = true;
      result = result && (hasPeerConfig() == other.hasPeerConfig());
      if (hasPeerConfig()) {
        result = result && getPeerConfig()
            .equals(other.getPeerConfig());
      }
      result = result && (hasEnabled() == other.hasEnabled());
      if (hasEnabled()) {
        result = result && (getEnabled()
            == other.getEnabled());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerConfig()) {
        hash = (37 * hash) + PEER_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getPeerConfig().hashCode();
      }
      if (hasEnabled()) {
        hash = (37 * hash) + ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getEnabled());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.AddPeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.AddPeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getPeerConfigFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (peerConfigBuilder_ == null) {
          peerConfig_ = null;
        } else {
          peerConfigBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        enabled_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (peerConfigBuilder_ == null) {
          result.peerConfig_ = peerConfig_;
        } else {
          result.peerConfig_ = peerConfigBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.enabled_ = enabled_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.getDefaultInstance()) return this;
        if (other.hasPeerConfig()) {
          mergePeerConfig(other.getPeerConfig());
        }
        if (other.hasEnabled()) {
          setEnabled(other.getEnabled());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerConfig()) {
          return false;
        }
        if (!hasEnabled()) {
          return false;
        }
        if (!getPeerConfig().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> peerConfigBuilder_;
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public boolean hasPeerConfig() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
        if (peerConfigBuilder_ == null) {
          return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        } else {
          return peerConfigBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          peerConfig_ = value;
          onChanged();
        } else {
          peerConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder builderForValue) {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = builderForValue.build();
          onChanged();
        } else {
          peerConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder mergePeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              peerConfig_ != null &&
              peerConfig_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance()) {
            peerConfig_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.newBuilder(peerConfig_).mergeFrom(value).buildPartial();
          } else {
            peerConfig_ = value;
          }
          onChanged();
        } else {
          peerConfigBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder clearPeerConfig() {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = null;
          onChanged();
        } else {
          peerConfigBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder getPeerConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPeerConfigFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
        if (peerConfigBuilder_ != null) {
          return peerConfigBuilder_.getMessageOrBuilder();
        } else {
          return peerConfig_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        }
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> 
          getPeerConfigFieldBuilder() {
        if (peerConfigBuilder_ == null) {
          peerConfigBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder>(
                  getPeerConfig(),
                  getParentForChildren(),
                  isClean());
          peerConfig_ = null;
        }
        return peerConfigBuilder_;
      }

      private boolean enabled_ ;
      /**
       * <code>required bool enabled = 2;</code>
       */
      public boolean hasEnabled() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bool enabled = 2;</code>
       */
      public boolean getEnabled() {
        return enabled_;
      }
      /**
       * <code>required bool enabled = 2;</code>
       */
      public Builder setEnabled(boolean value) {
        bitField0_ |= 0x00000002;
        enabled_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool enabled = 2;</code>
       */
      public Builder clearEnabled() {
        bitField0_ = (bitField0_ & ~0x00000002);
        enabled_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.AddPeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.AddPeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<AddPeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<AddPeerStateData>() {
      public AddPeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new AddPeerStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<AddPeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<AddPeerStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UpdatePeerConfigStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.UpdatePeerConfigStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    boolean hasPeerConfig();
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig();
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder();

    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     */
    boolean hasOldPeerConfig();
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getOldPeerConfig();
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getOldPeerConfigOrBuilder();

    /**
     * <code>required bool enabled = 3;</code>
     */
    boolean hasEnabled();
    /**
     * <code>required bool enabled = 3;</code>
     */
    boolean getEnabled();
  }
  /**
   * Protobuf type {@code hbase.pb.UpdatePeerConfigStateData}
   */
  @javax.annotation.Generated("proto") public  static final class UpdatePeerConfigStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.UpdatePeerConfigStateData)
      UpdatePeerConfigStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use UpdatePeerConfigStateData.newBuilder() to construct.
    private UpdatePeerConfigStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UpdatePeerConfigStateData() {
      enabled_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private UpdatePeerConfigStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = peerConfig_.toBuilder();
              }
              peerConfig_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(peerConfig_);
                peerConfig_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = oldPeerConfig_.toBuilder();
              }
              oldPeerConfig_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(oldPeerConfig_);
                oldPeerConfig_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              enabled_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_CONFIG_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public boolean hasPeerConfig() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }

    public static final int OLD_PEER_CONFIG_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer oldPeerConfig_;
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     */
    public boolean hasOldPeerConfig() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getOldPeerConfig() {
      return oldPeerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : oldPeerConfig_;
    }
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getOldPeerConfigOrBuilder() {
      return oldPeerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : oldPeerConfig_;
    }

    public static final int ENABLED_FIELD_NUMBER = 3;
    private boolean enabled_;
    /**
     * <code>required bool enabled = 3;</code>
     */
    public boolean hasEnabled() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bool enabled = 3;</code>
     */
    public boolean getEnabled() {
      return enabled_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerConfig()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getPeerConfig().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasOldPeerConfig()) {
        if (!getOldPeerConfig().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getPeerConfig());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getOldPeerConfig());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, enabled_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getPeerConfig());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getOldPeerConfig());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, enabled_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData) obj;

      boolean result = true;
      result = result && (hasPeerConfig() == other.hasPeerConfig());
      if (hasPeerConfig()) {
        result = result && getPeerConfig()
            .equals(other.getPeerConfig());
      }
      result = result && (hasOldPeerConfig() == other.hasOldPeerConfig());
      if (hasOldPeerConfig()) {
        result = result && getOldPeerConfig()
            .equals(other.getOldPeerConfig());
      }
      result = result && (hasEnabled() == other.hasEnabled());
      if (hasEnabled()) {
        result = result && (getEnabled()
            == other.getEnabled());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerConfig()) {
        hash = (37 * hash) + PEER_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getPeerConfig().hashCode();
      }
      if (hasOldPeerConfig()) {
        hash = (37 * hash) + OLD_PEER_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getOldPeerConfig().hashCode();
      }
      if (hasEnabled()) {
        hash = (37 * hash) + ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getEnabled());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UpdatePeerConfigStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.UpdatePeerConfigStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getPeerConfigFieldBuilder();
          getOldPeerConfigFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (peerConfigBuilder_ == null) {
          peerConfig_ = null;
        } else {
          peerConfigBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (oldPeerConfigBuilder_ == null) {
          oldPeerConfig_ = null;
        } else {
          oldPeerConfigBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        enabled_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (peerConfigBuilder_ == null) {
          result.peerConfig_ = peerConfig_;
        } else {
          result.peerConfig_ = peerConfigBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (oldPeerConfigBuilder_ == null) {
          result.oldPeerConfig_ = oldPeerConfig_;
        } else {
          result.oldPeerConfig_ = oldPeerConfigBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.enabled_ = enabled_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.getDefaultInstance()) return this;
        if (other.hasPeerConfig()) {
          mergePeerConfig(other.getPeerConfig());
        }
        if (other.hasOldPeerConfig()) {
          mergeOldPeerConfig(other.getOldPeerConfig());
        }
        if (other.hasEnabled()) {
          setEnabled(other.getEnabled());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerConfig()) {
          return false;
        }
        if (!hasEnabled()) {
          return false;
        }
        if (!getPeerConfig().isInitialized()) {
          return false;
        }
        if (hasOldPeerConfig()) {
          if (!getOldPeerConfig().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> peerConfigBuilder_;
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public boolean hasPeerConfig() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
        if (peerConfigBuilder_ == null) {
          return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        } else {
          return peerConfigBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          peerConfig_ = value;
          onChanged();
        } else {
          peerConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder builderForValue) {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = builderForValue.build();
          onChanged();
        } else {
          peerConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder mergePeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              peerConfig_ != null &&
              peerConfig_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance()) {
            peerConfig_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.newBuilder(peerConfig_).mergeFrom(value).buildPartial();
          } else {
            peerConfig_ = value;
          }
          onChanged();
        } else {
          peerConfigBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder clearPeerConfig() {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = null;
          onChanged();
        } else {
          peerConfigBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder getPeerConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPeerConfigFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
        if (peerConfigBuilder_ != null) {
          return peerConfigBuilder_.getMessageOrBuilder();
        } else {
          return peerConfig_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        }
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> 
          getPeerConfigFieldBuilder() {
        if (peerConfigBuilder_ == null) {
          peerConfigBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder>(
                  getPeerConfig(),
                  getParentForChildren(),
                  isClean());
          peerConfig_ = null;
        }
        return peerConfigBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer oldPeerConfig_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> oldPeerConfigBuilder_;
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public boolean hasOldPeerConfig() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getOldPeerConfig() {
        if (oldPeerConfigBuilder_ == null) {
          return oldPeerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : oldPeerConfig_;
        } else {
          return oldPeerConfigBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public Builder setOldPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (oldPeerConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          oldPeerConfig_ = value;
          onChanged();
        } else {
          oldPeerConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public Builder setOldPeerConfig(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder builderForValue) {
        if (oldPeerConfigBuilder_ == null) {
          oldPeerConfig_ = builderForValue.build();
          onChanged();
        } else {
          oldPeerConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public Builder mergeOldPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (oldPeerConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              oldPeerConfig_ != null &&
              oldPeerConfig_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance()) {
            oldPeerConfig_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.newBuilder(oldPeerConfig_).mergeFrom(value).buildPartial();
          } else {
            oldPeerConfig_ = value;
          }
          onChanged();
        } else {
          oldPeerConfigBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public Builder clearOldPeerConfig() {
        if (oldPeerConfigBuilder_ == null) {
          oldPeerConfig_ = null;
          onChanged();
        } else {
          oldPeerConfigBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder getOldPeerConfigBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getOldPeerConfigFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getOldPeerConfigOrBuilder() {
        if (oldPeerConfigBuilder_ != null) {
          return oldPeerConfigBuilder_.getMessageOrBuilder();
        } else {
          return oldPeerConfig_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : oldPeerConfig_;
        }
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> 
          getOldPeerConfigFieldBuilder() {
        if (oldPeerConfigBuilder_ == null) {
          oldPeerConfigBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder>(
                  getOldPeerConfig(),
                  getParentForChildren(),
                  isClean());
          oldPeerConfig_ = null;
        }
        return oldPeerConfigBuilder_;
      }

      private boolean enabled_ ;
      /**
       * <code>required bool enabled = 3;</code>
       */
      public boolean hasEnabled() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bool enabled = 3;</code>
       */
      public boolean getEnabled() {
        return enabled_;
      }
      /**
       * <code>required bool enabled = 3;</code>
       */
      public Builder setEnabled(boolean value) {
        bitField0_ |= 0x00000004;
        enabled_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool enabled = 3;</code>
       */
      public Builder clearEnabled() {
        bitField0_ = (bitField0_ & ~0x00000004);
        enabled_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.UpdatePeerConfigStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UpdatePeerConfigStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdatePeerConfigStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<UpdatePeerConfigStateData>() {
      public UpdatePeerConfigStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new UpdatePeerConfigStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdatePeerConfigStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdatePeerConfigStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RemovePeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RemovePeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    boolean hasPeerConfig();
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig();
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.RemovePeerStateData}
   */
  @javax.annotation.Generated("proto") public  static final class RemovePeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RemovePeerStateData)
      RemovePeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RemovePeerStateData.newBuilder() to construct.
    private RemovePeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RemovePeerStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RemovePeerStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = peerConfig_.toBuilder();
              }
              peerConfig_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(peerConfig_);
                peerConfig_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_CONFIG_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public boolean hasPeerConfig() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasPeerConfig()) {
        if (!getPeerConfig().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getPeerConfig());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getPeerConfig());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData) obj;

      boolean result = true;
      result = result && (hasPeerConfig() == other.hasPeerConfig());
      if (hasPeerConfig()) {
        result = result && getPeerConfig()
            .equals(other.getPeerConfig());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerConfig()) {
        hash = (37 * hash) + PEER_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getPeerConfig().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RemovePeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RemovePeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getPeerConfigFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (peerConfigBuilder_ == null) {
          peerConfig_ = null;
        } else {
          peerConfigBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (peerConfigBuilder_ == null) {
          result.peerConfig_ = peerConfig_;
        } else {
          result.peerConfig_ = peerConfigBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.getDefaultInstance()) return this;
        if (other.hasPeerConfig()) {
          mergePeerConfig(other.getPeerConfig());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasPeerConfig()) {
          if (!getPeerConfig().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> peerConfigBuilder_;
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public boolean hasPeerConfig() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
        if (peerConfigBuilder_ == null) {
          return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        } else {
          return peerConfigBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          peerConfig_ = value;
          onChanged();
        } else {
          peerConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder builderForValue) {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = builderForValue.build();
          onChanged();
        } else {
          peerConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder mergePeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              peerConfig_ != null &&
              peerConfig_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance()) {
            peerConfig_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.newBuilder(peerConfig_).mergeFrom(value).buildPartial();
          } else {
            peerConfig_ = value;
          }
          onChanged();
        } else {
          peerConfigBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder clearPeerConfig() {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = null;
          onChanged();
        } else {
          peerConfigBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder getPeerConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPeerConfigFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
        if (peerConfigBuilder_ != null) {
          return peerConfigBuilder_.getMessageOrBuilder();
        } else {
          return peerConfig_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        }
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> 
          getPeerConfigFieldBuilder() {
        if (peerConfigBuilder_ == null) {
          peerConfigBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder>(
                  getPeerConfig(),
                  getParentForChildren(),
                  isClean());
          peerConfig_ = null;
        }
        return peerConfigBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RemovePeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RemovePeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemovePeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RemovePeerStateData>() {
      public RemovePeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RemovePeerStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemovePeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemovePeerStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface EnablePeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.EnablePeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.EnablePeerStateData}
   */
  @javax.annotation.Generated("proto") public  static final class EnablePeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.EnablePeerStateData)
      EnablePeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use EnablePeerStateData.newBuilder() to construct.
    private EnablePeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private EnablePeerStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private EnablePeerStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.EnablePeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.EnablePeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.EnablePeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.EnablePeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnablePeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<EnablePeerStateData>() {
      public EnablePeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new EnablePeerStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnablePeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnablePeerStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DisablePeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DisablePeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.DisablePeerStateData}
   */
  @javax.annotation.Generated("proto") public  static final class DisablePeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DisablePeerStateData)
      DisablePeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DisablePeerStateData.newBuilder() to construct.
    private DisablePeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DisablePeerStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DisablePeerStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DisablePeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DisablePeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DisablePeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DisablePeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisablePeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DisablePeerStateData>() {
      public DisablePeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new DisablePeerStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisablePeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisablePeerStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReopenTableRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ReopenTableRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> 
        getRegionList();
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getRegion(int index);
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    int getRegionCount();
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
        getRegionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getRegionOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.ReopenTableRegionsStateData}
   */
  @javax.annotation.Generated("proto") public  static final class ReopenTableRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ReopenTableRegionsStateData)
      ReopenTableRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReopenTableRegionsStateData.newBuilder() to construct.
    private ReopenTableRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReopenTableRegionsStateData() {
      region_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReopenTableRegionsStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                region_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation>();
                mutable_bitField0_ |= 0x00000002;
              }
              region_.add(
                  input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          region_ = java.util.Collections.unmodifiableList(region_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int REGION_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> region_;
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> getRegionList() {
      return region_;
    }
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
        getRegionOrBuilderList() {
      return region_;
    }
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    public int getRegionCount() {
      return region_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getRegion(int index) {
      return region_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getRegionOrBuilder(
        int index) {
      return region_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionCount(); i++) {
        if (!getRegion(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getTableName());
      }
      for (int i = 0; i < region_.size(); i++) {
        output.writeMessage(2, region_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      for (int i = 0; i < region_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, region_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData) obj;

      boolean result = true;
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && getRegionList()
          .equals(other.getRegionList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (getRegionCount() > 0) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegionList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ReopenTableRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ReopenTableRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
          getRegionFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (regionBuilder_ == null) {
          region_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          regionBuilder_.clear();
        }
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            region_ = java.util.Collections.unmodifiableList(region_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (regionBuilder_ == null) {
          if (!other.region_.isEmpty()) {
            if (region_.isEmpty()) {
              region_ = other.region_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureRegionIsMutable();
              region_.addAll(other.region_);
            }
            onChanged();
          }
        } else {
          if (!other.region_.isEmpty()) {
            if (regionBuilder_.isEmpty()) {
              regionBuilder_.dispose();
              regionBuilder_ = null;
              region_ = other.region_;
              bitField0_ = (bitField0_ & ~0x00000002);
              regionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionFieldBuilder() : null;
            } else {
              regionBuilder_.addAllMessages(other.region_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionCount(); i++) {
          if (!getRegion(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> region_ =
        java.util.Collections.emptyList();
      private void ensureRegionIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          region_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation>(region_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> regionBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> getRegionList() {
        if (regionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(region_);
        } else {
          return regionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public int getRegionCount() {
        if (regionBuilder_ == null) {
          return region_.size();
        } else {
          return regionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getRegion(int index) {
        if (regionBuilder_ == null) {
          return region_.get(index);
        } else {
          return regionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder setRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.set(index, value);
          onChanged();
        } else {
          regionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder setRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.add(value);
          onChanged();
        } else {
          regionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.add(index, value);
          onChanged();
        } else {
          regionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.add(builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addAllRegion(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> values) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, region_);
          onChanged();
        } else {
          regionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder removeRegion(int index) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.remove(index);
          onChanged();
        } else {
          regionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder getRegionBuilder(
          int index) {
        return getRegionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getRegionOrBuilder(
          int index) {
        if (regionBuilder_ == null) {
          return region_.get(index);  } else {
          return regionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
           getRegionOrBuilderList() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(region_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder addRegionBuilder() {
        return getRegionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder addRegionBuilder(
          int index) {
        return getRegionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder> 
           getRegionBuilderList() {
        return getRegionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder>(
                  region_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ReopenTableRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ReopenTableRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReopenTableRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ReopenTableRegionsStateData>() {
      public ReopenTableRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new ReopenTableRegionsStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReopenTableRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReopenTableRegionsStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface InitMetaStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.InitMetaStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.InitMetaStateData}
   */
  @javax.annotation.Generated("proto") public  static final class InitMetaStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.InitMetaStateData)
      InitMetaStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use InitMetaStateData.newBuilder() to construct.
    private InitMetaStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private InitMetaStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private InitMetaStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.InitMetaStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.InitMetaStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.InitMetaStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.InitMetaStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<InitMetaStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<InitMetaStateData>() {
      public InitMetaStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new InitMetaStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<InitMetaStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<InitMetaStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TransitPeerSyncReplicationStateStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.TransitPeerSyncReplicationStateStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     ** Could be null if we fail in pre check, so optional 
     * </pre>
     *
     * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
     */
    boolean hasFromState();
    /**
     * <pre>
     ** Could be null if we fail in pre check, so optional 
     * </pre>
     *
     * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState getFromState();
    /**
     * <pre>
     ** Could be null if we fail in pre check, so optional 
     * </pre>
     *
     * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder getFromStateOrBuilder();

    /**
     * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
     */
    boolean hasToState();
    /**
     * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState getToState();
    /**
     * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder getToStateOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.TransitPeerSyncReplicationStateStateData}
   */
  @javax.annotation.Generated("proto") public  static final class TransitPeerSyncReplicationStateStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.TransitPeerSyncReplicationStateStateData)
      TransitPeerSyncReplicationStateStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TransitPeerSyncReplicationStateStateData.newBuilder() to construct.
    private TransitPeerSyncReplicationStateStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TransitPeerSyncReplicationStateStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private TransitPeerSyncReplicationStateStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = fromState_.toBuilder();
              }
              fromState_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(fromState_);
                fromState_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = toState_.toBuilder();
              }
              toState_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(toState_);
                toState_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData.Builder.class);
    }

    private int bitField0_;
    public static final int FROMSTATE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState fromState_;
    /**
     * <pre>
     ** Could be null if we fail in pre check, so optional 
     * </pre>
     *
     * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
     */
    public boolean hasFromState() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <pre>
     ** Could be null if we fail in pre check, so optional 
     * </pre>
     *
     * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState getFromState() {
      return fromState_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance() : fromState_;
    }
    /**
     * <pre>
     ** Could be null if we fail in pre check, so optional 
     * </pre>
     *
     * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder getFromStateOrBuilder() {
      return fromState_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance() : fromState_;
    }

    public static final int TOSTATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState toState_;
    /**
     * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
     */
    public boolean hasToState() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState getToState() {
      return toState_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance() : toState_;
    }
    /**
     * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder getToStateOrBuilder() {
      return toState_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance() : toState_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasToState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasFromState()) {
        if (!getFromState().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getToState().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getFromState());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getToState());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFromState());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getToState());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData) obj;

      boolean result = true;
      result = result && (hasFromState() == other.hasFromState());
      if (hasFromState()) {
        result = result && getFromState()
            .equals(other.getFromState());
      }
      result = result && (hasToState() == other.hasToState());
      if (hasToState()) {
        result = result && getToState()
            .equals(other.getToState());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFromState()) {
        hash = (37 * hash) + FROMSTATE_FIELD_NUMBER;
        hash = (53 * hash) + getFromState().hashCode();
      }
      if (hasToState()) {
        hash = (37 * hash) + TOSTATE_FIELD_NUMBER;
        hash = (53 * hash) + getToState().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TransitPeerSyncReplicationStateStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.TransitPeerSyncReplicationStateStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getFromStateFieldBuilder();
          getToStateFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (fromStateBuilder_ == null) {
          fromState_ = null;
        } else {
          fromStateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (toStateBuilder_ == null) {
          toState_ = null;
        } else {
          toStateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (fromStateBuilder_ == null) {
          result.fromState_ = fromState_;
        } else {
          result.fromState_ = fromStateBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (toStateBuilder_ == null) {
          result.toState_ = toState_;
        } else {
          result.toState_ = toStateBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData.getDefaultInstance()) return this;
        if (other.hasFromState()) {
          mergeFromState(other.getFromState());
        }
        if (other.hasToState()) {
          mergeToState(other.getToState());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasToState()) {
          return false;
        }
        if (hasFromState()) {
          if (!getFromState().isInitialized()) {
            return false;
          }
        }
        if (!getToState().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState fromState_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder> fromStateBuilder_;
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      public boolean hasFromState() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState getFromState() {
        if (fromStateBuilder_ == null) {
          return fromState_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance() : fromState_;
        } else {
          return fromStateBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      public Builder setFromState(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState value) {
        if (fromStateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          fromState_ = value;
          onChanged();
        } else {
          fromStateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      public Builder setFromState(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder builderForValue) {
        if (fromStateBuilder_ == null) {
          fromState_ = builderForValue.build();
          onChanged();
        } else {
          fromStateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      public Builder mergeFromState(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState value) {
        if (fromStateBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              fromState_ != null &&
              fromState_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance()) {
            fromState_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.newBuilder(fromState_).mergeFrom(value).buildPartial();
          } else {
            fromState_ = value;
          }
          onChanged();
        } else {
          fromStateBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      public Builder clearFromState() {
        if (fromStateBuilder_ == null) {
          fromState_ = null;
          onChanged();
        } else {
          fromStateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder getFromStateBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFromStateFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder getFromStateOrBuilder() {
        if (fromStateBuilder_ != null) {
          return fromStateBuilder_.getMessageOrBuilder();
        } else {
          return fromState_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance() : fromState_;
        }
      }
      /**
       * <pre>
       ** Could be null if we fail in pre check, so optional 
       * </pre>
       *
       * <code>optional .hbase.pb.SyncReplicationState fromState = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder> 
          getFromStateFieldBuilder() {
        if (fromStateBuilder_ == null) {
          fromStateBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder>(
                  getFromState(),
                  getParentForChildren(),
                  isClean());
          fromState_ = null;
        }
        return fromStateBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState toState_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder> toStateBuilder_;
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      public boolean hasToState() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState getToState() {
        if (toStateBuilder_ == null) {
          return toState_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance() : toState_;
        } else {
          return toStateBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      public Builder setToState(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState value) {
        if (toStateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          toState_ = value;
          onChanged();
        } else {
          toStateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      public Builder setToState(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder builderForValue) {
        if (toStateBuilder_ == null) {
          toState_ = builderForValue.build();
          onChanged();
        } else {
          toStateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      public Builder mergeToState(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState value) {
        if (toStateBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              toState_ != null &&
              toState_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance()) {
            toState_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.newBuilder(toState_).mergeFrom(value).buildPartial();
          } else {
            toState_ = value;
          }
          onChanged();
        } else {
          toStateBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      public Builder clearToState() {
        if (toStateBuilder_ == null) {
          toState_ = null;
          onChanged();
        } else {
          toStateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder getToStateBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getToStateFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder getToStateOrBuilder() {
        if (toStateBuilder_ != null) {
          return toStateBuilder_.getMessageOrBuilder();
        } else {
          return toState_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.getDefaultInstance() : toState_;
        }
      }
      /**
       * <code>required .hbase.pb.SyncReplicationState toState = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder> 
          getToStateFieldBuilder() {
        if (toStateBuilder_ == null) {
          toStateBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationState.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.SyncReplicationStateOrBuilder>(
                  getToState(),
                  getParentForChildren(),
                  isClean());
          toState_ = null;
        }
        return toStateBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.TransitPeerSyncReplicationStateStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TransitPeerSyncReplicationStateStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<TransitPeerSyncReplicationStateStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<TransitPeerSyncReplicationStateStateData>() {
      public TransitPeerSyncReplicationStateStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new TransitPeerSyncReplicationStateStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<TransitPeerSyncReplicationStateStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<TransitPeerSyncReplicationStateStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TransitPeerSyncReplicationStateStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RecoverStandbyStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RecoverStandbyStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool serial = 1;</code>
     */
    boolean hasSerial();
    /**
     * <code>required bool serial = 1;</code>
     */
    boolean getSerial();
  }
  /**
   * Protobuf type {@code hbase.pb.RecoverStandbyStateData}
   */
  @javax.annotation.Generated("proto") public  static final class RecoverStandbyStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RecoverStandbyStateData)
      RecoverStandbyStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RecoverStandbyStateData.newBuilder() to construct.
    private RecoverStandbyStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecoverStandbyStateData() {
      serial_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RecoverStandbyStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              serial_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverStandbyStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverStandbyStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData.Builder.class);
    }

    private int bitField0_;
    public static final int SERIAL_FIELD_NUMBER = 1;
    private boolean serial_;
    /**
     * <code>required bool serial = 1;</code>
     */
    public boolean hasSerial() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bool serial = 1;</code>
     */
    public boolean getSerial() {
      return serial_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasSerial()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, serial_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, serial_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData) obj;

      boolean result = true;
      result = result && (hasSerial() == other.hasSerial());
      if (hasSerial()) {
        result = result && (getSerial()
            == other.getSerial());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSerial()) {
        hash = (37 * hash) + SERIAL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getSerial());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RecoverStandbyStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RecoverStandbyStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverStandbyStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverStandbyStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        serial_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverStandbyStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.serial_ = serial_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData.getDefaultInstance()) return this;
        if (other.hasSerial()) {
          setSerial(other.getSerial());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasSerial()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private boolean serial_ ;
      /**
       * <code>required bool serial = 1;</code>
       */
      public boolean hasSerial() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bool serial = 1;</code>
       */
      public boolean getSerial() {
        return serial_;
      }
      /**
       * <code>required bool serial = 1;</code>
       */
      public Builder setSerial(boolean value) {
        bitField0_ |= 0x00000001;
        serial_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool serial = 1;</code>
       */
      public Builder clearSerial() {
        bitField0_ = (bitField0_ & ~0x00000001);
        serial_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RecoverStandbyStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RecoverStandbyStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverStandbyStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RecoverStandbyStateData>() {
      public RecoverStandbyStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RecoverStandbyStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverStandbyStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverStandbyStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverStandbyStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SyncReplicationReplayWALStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SyncReplicationReplayWALStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();

    /**
     * <code>repeated string wal = 2;</code>
     */
    java.util.List<java.lang.String>
        getWalList();
    /**
     * <code>repeated string wal = 2;</code>
     */
    int getWalCount();
    /**
     * <code>repeated string wal = 2;</code>
     */
    java.lang.String getWal(int index);
    /**
     * <code>repeated string wal = 2;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalBytes(int index);

    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    boolean hasWorker();
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker();
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SyncReplicationReplayWALStateData}
   */
  @javax.annotation.Generated("proto") public  static final class SyncReplicationReplayWALStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SyncReplicationReplayWALStateData)
      SyncReplicationReplayWALStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SyncReplicationReplayWALStateData.newBuilder() to construct.
    private SyncReplicationReplayWALStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SyncReplicationReplayWALStateData() {
      peerId_ = "";
      wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SyncReplicationReplayWALStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              peerId_ = bs;
              break;
            }
            case 18: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                wal_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              wal_.add(bs);
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = worker_.toBuilder();
              }
              worker_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(worker_);
                worker_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = wal_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object peerId_;
    /**
     * <code>required string peer_id = 1;</code>
     */
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int WAL_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringList wal_;
    /**
     * <code>repeated string wal = 2;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getWalList() {
      return wal_;
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public int getWalCount() {
      return wal_.size();
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public java.lang.String getWal(int index) {
      return wal_.get(index);
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalBytes(int index) {
      return wal_.getByteString(index);
    }

    public static final int WORKER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_;
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    public boolean hasWorker() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasWorker()) {
        if (!getWorker().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      for (int i = 0; i < wal_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, wal_.getRaw(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(3, getWorker());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < wal_.size(); i++) {
          dataSize += computeStringSizeNoTag(wal_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getWalList().size();
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getWorker());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData) obj;

      boolean result = true;
      result = result && (hasPeerId() == other.hasPeerId());
      if (hasPeerId()) {
        result = result && getPeerId()
            .equals(other.getPeerId());
      }
      result = result && getWalList()
          .equals(other.getWalList());
      result = result && (hasWorker() == other.hasWorker());
      if (hasWorker()) {
        result = result && getWorker()
            .equals(other.getWorker());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      if (getWalCount() > 0) {
        hash = (37 * hash) + WAL_FIELD_NUMBER;
        hash = (53 * hash) + getWalList().hashCode();
      }
      if (hasWorker()) {
        hash = (37 * hash) + WORKER_FIELD_NUMBER;
        hash = (53 * hash) + getWorker().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SyncReplicationReplayWALStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SyncReplicationReplayWALStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getWorkerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        peerId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (workerBuilder_ == null) {
          worker_ = null;
        } else {
          workerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.peerId_ = peerId_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = wal_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.wal_ = wal_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        if (workerBuilder_ == null) {
          result.worker_ = worker_;
        } else {
          result.worker_ = workerBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          bitField0_ |= 0x00000001;
          peerId_ = other.peerId_;
          onChanged();
        }
        if (!other.wal_.isEmpty()) {
          if (wal_.isEmpty()) {
            wal_ = other.wal_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureWalIsMutable();
            wal_.addAll(other.wal_);
          }
          onChanged();
        }
        if (other.hasWorker()) {
          mergeWorker(other.getWorker());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        if (hasWorker()) {
          if (!getWorker().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder clearPeerId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerId_ = getDefaultInstance().getPeerId();
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringList wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureWalIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(wal_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getWalList() {
        return wal_.getUnmodifiableView();
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public int getWalCount() {
        return wal_.size();
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public java.lang.String getWal(int index) {
        return wal_.get(index);
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalBytes(int index) {
        return wal_.getByteString(index);
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder setWal(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addWal(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addAllWal(
          java.lang.Iterable<java.lang.String> values) {
        ensureWalIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, wal_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder clearWal() {
        wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addWalBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.add(value);
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> workerBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public boolean hasWorker() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
        if (workerBuilder_ == null) {
          return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        } else {
          return workerBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          worker_ = value;
          onChanged();
        } else {
          workerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (workerBuilder_ == null) {
          worker_ = builderForValue.build();
          onChanged();
        } else {
          workerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder mergeWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              worker_ != null &&
              worker_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            worker_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(worker_).mergeFrom(value).buildPartial();
          } else {
            worker_ = value;
          }
          onChanged();
        } else {
          workerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder clearWorker() {
        if (workerBuilder_ == null) {
          worker_ = null;
          onChanged();
        } else {
          workerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getWorkerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getWorkerFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
        if (workerBuilder_ != null) {
          return workerBuilder_.getMessageOrBuilder();
        } else {
          return worker_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getWorkerFieldBuilder() {
        if (workerBuilder_ == null) {
          workerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getWorker(),
                  getParentForChildren(),
                  isClean());
          worker_ = null;
        }
        return workerBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SyncReplicationReplayWALStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SyncReplicationReplayWALStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SyncReplicationReplayWALStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SyncReplicationReplayWALStateData>() {
      public SyncReplicationReplayWALStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new SyncReplicationReplayWALStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SyncReplicationReplayWALStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SyncReplicationReplayWALStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SyncReplicationReplayWALRemoteStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SyncReplicationReplayWALRemoteStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();

    /**
     * <code>repeated string wal = 2;</code>
     */
    java.util.List<java.lang.String>
        getWalList();
    /**
     * <code>repeated string wal = 2;</code>
     */
    int getWalCount();
    /**
     * <code>repeated string wal = 2;</code>
     */
    java.lang.String getWal(int index);
    /**
     * <code>repeated string wal = 2;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalBytes(int index);

    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SyncReplicationReplayWALRemoteStateData}
   */
  @javax.annotation.Generated("proto") public  static final class SyncReplicationReplayWALRemoteStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SyncReplicationReplayWALRemoteStateData)
      SyncReplicationReplayWALRemoteStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SyncReplicationReplayWALRemoteStateData.newBuilder() to construct.
    private SyncReplicationReplayWALRemoteStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SyncReplicationReplayWALRemoteStateData() {
      peerId_ = "";
      wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SyncReplicationReplayWALRemoteStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              peerId_ = bs;
              break;
            }
            case 18: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                wal_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              wal_.add(bs);
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = targetServer_.toBuilder();
              }
              targetServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(targetServer_);
                targetServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = wal_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object peerId_;
    /**
     * <code>required string peer_id = 1;</code>
     */
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int WAL_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringList wal_;
    /**
     * <code>repeated string wal = 2;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getWalList() {
      return wal_;
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public int getWalCount() {
      return wal_.size();
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public java.lang.String getWal(int index) {
      return wal_.get(index);
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalBytes(int index) {
      return wal_.getByteString(index);
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      for (int i = 0; i < wal_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, wal_.getRaw(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(3, getTargetServer());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < wal_.size(); i++) {
          dataSize += computeStringSizeNoTag(wal_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getWalList().size();
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTargetServer());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData) obj;

      boolean result = true;
      result = result && (hasPeerId() == other.hasPeerId());
      if (hasPeerId()) {
        result = result && getPeerId()
            .equals(other.getPeerId());
      }
      result = result && getWalList()
          .equals(other.getWalList());
      result = result && (hasTargetServer() == other.hasTargetServer());
      if (hasTargetServer()) {
        result = result && getTargetServer()
            .equals(other.getTargetServer());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      if (getWalCount() > 0) {
        hash = (37 * hash) + WAL_FIELD_NUMBER;
        hash = (53 * hash) + getWalList().hashCode();
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SyncReplicationReplayWALRemoteStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SyncReplicationReplayWALRemoteStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTargetServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        peerId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.peerId_ = peerId_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = wal_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.wal_ = wal_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        if (targetServerBuilder_ == null) {
          result.targetServer_ = targetServer_;
        } else {
          result.targetServer_ = targetServerBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          bitField0_ |= 0x00000001;
          peerId_ = other.peerId_;
          onChanged();
        }
        if (!other.wal_.isEmpty()) {
          if (wal_.isEmpty()) {
            wal_ = other.wal_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureWalIsMutable();
            wal_.addAll(other.wal_);
          }
          onChanged();
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        if (!hasTargetServer()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder clearPeerId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerId_ = getDefaultInstance().getPeerId();
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringList wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureWalIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(wal_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getWalList() {
        return wal_.getUnmodifiableView();
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public int getWalCount() {
        return wal_.size();
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public java.lang.String getWal(int index) {
        return wal_.get(index);
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalBytes(int index) {
        return wal_.getByteString(index);
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder setWal(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addWal(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addAllWal(
          java.lang.Iterable<java.lang.String> values) {
        ensureWalIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, wal_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder clearWal() {
        wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addWalBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.add(value);
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
          onChanged();
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
          onChanged();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              targetServer_ != null &&
              targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            targetServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(targetServer_).mergeFrom(value).buildPartial();
          } else {
            targetServer_ = value;
          }
          onChanged();
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder clearTargetServer() {
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
          onChanged();
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SyncReplicationReplayWALRemoteStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SyncReplicationReplayWALRemoteStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SyncReplicationReplayWALRemoteStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SyncReplicationReplayWALRemoteStateData>() {
      public SyncReplicationReplayWALRemoteStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new SyncReplicationReplayWALRemoteStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SyncReplicationReplayWALRemoteStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SyncReplicationReplayWALRemoteStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SyncReplicationReplayWALRemoteStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReplaySyncReplicationWALParameterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ReplaySyncReplicationWALParameter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();

    /**
     * <code>repeated string wal = 2;</code>
     */
    java.util.List<java.lang.String>
        getWalList();
    /**
     * <code>repeated string wal = 2;</code>
     */
    int getWalCount();
    /**
     * <code>repeated string wal = 2;</code>
     */
    java.lang.String getWal(int index);
    /**
     * <code>repeated string wal = 2;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalBytes(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.ReplaySyncReplicationWALParameter}
   */
  @javax.annotation.Generated("proto") public  static final class ReplaySyncReplicationWALParameter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ReplaySyncReplicationWALParameter)
      ReplaySyncReplicationWALParameterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReplaySyncReplicationWALParameter.newBuilder() to construct.
    private ReplaySyncReplicationWALParameter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReplaySyncReplicationWALParameter() {
      peerId_ = "";
      wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReplaySyncReplicationWALParameter(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              peerId_ = bs;
              break;
            }
            case 18: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                wal_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              wal_.add(bs);
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = wal_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReplaySyncReplicationWALParameter_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReplaySyncReplicationWALParameter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object peerId_;
    /**
     * <code>required string peer_id = 1;</code>
     */
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int WAL_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringList wal_;
    /**
     * <code>repeated string wal = 2;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getWalList() {
      return wal_;
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public int getWalCount() {
      return wal_.size();
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public java.lang.String getWal(int index) {
      return wal_.get(index);
    }
    /**
     * <code>repeated string wal = 2;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalBytes(int index) {
      return wal_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      for (int i = 0; i < wal_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, wal_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < wal_.size(); i++) {
          dataSize += computeStringSizeNoTag(wal_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getWalList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter) obj;

      boolean result = true;
      result = result && (hasPeerId() == other.hasPeerId());
      if (hasPeerId()) {
        result = result && getPeerId()
            .equals(other.getPeerId());
      }
      result = result && getWalList()
          .equals(other.getWalList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      if (getWalCount() > 0) {
        hash = (37 * hash) + WAL_FIELD_NUMBER;
        hash = (53 * hash) + getWalList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ReplaySyncReplicationWALParameter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ReplaySyncReplicationWALParameter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReplaySyncReplicationWALParameter_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReplaySyncReplicationWALParameter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        peerId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReplaySyncReplicationWALParameter_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.peerId_ = peerId_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = wal_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.wal_ = wal_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          bitField0_ |= 0x00000001;
          peerId_ = other.peerId_;
          onChanged();
        }
        if (!other.wal_.isEmpty()) {
          if (wal_.isEmpty()) {
            wal_ = other.wal_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureWalIsMutable();
            wal_.addAll(other.wal_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder clearPeerId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerId_ = getDefaultInstance().getPeerId();
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        peerId_ = value;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringList wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureWalIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          wal_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(wal_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getWalList() {
        return wal_.getUnmodifiableView();
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public int getWalCount() {
        return wal_.size();
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public java.lang.String getWal(int index) {
        return wal_.get(index);
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalBytes(int index) {
        return wal_.getByteString(index);
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder setWal(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addWal(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addAllWal(
          java.lang.Iterable<java.lang.String> values) {
        ensureWalIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, wal_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder clearWal() {
        wal_ = org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string wal = 2;</code>
       */
      public Builder addWalBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureWalIsMutable();
        wal_.add(value);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ReplaySyncReplicationWALParameter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ReplaySyncReplicationWALParameter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplaySyncReplicationWALParameter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ReplaySyncReplicationWALParameter>() {
      public ReplaySyncReplicationWALParameter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new ReplaySyncReplicationWALParameter(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplaySyncReplicationWALParameter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplaySyncReplicationWALParameter> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReplaySyncReplicationWALParameter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegionStateTransitionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RegionStateTransitionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
     */
    boolean hasType();
    /**
     * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType getType();

    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     */
    boolean hasAssignCandidate();
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate();
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder();

    /**
     * <code>required bool force_new_plan = 3;</code>
     */
    boolean hasForceNewPlan();
    /**
     * <code>required bool force_new_plan = 3;</code>
     */
    boolean getForceNewPlan();
  }
  /**
   * Protobuf type {@code hbase.pb.RegionStateTransitionStateData}
   */
  @javax.annotation.Generated("proto") public  static final class RegionStateTransitionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RegionStateTransitionStateData)
      RegionStateTransitionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RegionStateTransitionStateData.newBuilder() to construct.
    private RegionStateTransitionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegionStateTransitionStateData() {
      type_ = 1;
      forceNewPlan_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RegionStateTransitionStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType value = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                type_ = rawValue;
              }
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = assignCandidate_.toBuilder();
              }
              assignCandidate_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(assignCandidate_);
                assignCandidate_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              forceNewPlan_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TYPE_FIELD_NUMBER = 1;
    private int type_;
    /**
     * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType getType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.valueOf(type_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.ASSIGN : result;
    }

    public static final int ASSIGN_CANDIDATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName assignCandidate_;
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     */
    public boolean hasAssignCandidate() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate() {
      return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
    }
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder() {
      return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
    }

    public static final int FORCE_NEW_PLAN_FIELD_NUMBER = 3;
    private boolean forceNewPlan_;
    /**
     * <code>required bool force_new_plan = 3;</code>
     */
    public boolean hasForceNewPlan() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bool force_new_plan = 3;</code>
     */
    public boolean getForceNewPlan() {
      return forceNewPlan_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasForceNewPlan()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasAssignCandidate()) {
        if (!getAssignCandidate().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, type_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getAssignCandidate());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, forceNewPlan_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, type_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getAssignCandidate());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, forceNewPlan_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData) obj;

      boolean result = true;
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result && type_ == other.type_;
      }
      result = result && (hasAssignCandidate() == other.hasAssignCandidate());
      if (hasAssignCandidate()) {
        result = result && getAssignCandidate()
            .equals(other.getAssignCandidate());
      }
      result = result && (hasForceNewPlan() == other.hasForceNewPlan());
      if (hasForceNewPlan()) {
        result = result && (getForceNewPlan()
            == other.getForceNewPlan());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasAssignCandidate()) {
        hash = (37 * hash) + ASSIGN_CANDIDATE_FIELD_NUMBER;
        hash = (53 * hash) + getAssignCandidate().hashCode();
      }
      if (hasForceNewPlan()) {
        hash = (37 * hash) + FORCE_NEW_PLAN_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForceNewPlan());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RegionStateTransitionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RegionStateTransitionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAssignCandidateFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        type_ = 1;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (assignCandidateBuilder_ == null) {
          assignCandidate_ = null;
        } else {
          assignCandidateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        forceNewPlan_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (assignCandidateBuilder_ == null) {
          result.assignCandidate_ = assignCandidate_;
        } else {
          result.assignCandidate_ = assignCandidateBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.forceNewPlan_ = forceNewPlan_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.getDefaultInstance()) return this;
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasAssignCandidate()) {
          mergeAssignCandidate(other.getAssignCandidate());
        }
        if (other.hasForceNewPlan()) {
          setForceNewPlan(other.getForceNewPlan());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasType()) {
          return false;
        }
        if (!hasForceNewPlan()) {
          return false;
        }
        if (hasAssignCandidate()) {
          if (!getAssignCandidate().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int type_ = 1;
      /**
       * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType getType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.valueOf(type_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.ASSIGN : result;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
       */
      public Builder setType(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName assignCandidate_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> assignCandidateBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public boolean hasAssignCandidate() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate() {
        if (assignCandidateBuilder_ == null) {
          return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
        } else {
          return assignCandidateBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public Builder setAssignCandidate(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (assignCandidateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          assignCandidate_ = value;
          onChanged();
        } else {
          assignCandidateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public Builder setAssignCandidate(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (assignCandidateBuilder_ == null) {
          assignCandidate_ = builderForValue.build();
          onChanged();
        } else {
          assignCandidateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public Builder mergeAssignCandidate(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (assignCandidateBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              assignCandidate_ != null &&
              assignCandidate_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            assignCandidate_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(assignCandidate_).mergeFrom(value).buildPartial();
          } else {
            assignCandidate_ = value;
          }
          onChanged();
        } else {
          assignCandidateBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public Builder clearAssignCandidate() {
        if (assignCandidateBuilder_ == null) {
          assignCandidate_ = null;
          onChanged();
        } else {
          assignCandidateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getAssignCandidateBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getAssignCandidateFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder() {
        if (assignCandidateBuilder_ != null) {
          return assignCandidateBuilder_.getMessageOrBuilder();
        } else {
          return assignCandidate_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getAssignCandidateFieldBuilder() {
        if (assignCandidateBuilder_ == null) {
          assignCandidateBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getAssignCandidate(),
                  getParentForChildren(),
                  isClean());
          assignCandidate_ = null;
        }
        return assignCandidateBuilder_;
      }

      private boolean forceNewPlan_ ;
      /**
       * <code>required bool force_new_plan = 3;</code>
       */
      public boolean hasForceNewPlan() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bool force_new_plan = 3;</code>
       */
      public boolean getForceNewPlan() {
        return forceNewPlan_;
      }
      /**
       * <code>required bool force_new_plan = 3;</code>
       */
      public Builder setForceNewPlan(boolean value) {
        bitField0_ |= 0x00000004;
        forceNewPlan_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool force_new_plan = 3;</code>
       */
      public Builder clearForceNewPlan() {
        bitField0_ = (bitField0_ & ~0x00000004);
        forceNewPlan_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RegionStateTransitionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RegionStateTransitionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionStateTransitionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionStateTransitionStateData>() {
      public RegionStateTransitionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RegionStateTransitionStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionStateTransitionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionStateTransitionStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegionRemoteProcedureBaseStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RegionRemoteProcedureBaseStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion();
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder();

    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <code>required .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
     */
    boolean hasState();
    /**
     * <code>required .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState getState();

    /**
     * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
     */
    boolean hasTransitionCode();
    /**
     * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode getTransitionCode();

    /**
     * <code>optional int64 seq_id = 5;</code>
     */
    boolean hasSeqId();
    /**
     * <code>optional int64 seq_id = 5;</code>
     */
    long getSeqId();
  }
  /**
   * Protobuf type {@code hbase.pb.RegionRemoteProcedureBaseStateData}
   */
  @javax.annotation.Generated("proto") public  static final class RegionRemoteProcedureBaseStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RegionRemoteProcedureBaseStateData)
      RegionRemoteProcedureBaseStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RegionRemoteProcedureBaseStateData.newBuilder() to construct.
    private RegionRemoteProcedureBaseStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegionRemoteProcedureBaseStateData() {
      state_ = 1;
      transitionCode_ = 0;
      seqId_ = 0L;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RegionRemoteProcedureBaseStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = targetServer_.toBuilder();
              }
              targetServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(targetServer_);
                targetServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState value = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(3, rawValue);
              } else {
                bitField0_ |= 0x00000004;
                state_ = rawValue;
              }
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode value = org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                transitionCode_ = rawValue;
              }
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              seqId_ = input.readInt64();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo region_;
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     */
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int STATE_FIELD_NUMBER = 3;
    private int state_;
    /**
     * <code>required .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
     */
    public boolean hasState() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState getState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.valueOf(state_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.REGION_REMOTE_PROCEDURE_DISPATCH : result;
    }

    public static final int TRANSITION_CODE_FIELD_NUMBER = 4;
    private int transitionCode_;
    /**
     * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
     */
    public boolean hasTransitionCode() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode getTransitionCode() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode result = org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.valueOf(transitionCode_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.OPENED : result;
    }

    public static final int SEQ_ID_FIELD_NUMBER = 5;
    private long seqId_;
    /**
     * <code>optional int64 seq_id = 5;</code>
     */
    public boolean hasSeqId() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int64 seq_id = 5;</code>
     */
    public long getSeqId() {
      return seqId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getTargetServer());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeEnum(3, state_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, transitionCode_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt64(5, seqId_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTargetServer());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, state_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, transitionCode_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt64Size(5, seqId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasTargetServer() == other.hasTargetServer());
      if (hasTargetServer()) {
        result = result && getTargetServer()
            .equals(other.getTargetServer());
      }
      result = result && (hasState() == other.hasState());
      if (hasState()) {
        result = result && state_ == other.state_;
      }
      result = result && (hasTransitionCode() == other.hasTransitionCode());
      if (hasTransitionCode()) {
        result = result && transitionCode_ == other.transitionCode_;
      }
      result = result && (hasSeqId() == other.hasSeqId());
      if (hasSeqId()) {
        result = result && (getSeqId()
            == other.getSeqId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + state_;
      }
      if (hasTransitionCode()) {
        hash = (37 * hash) + TRANSITION_CODE_FIELD_NUMBER;
        hash = (53 * hash) + transitionCode_;
      }
      if (hasSeqId()) {
        hash = (37 * hash) + SEQ_ID_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getSeqId());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RegionRemoteProcedureBaseStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RegionRemoteProcedureBaseStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getTargetServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = null;
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        state_ = 1;
        bitField0_ = (bitField0_ & ~0x00000004);
        transitionCode_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        seqId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (targetServerBuilder_ == null) {
          result.targetServer_ = targetServer_;
        } else {
          result.targetServer_ = targetServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.state_ = state_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.transitionCode_ = transitionCode_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.seqId_ = seqId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasTransitionCode()) {
          setTransitionCode(other.getTransitionCode());
        }
        if (other.hasSeqId()) {
          setSeqId(other.getSeqId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!hasTargetServer()) {
          return false;
        }
        if (!hasState()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo region_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != null &&
              region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = null;
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
          onChanged();
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
          onChanged();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              targetServer_ != null &&
              targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            targetServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(targetServer_).mergeFrom(value).buildPartial();
          } else {
            targetServer_ = value;
          }
          onChanged();
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public Builder clearTargetServer() {
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
          onChanged();
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private int state_ = 1;
      /**
       * <code>required .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
       */
      public boolean hasState() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState getState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.valueOf(state_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.REGION_REMOTE_PROCEDURE_DISPATCH : result;
      }
      /**
       * <code>required .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
       */
      public Builder setState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000004);
        state_ = 1;
        onChanged();
        return this;
      }

      private int transitionCode_ = 0;
      /**
       * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
       */
      public boolean hasTransitionCode() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode getTransitionCode() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode result = org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.valueOf(transitionCode_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.OPENED : result;
      }
      /**
       * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
       */
      public Builder setTransitionCode(org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        transitionCode_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
       */
      public Builder clearTransitionCode() {
        bitField0_ = (bitField0_ & ~0x00000008);
        transitionCode_ = 0;
        onChanged();
        return this;
      }

      private long seqId_ ;
      /**
       * <code>optional int64 seq_id = 5;</code>
       */
      public boolean hasSeqId() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional int64 seq_id = 5;</code>
       */
      public long getSeqId() {
        return seqId_;
      }
      /**
       * <code>optional int64 seq_id = 5;</code>
       */
      public Builder setSeqId(long value) {
        bitField0_ |= 0x00000010;
        seqId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 seq_id = 5;</code>
       */
      public Builder clearSeqId() {
        bitField0_ = (bitField0_ & ~0x00000010);
        seqId_ = 0L;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RegionRemoteProcedureBaseStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RegionRemoteProcedureBaseStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionRemoteProcedureBaseStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionRemoteProcedureBaseStateData>() {
      public RegionRemoteProcedureBaseStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new RegionRemoteProcedureBaseStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionRemoteProcedureBaseStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionRemoteProcedureBaseStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface OpenRegionProcedureStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.OpenRegionProcedureStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.OpenRegionProcedureStateData}
   */
  @javax.annotation.Generated("proto") public  static final class OpenRegionProcedureStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.OpenRegionProcedureStateData)
      OpenRegionProcedureStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use OpenRegionProcedureStateData.newBuilder() to construct.
    private OpenRegionProcedureStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private OpenRegionProcedureStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private OpenRegionProcedureStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData) obj;

      boolean result = true;
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.OpenRegionProcedureStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.OpenRegionProcedureStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData(this);
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.OpenRegionProcedureStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.OpenRegionProcedureStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionProcedureStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<OpenRegionProcedureStateData>() {
      public OpenRegionProcedureStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new OpenRegionProcedureStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionProcedureStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionProcedureStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloseRegionProcedureStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CloseRegionProcedureStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     */
    boolean hasAssignCandidate();
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate();
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CloseRegionProcedureStateData}
   */
  @javax.annotation.Generated("proto") public  static final class CloseRegionProcedureStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CloseRegionProcedureStateData)
      CloseRegionProcedureStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloseRegionProcedureStateData.newBuilder() to construct.
    private CloseRegionProcedureStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloseRegionProcedureStateData() {
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CloseRegionProcedureStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = assignCandidate_.toBuilder();
              }
              assignCandidate_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(assignCandidate_);
                assignCandidate_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.Builder.class);
    }

    private int bitField0_;
    public static final int ASSIGN_CANDIDATE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName assignCandidate_;
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     */
    public boolean hasAssignCandidate() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate() {
      return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
    }
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder() {
      return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasAssignCandidate()) {
        if (!getAssignCandidate().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getAssignCandidate());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getAssignCandidate());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData) obj;

      boolean result = true;
      result = result && (hasAssignCandidate() == other.hasAssignCandidate());
      if (hasAssignCandidate()) {
        result = result && getAssignCandidate()
            .equals(other.getAssignCandidate());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasAssignCandidate()) {
        hash = (37 * hash) + ASSIGN_CANDIDATE_FIELD_NUMBER;
        hash = (53 * hash) + getAssignCandidate().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CloseRegionProcedureStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CloseRegionProcedureStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAssignCandidateFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (assignCandidateBuilder_ == null) {
          assignCandidate_ = null;
        } else {
          assignCandidateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (assignCandidateBuilder_ == null) {
          result.assignCandidate_ = assignCandidate_;
        } else {
          result.assignCandidate_ = assignCandidateBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.getDefaultInstance()) return this;
        if (other.hasAssignCandidate()) {
          mergeAssignCandidate(other.getAssignCandidate());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasAssignCandidate()) {
          if (!getAssignCandidate().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName assignCandidate_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> assignCandidateBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public boolean hasAssignCandidate() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate() {
        if (assignCandidateBuilder_ == null) {
          return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
        } else {
          return assignCandidateBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public Builder setAssignCandidate(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (assignCandidateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          assignCandidate_ = value;
          onChanged();
        } else {
          assignCandidateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public Builder setAssignCandidate(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (assignCandidateBuilder_ == null) {
          assignCandidate_ = builderForValue.build();
          onChanged();
        } else {
          assignCandidateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public Builder mergeAssignCandidate(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (assignCandidateBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              assignCandidate_ != null &&
              assignCandidate_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            assignCandidate_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(assignCandidate_).mergeFrom(value).buildPartial();
          } else {
            assignCandidate_ = value;
          }
          onChanged();
        } else {
          assignCandidateBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public Builder clearAssignCandidate() {
        if (assignCandidateBuilder_ == null) {
          assignCandidate_ = null;
          onChanged();
        } else {
          assignCandidateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getAssignCandidateBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAssignCandidateFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder() {
        if (assignCandidateBuilder_ != null) {
          return assignCandidateBuilder_.getMessageOrBuilder();
        } else {
          return assignCandidate_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getAssignCandidateFieldBuilder() {
        if (assignCandidateBuilder_ == null) {
          assignCandidateBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getAssignCandidate(),
                  getParentForChildren(),
                  isClean());
          assignCandidate_ = null;
        }
        return assignCandidateBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CloseRegionProcedureStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CloseRegionProcedureStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionProcedureStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CloseRegionProcedureStateData>() {
      public CloseRegionProcedureStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new CloseRegionProcedureStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionProcedureStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionProcedureStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SwitchRpcThrottleStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SwitchRpcThrottleStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool rpc_throttle_enabled = 1;</code>
     */
    boolean hasRpcThrottleEnabled();
    /**
     * <code>required bool rpc_throttle_enabled = 1;</code>
     */
    boolean getRpcThrottleEnabled();
  }
  /**
   * Protobuf type {@code hbase.pb.SwitchRpcThrottleStateData}
   */
  @javax.annotation.Generated("proto") public  static final class SwitchRpcThrottleStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SwitchRpcThrottleStateData)
      SwitchRpcThrottleStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SwitchRpcThrottleStateData.newBuilder() to construct.
    private SwitchRpcThrottleStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SwitchRpcThrottleStateData() {
      rpcThrottleEnabled_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SwitchRpcThrottleStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              rpcThrottleEnabled_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.Builder.class);
    }

    private int bitField0_;
    public static final int RPC_THROTTLE_ENABLED_FIELD_NUMBER = 1;
    private boolean rpcThrottleEnabled_;
    /**
     * <code>required bool rpc_throttle_enabled = 1;</code>
     */
    public boolean hasRpcThrottleEnabled() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bool rpc_throttle_enabled = 1;</code>
     */
    public boolean getRpcThrottleEnabled() {
      return rpcThrottleEnabled_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRpcThrottleEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, rpcThrottleEnabled_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, rpcThrottleEnabled_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData) obj;

      boolean result = true;
      result = result && (hasRpcThrottleEnabled() == other.hasRpcThrottleEnabled());
      if (hasRpcThrottleEnabled()) {
        result = result && (getRpcThrottleEnabled()
            == other.getRpcThrottleEnabled());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRpcThrottleEnabled()) {
        hash = (37 * hash) + RPC_THROTTLE_ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRpcThrottleEnabled());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SwitchRpcThrottleStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SwitchRpcThrottleStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        rpcThrottleEnabled_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.rpcThrottleEnabled_ = rpcThrottleEnabled_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.getDefaultInstance()) return this;
        if (other.hasRpcThrottleEnabled()) {
          setRpcThrottleEnabled(other.getRpcThrottleEnabled());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRpcThrottleEnabled()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private boolean rpcThrottleEnabled_ ;
      /**
       * <code>required bool rpc_throttle_enabled = 1;</code>
       */
      public boolean hasRpcThrottleEnabled() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bool rpc_throttle_enabled = 1;</code>
       */
      public boolean getRpcThrottleEnabled() {
        return rpcThrottleEnabled_;
      }
      /**
       * <code>required bool rpc_throttle_enabled = 1;</code>
       */
      public Builder setRpcThrottleEnabled(boolean value) {
        bitField0_ |= 0x00000001;
        rpcThrottleEnabled_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool rpc_throttle_enabled = 1;</code>
       */
      public Builder clearRpcThrottleEnabled() {
        bitField0_ = (bitField0_ & ~0x00000001);
        rpcThrottleEnabled_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SwitchRpcThrottleStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SwitchRpcThrottleStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SwitchRpcThrottleStateData>() {
      public SwitchRpcThrottleStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new SwitchRpcThrottleStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SwitchRpcThrottleRemoteStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SwitchRpcThrottleRemoteStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <code>required bool rpc_throttle_enabled = 2;</code>
     */
    boolean hasRpcThrottleEnabled();
    /**
     * <code>required bool rpc_throttle_enabled = 2;</code>
     */
    boolean getRpcThrottleEnabled();
  }
  /**
   * Protobuf type {@code hbase.pb.SwitchRpcThrottleRemoteStateData}
   */
  @javax.annotation.Generated("proto") public  static final class SwitchRpcThrottleRemoteStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SwitchRpcThrottleRemoteStateData)
      SwitchRpcThrottleRemoteStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SwitchRpcThrottleRemoteStateData.newBuilder() to construct.
    private SwitchRpcThrottleRemoteStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SwitchRpcThrottleRemoteStateData() {
      rpcThrottleEnabled_ = false;
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SwitchRpcThrottleRemoteStateData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = targetServer_.toBuilder();
              }
              targetServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(targetServer_);
                targetServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              rpcThrottleEnabled_ = input.readBool();
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TARGET_SERVER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     */
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int RPC_THROTTLE_ENABLED_FIELD_NUMBER = 2;
    private boolean rpcThrottleEnabled_;
    /**
     * <code>required bool rpc_throttle_enabled = 2;</code>
     */
    public boolean hasRpcThrottleEnabled() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bool rpc_throttle_enabled = 2;</code>
     */
    public boolean getRpcThrottleEnabled() {
      return rpcThrottleEnabled_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRpcThrottleEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getTargetServer());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, rpcThrottleEnabled_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTargetServer());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, rpcThrottleEnabled_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData) obj;

      boolean result = true;
      result = result && (hasTargetServer() == other.hasTargetServer());
      if (hasTargetServer()) {
        result = result && getTargetServer()
            .equals(other.getTargetServer());
      }
      result = result && (hasRpcThrottleEnabled() == other.hasRpcThrottleEnabled());
      if (hasRpcThrottleEnabled()) {
        result = result && (getRpcThrottleEnabled()
            == other.getRpcThrottleEnabled());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasRpcThrottleEnabled()) {
        hash = (37 * hash) + RPC_THROTTLE_ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRpcThrottleEnabled());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SwitchRpcThrottleRemoteStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SwitchRpcThrottleRemoteStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTargetServerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        rpcThrottleEnabled_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (targetServerBuilder_ == null) {
          result.targetServer_ = targetServer_;
        } else {
          result.targetServer_ = targetServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.rpcThrottleEnabled_ = rpcThrottleEnabled_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.getDefaultInstance()) return this;
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasRpcThrottleEnabled()) {
          setRpcThrottleEnabled(other.getRpcThrottleEnabled());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasTargetServer()) {
          return false;
        }
        if (!hasRpcThrottleEnabled()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
          onChanged();
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
          onChanged();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              targetServer_ != null &&
              targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            targetServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(targetServer_).mergeFrom(value).buildPartial();
          } else {
            targetServer_ = value;
          }
          onChanged();
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public Builder clearTargetServer() {
        if (targetServerBuilder_ == null) {
          targetServer_ = null;
          onChanged();
        } else {
          targetServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private boolean rpcThrottleEnabled_ ;
      /**
       * <code>required bool rpc_throttle_enabled = 2;</code>
       */
      public boolean hasRpcThrottleEnabled() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bool rpc_throttle_enabled = 2;</code>
       */
      public boolean getRpcThrottleEnabled() {
        return rpcThrottleEnabled_;
      }
      /**
       * <code>required bool rpc_throttle_enabled = 2;</code>
       */
      public Builder setRpcThrottleEnabled(boolean value) {
        bitField0_ |= 0x00000002;
        rpcThrottleEnabled_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool rpc_throttle_enabled = 2;</code>
       */
      public Builder clearRpcThrottleEnabled() {
        bitField0_ = (bitField0_ & ~0x00000002);
        rpcThrottleEnabled_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SwitchRpcThrottleRemoteStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SwitchRpcThrottleRemoteStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleRemoteStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SwitchRpcThrottleRemoteStateData>() {
      public SwitchRpcThrottleRemoteStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new SwitchRpcThrottleRemoteStateData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleRemoteStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleRemoteStateData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SplitWALParameterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SplitWALParameter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string wal_path = 1;</code>
     */
    boolean hasWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     */
    java.lang.String getWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.SplitWALParameter}
   */
  @javax.annotation.Generated("proto") public  static final class SplitWALParameter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SplitWALParameter)
      SplitWALParameterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SplitWALParameter.newBuilder() to construct.
    private SplitWALParameter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SplitWALParameter() {
      walPath_ = "";
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SplitWALParameter(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              walPath_ = bs;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.Builder.class);
    }

    private int bitField0_;
    public static final int WAL_PATH_FIELD_NUMBER = 1;
    private volatile java.lang.Object walPath_;
    /**
     * <code>required string wal_path = 1;</code>
     */
    public boolean hasWalPath() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string wal_path = 1;</code>
     */
    public java.lang.String getWalPath() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          walPath_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string wal_path = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        walPath_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasWalPath()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, walPath_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, walPath_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter) obj;

      boolean result = true;
      result = result && (hasWalPath() == other.hasWalPath());
      if (hasWalPath()) {
        result = result && getWalPath()
            .equals(other.getWalPath());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasWalPath()) {
        hash = (37 * hash) + WAL_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getWalPath().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SplitWALParameter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SplitWALParameter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        walPath_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.walPath_ = walPath_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.getDefaultInstance()) return this;
        if (other.hasWalPath()) {
          bitField0_ |= 0x00000001;
          walPath_ = other.walPath_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasWalPath()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object walPath_ = "";
      /**
       * <code>required string wal_path = 1;</code>
       */
      public boolean hasWalPath() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public java.lang.String getWalPath() {
        java.lang.Object ref = walPath_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            walPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalPathBytes() {
        java.lang.Object ref = walPath_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          walPath_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder setWalPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        walPath_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder clearWalPath() {
        bitField0_ = (bitField0_ & ~0x00000001);
        walPath_ = getDefaultInstance().getWalPath();
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder setWalPathBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        walPath_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SplitWALParameter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SplitWALParameter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALParameter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SplitWALParameter>() {
      public SplitWALParameter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new SplitWALParameter(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALParameter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALParameter> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SplitWALDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SplitWALData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string wal_path = 1;</code>
     */
    boolean hasWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     */
    java.lang.String getWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes();

    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    boolean hasCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder();

    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    boolean hasWorker();
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker();
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SplitWALData}
   */
  @javax.annotation.Generated("proto") public  static final class SplitWALData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SplitWALData)
      SplitWALDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SplitWALData.newBuilder() to construct.
    private SplitWALData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SplitWALData() {
      walPath_ = "";
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SplitWALData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              walPath_ = bs;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = crashedServer_.toBuilder();
              }
              crashedServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(crashedServer_);
                crashedServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = worker_.toBuilder();
              }
              worker_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(worker_);
                worker_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.Builder.class);
    }

    private int bitField0_;
    public static final int WAL_PATH_FIELD_NUMBER = 1;
    private volatile java.lang.Object walPath_;
    /**
     * <code>required string wal_path = 1;</code>
     */
    public boolean hasWalPath() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string wal_path = 1;</code>
     */
    public java.lang.String getWalPath() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          walPath_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string wal_path = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        walPath_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CRASHED_SERVER_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    public boolean hasCrashedServer() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }

    public static final int WORKER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_;
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    public boolean hasWorker() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasWalPath()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCrashedServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCrashedServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasWorker()) {
        if (!getWorker().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, walPath_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getCrashedServer());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getWorker());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, walPath_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getCrashedServer());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getWorker());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData) obj;

      boolean result = true;
      result = result && (hasWalPath() == other.hasWalPath());
      if (hasWalPath()) {
        result = result && getWalPath()
            .equals(other.getWalPath());
      }
      result = result && (hasCrashedServer() == other.hasCrashedServer());
      if (hasCrashedServer()) {
        result = result && getCrashedServer()
            .equals(other.getCrashedServer());
      }
      result = result && (hasWorker() == other.hasWorker());
      if (hasWorker()) {
        result = result && getWorker()
            .equals(other.getWorker());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasWalPath()) {
        hash = (37 * hash) + WAL_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getWalPath().hashCode();
      }
      if (hasCrashedServer()) {
        hash = (37 * hash) + CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getCrashedServer().hashCode();
      }
      if (hasWorker()) {
        hash = (37 * hash) + WORKER_FIELD_NUMBER;
        hash = (53 * hash) + getWorker().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SplitWALData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SplitWALData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCrashedServerFieldBuilder();
          getWorkerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        walPath_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (crashedServerBuilder_ == null) {
          crashedServer_ = null;
        } else {
          crashedServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (workerBuilder_ == null) {
          worker_ = null;
        } else {
          workerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.walPath_ = walPath_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (crashedServerBuilder_ == null) {
          result.crashedServer_ = crashedServer_;
        } else {
          result.crashedServer_ = crashedServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (workerBuilder_ == null) {
          result.worker_ = worker_;
        } else {
          result.worker_ = workerBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.getDefaultInstance()) return this;
        if (other.hasWalPath()) {
          bitField0_ |= 0x00000001;
          walPath_ = other.walPath_;
          onChanged();
        }
        if (other.hasCrashedServer()) {
          mergeCrashedServer(other.getCrashedServer());
        }
        if (other.hasWorker()) {
          mergeWorker(other.getWorker());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasWalPath()) {
          return false;
        }
        if (!hasCrashedServer()) {
          return false;
        }
        if (!getCrashedServer().isInitialized()) {
          return false;
        }
        if (hasWorker()) {
          if (!getWorker().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object walPath_ = "";
      /**
       * <code>required string wal_path = 1;</code>
       */
      public boolean hasWalPath() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public java.lang.String getWalPath() {
        java.lang.Object ref = walPath_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            walPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalPathBytes() {
        java.lang.Object ref = walPath_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          walPath_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder setWalPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        walPath_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder clearWalPath() {
        bitField0_ = (bitField0_ & ~0x00000001);
        walPath_ = getDefaultInstance().getWalPath();
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder setWalPathBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        walPath_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> crashedServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public boolean hasCrashedServer() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
        if (crashedServerBuilder_ == null) {
          return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        } else {
          return crashedServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder setCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          crashedServer_ = value;
          onChanged();
        } else {
          crashedServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder setCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = builderForValue.build();
          onChanged();
        } else {
          crashedServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder mergeCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              crashedServer_ != null &&
              crashedServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            crashedServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(crashedServer_).mergeFrom(value).buildPartial();
          } else {
            crashedServer_ = value;
          }
          onChanged();
        } else {
          crashedServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder clearCrashedServer() {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = null;
          onChanged();
        } else {
          crashedServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getCrashedServerBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCrashedServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
        if (crashedServerBuilder_ != null) {
          return crashedServerBuilder_.getMessageOrBuilder();
        } else {
          return crashedServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getCrashedServerFieldBuilder() {
        if (crashedServerBuilder_ == null) {
          crashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getCrashedServer(),
                  getParentForChildren(),
                  isClean());
          crashedServer_ = null;
        }
        return crashedServerBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> workerBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public boolean hasWorker() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
        if (workerBuilder_ == null) {
          return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        } else {
          return workerBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          worker_ = value;
          onChanged();
        } else {
          workerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (workerBuilder_ == null) {
          worker_ = builderForValue.build();
          onChanged();
        } else {
          workerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder mergeWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              worker_ != null &&
              worker_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            worker_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(worker_).mergeFrom(value).buildPartial();
          } else {
            worker_ = value;
          }
          onChanged();
        } else {
          workerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder clearWorker() {
        if (workerBuilder_ == null) {
          worker_ = null;
          onChanged();
        } else {
          workerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getWorkerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getWorkerFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
        if (workerBuilder_ != null) {
          return workerBuilder_.getMessageOrBuilder();
        } else {
          return worker_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getWorkerFieldBuilder() {
        if (workerBuilder_ == null) {
          workerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getWorker(),
                  getParentForChildren(),
                  isClean());
          worker_ = null;
        }
        return workerBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SplitWALData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SplitWALData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SplitWALData>() {
      public SplitWALData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new SplitWALData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SplitWALRemoteDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SplitWALRemoteData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string wal_path = 1;</code>
     */
    boolean hasWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     */
    java.lang.String getWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes();

    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    boolean hasCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder();

    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     */
    boolean hasWorker();
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker();
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SplitWALRemoteData}
   */
  @javax.annotation.Generated("proto") public  static final class SplitWALRemoteData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SplitWALRemoteData)
      SplitWALRemoteDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SplitWALRemoteData.newBuilder() to construct.
    private SplitWALRemoteData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SplitWALRemoteData() {
      walPath_ = "";
    }

    @java.lang.Override
    public final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SplitWALRemoteData(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              walPath_ = bs;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = crashedServer_.toBuilder();
              }
              crashedServer_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(crashedServer_);
                crashedServer_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = worker_.toBuilder();
              }
              worker_ = input.readMessage(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(worker_);
                worker_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_descriptor;
    }

    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.Builder.class);
    }

    private int bitField0_;
    public static final int WAL_PATH_FIELD_NUMBER = 1;
    private volatile java.lang.Object walPath_;
    /**
     * <code>required string wal_path = 1;</code>
     */
    public boolean hasWalPath() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string wal_path = 1;</code>
     */
    public java.lang.String getWalPath() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          walPath_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string wal_path = 1;</code>
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        walPath_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CRASHED_SERVER_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    public boolean hasCrashedServer() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }

    public static final int WORKER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_;
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     */
    public boolean hasWorker() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     */
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasWalPath()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCrashedServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasWorker()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCrashedServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getWorker().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, walPath_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getCrashedServer());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getWorker());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, walPath_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getCrashedServer());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getWorker());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData) obj;

      boolean result = true;
      result = result && (hasWalPath() == other.hasWalPath());
      if (hasWalPath()) {
        result = result && getWalPath()
            .equals(other.getWalPath());
      }
      result = result && (hasCrashedServer() == other.hasCrashedServer());
      if (hasCrashedServer()) {
        result = result && getCrashedServer()
            .equals(other.getCrashedServer());
      }
      result = result && (hasWorker() == other.hasWorker());
      if (hasWorker()) {
        result = result && getWorker()
            .equals(other.getWorker());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasWalPath()) {
        hash = (37 * hash) + WAL_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getWalPath().hashCode();
      }
      if (hasCrashedServer()) {
        hash = (37 * hash) + CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getCrashedServer().hashCode();
      }
      if (hasWorker()) {
        hash = (37 * hash) + WORKER_FIELD_NUMBER;
        hash = (53 * hash) + getWorker().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SplitWALRemoteData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SplitWALRemoteData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_descriptor;
      }

      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCrashedServerFieldBuilder();
          getWorkerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        walPath_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (crashedServerBuilder_ == null) {
          crashedServer_ = null;
        } else {
          crashedServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (workerBuilder_ == null) {
          worker_ = null;
        } else {
          workerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_descriptor;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.walPath_ = walPath_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (crashedServerBuilder_ == null) {
          result.crashedServer_ = crashedServer_;
        } else {
          result.crashedServer_ = crashedServerBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (workerBuilder_ == null) {
          result.worker_ = worker_;
        } else {
          result.worker_ = workerBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.getDefaultInstance()) return this;
        if (other.hasWalPath()) {
          bitField0_ |= 0x00000001;
          walPath_ = other.walPath_;
          onChanged();
        }
        if (other.hasCrashedServer()) {
          mergeCrashedServer(other.getCrashedServer());
        }
        if (other.hasWorker()) {
          mergeWorker(other.getWorker());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (!hasWalPath()) {
          return false;
        }
        if (!hasCrashedServer()) {
          return false;
        }
        if (!hasWorker()) {
          return false;
        }
        if (!getCrashedServer().isInitialized()) {
          return false;
        }
        if (!getWorker().isInitialized()) {
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object walPath_ = "";
      /**
       * <code>required string wal_path = 1;</code>
       */
      public boolean hasWalPath() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public java.lang.String getWalPath() {
        java.lang.Object ref = walPath_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            walPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalPathBytes() {
        java.lang.Object ref = walPath_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          walPath_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder setWalPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        walPath_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder clearWalPath() {
        bitField0_ = (bitField0_ & ~0x00000001);
        walPath_ = getDefaultInstance().getWalPath();
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       */
      public Builder setWalPathBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        walPath_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> crashedServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public boolean hasCrashedServer() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
        if (crashedServerBuilder_ == null) {
          return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        } else {
          return crashedServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder setCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          crashedServer_ = value;
          onChanged();
        } else {
          crashedServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder setCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = builderForValue.build();
          onChanged();
        } else {
          crashedServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder mergeCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              crashedServer_ != null &&
              crashedServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            crashedServer_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(crashedServer_).mergeFrom(value).buildPartial();
          } else {
            crashedServer_ = value;
          }
          onChanged();
        } else {
          crashedServerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder clearCrashedServer() {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = null;
          onChanged();
        } else {
          crashedServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getCrashedServerBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCrashedServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
        if (crashedServerBuilder_ != null) {
          return crashedServerBuilder_.getMessageOrBuilder();
        } else {
          return crashedServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getCrashedServerFieldBuilder() {
        if (crashedServerBuilder_ == null) {
          crashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getCrashedServer(),
                  getParentForChildren(),
                  isClean());
          crashedServer_ = null;
        }
        return crashedServerBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_ = null;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> workerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public boolean hasWorker() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
        if (workerBuilder_ == null) {
          return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        } else {
          return workerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          worker_ = value;
          onChanged();
        } else {
          workerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (workerBuilder_ == null) {
          worker_ = builderForValue.build();
          onChanged();
        } else {
          workerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder mergeWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              worker_ != null &&
              worker_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            worker_ =
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.newBuilder(worker_).mergeFrom(value).buildPartial();
          } else {
            worker_ = value;
          }
          onChanged();
        } else {
          workerBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder clearWorker() {
        if (workerBuilder_ == null) {
          worker_ = null;
          onChanged();
        } else {
          workerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getWorkerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getWorkerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
        if (workerBuilder_ != null) {
          return workerBuilder_.getMessageOrBuilder();
        } else {
          return worker_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getWorkerFieldBuilder() {
        if (workerBuilder_ == null) {
          workerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getWorker(),
                  getParentForChildren(),
                  isClean());
          worker_ = null;
        }
        return workerBuilder_;
      }
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SplitWALRemoteData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SplitWALRemoteData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALRemoteData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SplitWALRemoteData>() {
      public SplitWALRemoteData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return new SplitWALRemoteData(input, extensionRegistry);
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALRemoteData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALRemoteData> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CreateTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TruncateTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_EnableTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DisableTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RestoreParentToChildRegionsPair_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CloneSnapshotStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CloneSnapshotStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RestoreSnapshotStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RestoreSnapshotStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DispatchMergingRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SplitTableRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SplitTableRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MergeTableRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MergeTableRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ServerCrashStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RecoverMetaStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RecoverMetaStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_AssignRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_AssignRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UnassignRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UnassignRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MoveRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MoveRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GCRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GCRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GCMergedRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GCMergedRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GCMultipleMergedRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_PeerModificationStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_PeerModificationStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RefreshPeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RefreshPeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RefreshPeerParameter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RefreshPeerParameter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_PeerProcedureStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_PeerProcedureStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_AddPeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_AddPeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UpdatePeerConfigStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RemovePeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RemovePeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_EnablePeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_EnablePeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DisablePeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DisablePeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ReopenTableRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_InitMetaStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_InitMetaStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RecoverStandbyStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RecoverStandbyStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SyncReplicationReplayWALStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SyncReplicationReplayWALStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ReplaySyncReplicationWALParameter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ReplaySyncReplicationWALParameter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RegionStateTransitionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RegionStateTransitionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_OpenRegionProcedureStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CloseRegionProcedureStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SwitchRpcThrottleStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SplitWALParameter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SplitWALParameter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SplitWALData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SplitWALData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SplitWALRemoteData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SplitWALRemoteData_fieldAccessorTable;

  public static org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\025MasterProcedure.proto\022\010hbase.pb\032\013HBase" +
      ".proto\032\tRPC.proto\032\016Snapshot.proto\032\021Repli" +
      "cation.proto\032\030RegionServerStatus.proto\"\234" +
      "\001\n\024CreateTableStateData\022,\n\tuser_info\030\001 \002" +
      "(\0132\031.hbase.pb.UserInformation\022+\n\014table_s" +
      "chema\030\002 \002(\0132\025.hbase.pb.TableSchema\022)\n\013re" +
      "gion_info\030\003 \003(\0132\024.hbase.pb.RegionInfo\"\373\001" +
      "\n\024ModifyTableStateData\022,\n\tuser_info\030\001 \002(" +
      "\0132\031.hbase.pb.UserInformation\0226\n\027unmodifi" +
      "ed_table_schema\030\002 \001(\0132\025.hbase.pb.TableSc" +
      "hema\0224\n\025modified_table_schema\030\003 \002(\0132\025.hb" +
      "ase.pb.TableSchema\022&\n\036delete_column_fami" +
      "ly_in_modify\030\004 \002(\010\022\037\n\027should_check_descr" +
      "iptor\030\005 \001(\010\"\340\001\n\026TruncateTableStateData\022," +
      "\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserInforma" +
      "tion\022\027\n\017preserve_splits\030\002 \002(\010\022\'\n\ntable_n" +
      "ame\030\003 \001(\0132\023.hbase.pb.TableName\022+\n\014table_" +
      "schema\030\004 \001(\0132\025.hbase.pb.TableSchema\022)\n\013r" +
      "egion_info\030\005 \003(\0132\024.hbase.pb.RegionInfo\"\230" +
      "\001\n\024DeleteTableStateData\022,\n\tuser_info\030\001 \002" +
      "(\0132\031.hbase.pb.UserInformation\022\'\n\ntable_n" +
      "ame\030\002 \002(\0132\023.hbase.pb.TableName\022)\n\013region" +
      "_info\030\003 \003(\0132\024.hbase.pb.RegionInfo\"W\n\030Cre" +
      "ateNamespaceStateData\022;\n\024namespace_descr" +
      "iptor\030\001 \002(\0132\035.hbase.pb.NamespaceDescript" +
      "or\"\237\001\n\030ModifyNamespaceStateData\022;\n\024names" +
      "pace_descriptor\030\001 \002(\0132\035.hbase.pb.Namespa" +
      "ceDescriptor\022F\n\037unmodified_namespace_des" +
      "criptor\030\002 \001(\0132\035.hbase.pb.NamespaceDescri" +
      "ptor\"o\n\030DeleteNamespaceStateData\022\026\n\016name" +
      "space_name\030\001 \002(\t\022;\n\024namespace_descriptor" +
      "\030\002 \001(\0132\035.hbase.pb.NamespaceDescriptor\"\221\001" +
      "\n\024EnableTableStateData\022,\n\tuser_info\030\001 \002(" +
      "\0132\031.hbase.pb.UserInformation\022\'\n\ntable_na" +
      "me\030\002 \002(\0132\023.hbase.pb.TableName\022\"\n\026skip_ta" +
      "ble_state_check\030\003 \002(\010B\002\030\001\"\216\001\n\025DisableTab" +
      "leStateData\022,\n\tuser_info\030\001 \002(\0132\031.hbase.p" +
      "b.UserInformation\022\'\n\ntable_name\030\002 \002(\0132\023." +
      "hbase.pb.TableName\022\036\n\026skip_table_state_c" +
      "heck\030\003 \002(\010\"u\n\037RestoreParentToChildRegion" +
      "sPair\022\032\n\022parent_region_name\030\001 \002(\t\022\032\n\022chi" +
      "ld1_region_name\030\002 \002(\t\022\032\n\022child2_region_n" +
      "ame\030\003 \002(\t\"\245\002\n\026CloneSnapshotStateData\022,\n\t" +
      "user_info\030\001 \002(\0132\031.hbase.pb.UserInformati" +
      "on\022/\n\010snapshot\030\002 \002(\0132\035.hbase.pb.Snapshot" +
      "Description\022+\n\014table_schema\030\003 \002(\0132\025.hbas" +
      "e.pb.TableSchema\022)\n\013region_info\030\004 \003(\0132\024." +
      "hbase.pb.RegionInfo\022T\n!parent_to_child_r" +
      "egions_pair_list\030\005 \003(\0132).hbase.pb.Restor" +
      "eParentToChildRegionsPair\"\245\003\n\030RestoreSna" +
      "pshotStateData\022,\n\tuser_info\030\001 \002(\0132\031.hbas" +
      "e.pb.UserInformation\022/\n\010snapshot\030\002 \002(\0132\035" +
      ".hbase.pb.SnapshotDescription\0224\n\025modifie" +
      "d_table_schema\030\003 \002(\0132\025.hbase.pb.TableSch" +
      "ema\0225\n\027region_info_for_restore\030\004 \003(\0132\024.h" +
      "base.pb.RegionInfo\0224\n\026region_info_for_re" +
      "move\030\005 \003(\0132\024.hbase.pb.RegionInfo\0221\n\023regi" +
      "on_info_for_add\030\006 \003(\0132\024.hbase.pb.RegionI" +
      "nfo\022T\n!parent_to_child_regions_pair_list" +
      "\030\007 \003(\0132).hbase.pb.RestoreParentToChildRe" +
      "gionsPair\"\265\001\n\037DispatchMergingRegionsStat" +
      "eData\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.User" +
      "Information\022\'\n\ntable_name\030\002 \002(\0132\023.hbase." +
      "pb.TableName\022)\n\013region_info\030\003 \003(\0132\024.hbas" +
      "e.pb.RegionInfo\022\020\n\010forcible\030\004 \001(\010\"\254\001\n\031Sp" +
      "litTableRegionStateData\022,\n\tuser_info\030\001 \002" +
      "(\0132\031.hbase.pb.UserInformation\0220\n\022parent_" +
      "region_info\030\002 \002(\0132\024.hbase.pb.RegionInfo\022" +
      "/\n\021child_region_info\030\003 \003(\0132\024.hbase.pb.Re" +
      "gionInfo\"\300\001\n\032MergeTableRegionsStateData\022" +
      ",\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserInform" +
      "ation\022)\n\013region_info\030\002 \003(\0132\024.hbase.pb.Re" +
      "gionInfo\0220\n\022merged_region_info\030\003 \001(\0132\024.h" +
      "base.pb.RegionInfo\022\027\n\010forcible\030\004 \001(\010:\005fa" +
      "lse\"\341\001\n\024ServerCrashStateData\022)\n\013server_n" +
      "ame\030\001 \002(\0132\024.hbase.pb.ServerName\0227\n\031regio" +
      "ns_on_crashed_server\030\003 \003(\0132\024.hbase.pb.Re" +
      "gionInfo\022.\n\020regions_assigned\030\004 \003(\0132\024.hba" +
      "se.pb.RegionInfo\022\025\n\rcarrying_meta\030\005 \001(\010\022" +
      "\036\n\020should_split_wal\030\006 \001(\010:\004true\"\177\n\024Recov" +
      "erMetaStateData\0220\n\022failed_meta_server\030\001 " +
      "\001(\0132\024.hbase.pb.ServerName\022\036\n\020should_spli" +
      "t_wal\030\002 \001(\010:\004true\022\025\n\nreplica_id\030\003 \001(\005:\0010" +
      "\"\332\001\n\025AssignRegionStateData\0229\n\020transition" +
      "_state\030\001 \002(\0162\037.hbase.pb.RegionTransition" +
      "State\022)\n\013region_info\030\002 \002(\0132\024.hbase.pb.Re" +
      "gionInfo\022\035\n\016force_new_plan\030\003 \001(\010:\005false\022" +
      "+\n\rtarget_server\030\004 \001(\0132\024.hbase.pb.Server" +
      "Name\022\017\n\007attempt\030\005 \001(\005\"\257\002\n\027UnassignRegion" +
      "StateData\0229\n\020transition_state\030\001 \002(\0162\037.hb" +
      "ase.pb.RegionTransitionState\022)\n\013region_i" +
      "nfo\030\002 \002(\0132\024.hbase.pb.RegionInfo\0220\n\022desti" +
      "nation_server\030\003 \001(\0132\024.hbase.pb.ServerNam" +
      "e\022,\n\016hosting_server\030\005 \001(\0132\024.hbase.pb.Ser" +
      "verName\022\024\n\005force\030\004 \001(\010:\005false\022\'\n\030remove_" +
      "after_unassigning\030\006 \001(\010:\005false\022\017\n\007attemp" +
      "t\030\007 \001(\005\"\237\001\n\023MoveRegionStateData\022)\n\013regio" +
      "n_info\030\001 \001(\0132\024.hbase.pb.RegionInfo\022+\n\rso" +
      "urce_server\030\002 \002(\0132\024.hbase.pb.ServerName\022" +
      "0\n\022destination_server\030\003 \001(\0132\024.hbase.pb.S" +
      "erverName\">\n\021GCRegionStateData\022)\n\013region" +
      "_info\030\001 \002(\0132\024.hbase.pb.RegionInfo\"\232\001\n\030GC" +
      "MergedRegionsStateData\022&\n\010parent_a\030\001 \002(\013" +
      "2\024.hbase.pb.RegionInfo\022&\n\010parent_b\030\002 \002(\013" +
      "2\024.hbase.pb.RegionInfo\022*\n\014merged_child\030\003" +
      " \002(\0132\024.hbase.pb.RegionInfo:\002\030\001\"u\n GCMult" +
      "ipleMergedRegionsStateData\022%\n\007parents\030\001 " +
      "\003(\0132\024.hbase.pb.RegionInfo\022*\n\014merged_chil" +
      "d\030\002 \002(\0132\024.hbase.pb.RegionInfo\",\n\031PeerMod" +
      "ificationStateData\022\017\n\007peer_id\030\001 \002(\t\"\224\001\n\024" +
      "RefreshPeerStateData\022\017\n\007peer_id\030\001 \002(\t\022,\n" +
      "\004type\030\002 \002(\0162\036.hbase.pb.PeerModificationT" +
      "ype\022+\n\rtarget_server\030\003 \002(\0132\024.hbase.pb.Se" +
      "rverName\022\020\n\005stage\030\004 \001(\r:\0010\"\224\001\n\024RefreshPe" +
      "erParameter\022\017\n\007peer_id\030\001 \002(\t\022,\n\004type\030\002 \002" +
      "(\0162\036.hbase.pb.PeerModificationType\022+\n\rta" +
      "rget_server\030\003 \002(\0132\024.hbase.pb.ServerName\022" +
      "\020\n\005stage\030\004 \001(\r:\0010\")\n\026PeerProcedureStateD" +
      "ata\022\017\n\007peer_id\030\001 \002(\t\"S\n\020AddPeerStateData" +
      "\022.\n\013peer_config\030\001 \002(\0132\031.hbase.pb.Replica" +
      "tionPeer\022\017\n\007enabled\030\002 \002(\010\"\220\001\n\031UpdatePeer" +
      "ConfigStateData\022.\n\013peer_config\030\001 \002(\0132\031.h" +
      "base.pb.ReplicationPeer\0222\n\017old_peer_conf" +
      "ig\030\002 \001(\0132\031.hbase.pb.ReplicationPeer\022\017\n\007e" +
      "nabled\030\003 \002(\010\"E\n\023RemovePeerStateData\022.\n\013p" +
      "eer_config\030\001 \001(\0132\031.hbase.pb.ReplicationP" +
      "eer\"\025\n\023EnablePeerStateData\"\026\n\024DisablePee" +
      "rStateData\"p\n\033ReopenTableRegionsStateDat" +
      "a\022\'\n\ntable_name\030\001 \002(\0132\023.hbase.pb.TableNa" +
      "me\022(\n\006region\030\002 \003(\0132\030.hbase.pb.RegionLoca" +
      "tion\"\023\n\021InitMetaStateData\"\216\001\n(TransitPee" +
      "rSyncReplicationStateStateData\0221\n\tfromSt" +
      "ate\030\001 \001(\0132\036.hbase.pb.SyncReplicationStat" +
      "e\022/\n\007toState\030\002 \002(\0132\036.hbase.pb.SyncReplic" +
      "ationState\")\n\027RecoverStandbyStateData\022\016\n" +
      "\006serial\030\001 \002(\010\"g\n!SyncReplicationReplayWA" +
      "LStateData\022\017\n\007peer_id\030\001 \002(\t\022\013\n\003wal\030\002 \003(\t" +
      "\022$\n\006worker\030\003 \001(\0132\024.hbase.pb.ServerName\"t" +
      "\n\'SyncReplicationReplayWALRemoteStateDat" +
      "a\022\017\n\007peer_id\030\001 \002(\t\022\013\n\003wal\030\002 \003(\t\022+\n\rtarge" +
      "t_server\030\003 \002(\0132\024.hbase.pb.ServerName\"A\n!" +
      "ReplaySyncReplicationWALParameter\022\017\n\007pee" +
      "r_id\030\001 \002(\t\022\013\n\003wal\030\002 \003(\t\"\226\001\n\036RegionStateT" +
      "ransitionStateData\022,\n\004type\030\001 \002(\0162\036.hbase" +
      ".pb.RegionTransitionType\022.\n\020assign_candi" +
      "date\030\002 \001(\0132\024.hbase.pb.ServerName\022\026\n\016forc" +
      "e_new_plan\030\003 \002(\010\"\211\002\n\"RegionRemoteProcedu" +
      "reBaseStateData\022$\n\006region\030\001 \002(\0132\024.hbase." +
      "pb.RegionInfo\022+\n\rtarget_server\030\002 \002(\0132\024.h" +
      "base.pb.ServerName\0227\n\005state\030\003 \002(\0162(.hbas" +
      "e.pb.RegionRemoteProcedureBaseState\022G\n\017t" +
      "ransition_code\030\004 \001(\0162..hbase.pb.RegionSt" +
      "ateTransition.TransitionCode\022\016\n\006seq_id\030\005" +
      " \001(\003\"\036\n\034OpenRegionProcedureStateData\"O\n\035" +
      "CloseRegionProcedureStateData\022.\n\020assign_" +
      "candidate\030\001 \001(\0132\024.hbase.pb.ServerName\":\n" +
      "\032SwitchRpcThrottleStateData\022\034\n\024rpc_throt" +
      "tle_enabled\030\001 \002(\010\"m\n SwitchRpcThrottleRe" +
      "moteStateData\022+\n\rtarget_server\030\001 \002(\0132\024.h" +
      "base.pb.ServerName\022\034\n\024rpc_throttle_enabl" +
      "ed\030\002 \002(\010\"%\n\021SplitWALParameter\022\020\n\010wal_pat" +
      "h\030\001 \002(\t\"t\n\014SplitWALData\022\020\n\010wal_path\030\001 \002(" +
      "\t\022,\n\016crashed_server\030\002 \002(\0132\024.hbase.pb.Ser" +
      "verName\022$\n\006worker\030\003 \001(\0132\024.hbase.pb.Serve" +
      "rName\"z\n\022SplitWALRemoteData\022\020\n\010wal_path\030" +
      "\001 \002(\t\022,\n\016crashed_server\030\002 \002(\0132\024.hbase.pb" +
      ".ServerName\022$\n\006worker\030\003 \002(\0132\024.hbase.pb.S" +
      "erverName*\330\001\n\020CreateTableState\022\036\n\032CREATE" +
      "_TABLE_PRE_OPERATION\020\001\022 \n\034CREATE_TABLE_W" +
      "RITE_FS_LAYOUT\020\002\022\034\n\030CREATE_TABLE_ADD_TO_" +
      "META\020\003\022\037\n\033CREATE_TABLE_ASSIGN_REGIONS\020\004\022" +
      "\"\n\036CREATE_TABLE_UPDATE_DESC_CACHE\020\005\022\037\n\033C" +
      "REATE_TABLE_POST_OPERATION\020\006*\207\002\n\020ModifyT" +
      "ableState\022\030\n\024MODIFY_TABLE_PREPARE\020\001\022\036\n\032M" +
      "ODIFY_TABLE_PRE_OPERATION\020\002\022(\n$MODIFY_TA" +
      "BLE_UPDATE_TABLE_DESCRIPTOR\020\003\022&\n\"MODIFY_" +
      "TABLE_REMOVE_REPLICA_COLUMN\020\004\022!\n\035MODIFY_" +
      "TABLE_DELETE_FS_LAYOUT\020\005\022\037\n\033MODIFY_TABLE" +
      "_POST_OPERATION\020\006\022#\n\037MODIFY_TABLE_REOPEN" +
      "_ALL_REGIONS\020\007*\212\002\n\022TruncateTableState\022 \n" +
      "\034TRUNCATE_TABLE_PRE_OPERATION\020\001\022#\n\037TRUNC" +
      "ATE_TABLE_REMOVE_FROM_META\020\002\022\"\n\036TRUNCATE" +
      "_TABLE_CLEAR_FS_LAYOUT\020\003\022#\n\037TRUNCATE_TAB" +
      "LE_CREATE_FS_LAYOUT\020\004\022\036\n\032TRUNCATE_TABLE_" +
      "ADD_TO_META\020\005\022!\n\035TRUNCATE_TABLE_ASSIGN_R" +
      "EGIONS\020\006\022!\n\035TRUNCATE_TABLE_POST_OPERATIO" +
      "N\020\007*\337\001\n\020DeleteTableState\022\036\n\032DELETE_TABLE" +
      "_PRE_OPERATION\020\001\022!\n\035DELETE_TABLE_REMOVE_" +
      "FROM_META\020\002\022 \n\034DELETE_TABLE_CLEAR_FS_LAY" +
      "OUT\020\003\022\"\n\036DELETE_TABLE_UPDATE_DESC_CACHE\020" +
      "\004\022!\n\035DELETE_TABLE_UNASSIGN_REGIONS\020\005\022\037\n\033" +
      "DELETE_TABLE_POST_OPERATION\020\006*\324\001\n\024Create" +
      "NamespaceState\022\034\n\030CREATE_NAMESPACE_PREPA" +
      "RE\020\001\022%\n!CREATE_NAMESPACE_CREATE_DIRECTOR" +
      "Y\020\002\022)\n%CREATE_NAMESPACE_INSERT_INTO_NS_T" +
      "ABLE\020\003\022\"\n\032CREATE_NAMESPACE_UPDATE_ZK\020\004\032\002" +
      "\010\001\022(\n$CREATE_NAMESPACE_SET_NAMESPACE_QUO" +
      "TA\020\005*~\n\024ModifyNamespaceState\022\034\n\030MODIFY_N" +
      "AMESPACE_PREPARE\020\001\022$\n MODIFY_NAMESPACE_U" +
      "PDATE_NS_TABLE\020\002\022\"\n\032MODIFY_NAMESPACE_UPD" +
      "ATE_ZK\020\003\032\002\010\001*\336\001\n\024DeleteNamespaceState\022\034\n" +
      "\030DELETE_NAMESPACE_PREPARE\020\001\022)\n%DELETE_NA" +
      "MESPACE_DELETE_FROM_NS_TABLE\020\002\022\'\n\037DELETE" +
      "_NAMESPACE_REMOVE_FROM_ZK\020\003\032\002\010\001\022\'\n#DELET" +
      "E_NAMESPACE_DELETE_DIRECTORIES\020\004\022+\n\'DELE" +
      "TE_NAMESPACE_REMOVE_NAMESPACE_QUOTA\020\005*\350\001" +
      "\n\020EnableTableState\022\030\n\024ENABLE_TABLE_PREPA" +
      "RE\020\001\022\036\n\032ENABLE_TABLE_PRE_OPERATION\020\002\022)\n%" +
      "ENABLE_TABLE_SET_ENABLING_TABLE_STATE\020\003\022" +
      "$\n ENABLE_TABLE_MARK_REGIONS_ONLINE\020\004\022(\n" +
      "$ENABLE_TABLE_SET_ENABLED_TABLE_STATE\020\005\022" +
      "\037\n\033ENABLE_TABLE_POST_OPERATION\020\006*\235\002\n\021Dis" +
      "ableTableState\022\031\n\025DISABLE_TABLE_PREPARE\020" +
      "\001\022\037\n\033DISABLE_TABLE_PRE_OPERATION\020\002\022+\n\'DI" +
      "SABLE_TABLE_SET_DISABLING_TABLE_STATE\020\003\022" +
      "&\n\"DISABLE_TABLE_MARK_REGIONS_OFFLINE\020\004\022" +
      "*\n&DISABLE_TABLE_SET_DISABLED_TABLE_STAT" +
      "E\020\005\022 \n\034DISABLE_TABLE_POST_OPERATION\020\006\022)\n" +
      "%DISABLE_TABLE_ADD_REPLICATION_BARRIER\020\007" +
      "*\206\002\n\022CloneSnapshotState\022 \n\034CLONE_SNAPSHO" +
      "T_PRE_OPERATION\020\001\022\"\n\036CLONE_SNAPSHOT_WRIT" +
      "E_FS_LAYOUT\020\002\022\036\n\032CLONE_SNAPSHOT_ADD_TO_M" +
      "ETA\020\003\022!\n\035CLONE_SNAPSHOT_ASSIGN_REGIONS\020\004" +
      "\022$\n CLONE_SNAPSHOT_UPDATE_DESC_CACHE\020\005\022!" +
      "\n\035CLONE_SNAPSHOT_POST_OPERATION\020\006\022\036\n\032CLO" +
      "NE_SNAPHOST_RESTORE_ACL\020\007*\322\001\n\024RestoreSna" +
      "pshotState\022\"\n\036RESTORE_SNAPSHOT_PRE_OPERA" +
      "TION\020\001\022,\n(RESTORE_SNAPSHOT_UPDATE_TABLE_" +
      "DESCRIPTOR\020\002\022$\n RESTORE_SNAPSHOT_WRITE_F" +
      "S_LAYOUT\020\003\022 \n\034RESTORE_SNAPSHOT_UPDATE_ME" +
      "TA\020\004\022 \n\034RESTORE_SNAPSHOT_RESTORE_ACL\020\005*\376" +
      "\001\n\033DispatchMergingRegionsState\022$\n DISPAT" +
      "CH_MERGING_REGIONS_PREPARE\020\001\022*\n&DISPATCH" +
      "_MERGING_REGIONS_PRE_OPERATION\020\002\0223\n/DISP" +
      "ATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME" +
      "_RS\020\003\022+\n\'DISPATCH_MERGING_REGIONS_DO_MER" +
      "GE_IN_RS\020\004\022+\n\'DISPATCH_MERGING_REGIONS_P" +
      "OST_OPERATION\020\005*\363\003\n\025SplitTableRegionStat" +
      "e\022\036\n\032SPLIT_TABLE_REGION_PREPARE\020\001\022$\n SPL" +
      "IT_TABLE_REGION_PRE_OPERATION\020\002\022*\n&SPLIT" +
      "_TABLE_REGION_CLOSE_PARENT_REGION\020\003\022.\n*S" +
      "PLIT_TABLE_REGION_CREATE_DAUGHTER_REGION" +
      "S\020\004\0221\n-SPLIT_TABLE_REGION_WRITE_MAX_SEQU" +
      "ENCE_ID_FILE\020\005\0220\n,SPLIT_TABLE_REGION_PRE" +
      "_OPERATION_BEFORE_META\020\006\022\"\n\036SPLIT_TABLE_" +
      "REGION_UPDATE_META\020\007\022/\n+SPLIT_TABLE_REGI" +
      "ON_PRE_OPERATION_AFTER_META\020\010\022)\n%SPLIT_T" +
      "ABLE_REGION_OPEN_CHILD_REGIONS\020\t\022%\n!SPLI" +
      "T_TABLE_REGION_POST_OPERATION\020\n\022,\n(SPLIT" +
      "_TABLE_REGIONS_CHECK_CLOSED_REGIONS\020\013*\246\004" +
      "\n\026MergeTableRegionsState\022\037\n\033MERGE_TABLE_" +
      "REGIONS_PREPARE\020\001\022%\n!MERGE_TABLE_REGIONS" +
      "_PRE_OPERATION\020\002\022+\n\'MERGE_TABLE_REGIONS_" +
      "PRE_MERGE_OPERATION\020\003\022%\n!MERGE_TABLE_REG" +
      "IONS_CLOSE_REGIONS\020\004\022,\n(MERGE_TABLE_REGI" +
      "ONS_CREATE_MERGED_REGION\020\005\0222\n.MERGE_TABL" +
      "E_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE\020\006\0222" +
      "\n.MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_O" +
      "PERATION\020\007\022#\n\037MERGE_TABLE_REGIONS_UPDATE" +
      "_META\020\010\0223\n/MERGE_TABLE_REGIONS_POST_MERG" +
      "E_COMMIT_OPERATION\020\t\022*\n&MERGE_TABLE_REGI" +
      "ONS_OPEN_MERGED_REGION\020\n\022&\n\"MERGE_TABLE_" +
      "REGIONS_POST_OPERATION\020\013\022,\n(MERGE_TABLE_" +
      "REGIONS_CHECK_CLOSED_REGIONS\020\014*\266\003\n\020Serve" +
      "rCrashState\022\026\n\022SERVER_CRASH_START\020\001\022!\n\031S" +
      "ERVER_CRASH_PROCESS_META\020\002\032\002\010\001\022\034\n\030SERVER" +
      "_CRASH_GET_REGIONS\020\003\022\"\n\032SERVER_CRASH_NO_" +
      "SPLIT_LOGS\020\004\032\002\010\001\022\033\n\027SERVER_CRASH_SPLIT_L" +
      "OGS\020\005\022\027\n\023SERVER_CRASH_ASSIGN\020\010\022\037\n\033SERVER" +
      "_CRASH_WAIT_ON_ASSIGN\020\t\022 \n\034SERVER_CRASH_" +
      "SPLIT_META_LOGS\020\n\022\034\n\030SERVER_CRASH_ASSIGN" +
      "_META\020\013\022+\n\'SERVER_CRASH_DELETE_SPLIT_MET" +
      "A_WALS_DIR\020\014\022&\n\"SERVER_CRASH_DELETE_SPLI" +
      "T_WALS_DIR\020\r\022 \n\030SERVER_CRASH_HANDLE_RIT2" +
      "\020\024\032\002\010\001\022\027\n\023SERVER_CRASH_FINISH\020d*j\n\020Recov" +
      "erMetaState\022\030\n\024RECOVER_META_PREPARE\020\000\022\033\n" +
      "\027RECOVER_META_SPLIT_LOGS\020\001\022\037\n\033RECOVER_ME" +
      "TA_ASSIGN_REGIONS\020\002*r\n\025RegionTransitionS" +
      "tate\022\033\n\027REGION_TRANSITION_QUEUE\020\001\022\036\n\032REG" +
      "ION_TRANSITION_DISPATCH\020\002\022\034\n\030REGION_TRAN" +
      "SITION_FINISH\020\003*\\\n\017MoveRegionState\022\027\n\023MO" +
      "VE_REGION_PREPARE\020\000\022\030\n\024MOVE_REGION_UNASS" +
      "IGN\020\001\022\026\n\022MOVE_REGION_ASSIGN\020\002*[\n\rGCRegio" +
      "nState\022\025\n\021GC_REGION_PREPARE\020\001\022\025\n\021GC_REGI" +
      "ON_ARCHIVE\020\002\022\034\n\030GC_REGION_PURGE_METADATA" +
      "\020\003*o\n\024GCMergedRegionsState\022\035\n\031GC_MERGED_" +
      "REGIONS_PREPARE\020\001\022\033\n\027GC_MERGED_REGIONS_P" +
      "URGE\020\002\022\033\n\027GC_REGION_EDIT_METADATA\020\003*\234\002\n\025" +
      "PeerModificationState\022\031\n\025PRE_PEER_MODIFI" +
      "CATION\020\001\022\027\n\023UPDATE_PEER_STORAGE\020\002\022\026\n\022REF" +
      "RESH_PEER_ON_RS\020\003\022\036\n\032SERIAL_PEER_REOPEN_" +
      "REGIONS\020\004\022)\n%SERIAL_PEER_UPDATE_LAST_PUS" +
      "HED_SEQ_ID\020\005\022 \n\034SERIAL_PEER_SET_PEER_ENA" +
      "BLED\020\006\022.\n*SERIAL_PEER_ENABLE_PEER_REFRES" +
      "H_PEER_ON_RS\020\007\022\032\n\026POST_PEER_MODIFICATION" +
      "\020\010*\355\004\n\'PeerSyncReplicationStateTransitio" +
      "nState\022.\n*PRE_PEER_SYNC_REPLICATION_STAT" +
      "E_TRANSITION\020\001\022\'\n#SET_PEER_NEW_SYNC_REPL" +
      "ICATION_STATE\020\002\0223\n/REFRESH_PEER_SYNC_REP" +
      "LICATION_STATE_ON_RS_BEGIN\020\003\022\036\n\032REOPEN_A" +
      "LL_REGIONS_IN_PEER\020\004\022>\n:SYNC_REPLICATION" +
      "_UPDATE_LAST_PUSHED_SEQ_ID_FOR_SERIAL_PE" +
      "ER\020\005\022\035\n\031REPLAY_REMOTE_WAL_IN_PEER\020\006\022)\n%R" +
      "EMOVE_ALL_REPLICATION_QUEUES_IN_PEER\020\007\022+" +
      "\n\'TRANSIT_PEER_NEW_SYNC_REPLICATION_STAT" +
      "E\020\010\0221\n-REFRESH_PEER_SYNC_REPLICATION_STA" +
      "TE_ON_RS_END\020\t\022%\n!SYNC_REPLICATION_SET_P" +
      "EER_ENABLED\020\n\0223\n/SYNC_REPLICATION_ENABLE" +
      "_PEER_REFRESH_PEER_ON_RS\020\013\022\035\n\031CREATE_DIR" +
      "_FOR_REMOTE_WAL\020\014\022/\n+POST_PEER_SYNC_REPL" +
      "ICATION_STATE_TRANSITION\020\r*\224\001\n\024PeerModif" +
      "icationType\022\014\n\010ADD_PEER\020\001\022\017\n\013REMOVE_PEER" +
      "\020\002\022\017\n\013ENABLE_PEER\020\003\022\020\n\014DISABLE_PEER\020\004\022\026\n" +
      "\022UPDATE_PEER_CONFIG\020\005\022\"\n\036TRANSIT_SYNC_RE" +
      "PLICATION_STATE\020\006*\223\001\n\027ReopenTableRegions" +
      "State\022$\n REOPEN_TABLE_REGIONS_GET_REGION" +
      "S\020\001\022\'\n#REOPEN_TABLE_REGIONS_REOPEN_REGIO" +
      "NS\020\002\022)\n%REOPEN_TABLE_REGIONS_CONFIRM_REO" +
      "PENED\020\003*K\n\rInitMetaState\022\031\n\025INIT_META_AS" +
      "SIGN_META\020\001\022\037\n\033INIT_META_CREATE_NAMESPAC" +
      "ES\020\002*\304\001\n\023RecoverStandbyState\022$\n RENAME_S" +
      "YNC_REPLICATION_WALS_DIR\020\001\022#\n\037REGISTER_P" +
      "EER_TO_WORKER_STORAGE\020\002\022\021\n\rDISPATCH_WALS" +
      "\020\003\022\'\n#UNREGISTER_PEER_FROM_WORKER_STORAG" +
      "E\020\004\022&\n\"SNAPSHOT_SYNC_REPLICATION_WALS_DI" +
      "R\020\005*c\n\035SyncReplicationReplayWALState\022\021\n\r" +
      "ASSIGN_WORKER\020\001\022\033\n\027DISPATCH_WALS_TO_WORK" +
      "ER\020\002\022\022\n\016RELEASE_WORKER\020\003*\353\001\n\032RegionState" +
      "TransitionState\0220\n,REGION_STATE_TRANSITI" +
      "ON_GET_ASSIGN_CANDIDATE\020\001\022 \n\034REGION_STAT" +
      "E_TRANSITION_OPEN\020\002\022*\n&REGION_STATE_TRAN" +
      "SITION_CONFIRM_OPENED\020\003\022!\n\035REGION_STATE_" +
      "TRANSITION_CLOSE\020\004\022*\n&REGION_STATE_TRANS" +
      "ITION_CONFIRM_CLOSED\020\005*F\n\024RegionTransiti" +
      "onType\022\n\n\006ASSIGN\020\001\022\014\n\010UNASSIGN\020\002\022\010\n\004MOVE" +
      "\020\003\022\n\n\006REOPEN\020\004*\307\001\n\036RegionRemoteProcedure" +
      "BaseState\022$\n REGION_REMOTE_PROCEDURE_DIS" +
      "PATCH\020\001\022*\n&REGION_REMOTE_PROCEDURE_REPOR" +
      "T_SUCCEED\020\002\022)\n%REGION_REMOTE_PROCEDURE_D" +
      "ISPATCH_FAIL\020\003\022(\n$REGION_REMOTE_PROCEDUR" +
      "E_SERVER_CRASH\020\004*}\n\026SwitchRpcThrottleSta" +
      "te\022&\n\"UPDATE_SWITCH_RPC_THROTTLE_STORAGE" +
      "\020\001\022\035\n\031SWITCH_RPC_THROTTLE_ON_RS\020\002\022\034\n\030POS" +
      "T_SWITCH_RPC_THROTTLE\020\003*c\n\rSplitWALState" +
      "\022\034\n\030ACQUIRE_SPLIT_WAL_WORKER\020\001\022\032\n\026DISPAT" +
      "CH_WAL_TO_WORKER\020\002\022\030\n\024RELEASE_SPLIT_WORK" +
      "ER\020\003BR\n1org.apache.hadoop.hbase.shaded.p" +
      "rotobuf.generatedB\025MasterProcedureProtos" +
      "H\001\210\001\001\240\001\001"
    };
    org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistry assignDescriptors(
              org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.getDescriptor(),
        }, assigner);
    internal_static_hbase_pb_CreateTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CreateTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableSchema", "RegionInfo", });
    internal_static_hbase_pb_ModifyTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "UnmodifiedTableSchema", "ModifiedTableSchema", "DeleteColumnFamilyInModify", "ShouldCheckDescriptor", });
    internal_static_hbase_pb_TruncateTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_TruncateTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "PreserveSplits", "TableName", "TableSchema", "RegionInfo", });
    internal_static_hbase_pb_DeleteTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DeleteTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "RegionInfo", });
    internal_static_hbase_pb_CreateNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CreateNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceDescriptor", });
    internal_static_hbase_pb_ModifyNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceDescriptor", "UnmodifiedNamespaceDescriptor", });
    internal_static_hbase_pb_DeleteNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DeleteNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceName", "NamespaceDescriptor", });
    internal_static_hbase_pb_EnableTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_EnableTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "SkipTableStateCheck", });
    internal_static_hbase_pb_DisableTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DisableTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "SkipTableStateCheck", });
    internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hbase_pb_RestoreParentToChildRegionsPair_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor,
        new java.lang.String[] { "ParentRegionName", "Child1RegionName", "Child2RegionName", });
    internal_static_hbase_pb_CloneSnapshotStateData_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hbase_pb_CloneSnapshotStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CloneSnapshotStateData_descriptor,
        new java.lang.String[] { "UserInfo", "Snapshot", "TableSchema", "RegionInfo", "ParentToChildRegionsPairList", });
    internal_static_hbase_pb_RestoreSnapshotStateData_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hbase_pb_RestoreSnapshotStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RestoreSnapshotStateData_descriptor,
        new java.lang.String[] { "UserInfo", "Snapshot", "ModifiedTableSchema", "RegionInfoForRestore", "RegionInfoForRemove", "RegionInfoForAdd", "ParentToChildRegionsPairList", });
    internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hbase_pb_DispatchMergingRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "RegionInfo", "Forcible", });
    internal_static_hbase_pb_SplitTableRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_hbase_pb_SplitTableRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SplitTableRegionStateData_descriptor,
        new java.lang.String[] { "UserInfo", "ParentRegionInfo", "ChildRegionInfo", });
    internal_static_hbase_pb_MergeTableRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_hbase_pb_MergeTableRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MergeTableRegionsStateData_descriptor,
        new java.lang.String[] { "UserInfo", "RegionInfo", "MergedRegionInfo", "Forcible", });
    internal_static_hbase_pb_ServerCrashStateData_descriptor =
      getDescriptor().getMessageTypes().get(15);
    internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ServerCrashStateData_descriptor,
        new java.lang.String[] { "ServerName", "RegionsOnCrashedServer", "RegionsAssigned", "CarryingMeta", "ShouldSplitWal", });
    internal_static_hbase_pb_RecoverMetaStateData_descriptor =
      getDescriptor().getMessageTypes().get(16);
    internal_static_hbase_pb_RecoverMetaStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RecoverMetaStateData_descriptor,
        new java.lang.String[] { "FailedMetaServer", "ShouldSplitWal", "ReplicaId", });
    internal_static_hbase_pb_AssignRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(17);
    internal_static_hbase_pb_AssignRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_AssignRegionStateData_descriptor,
        new java.lang.String[] { "TransitionState", "RegionInfo", "ForceNewPlan", "TargetServer", "Attempt", });
    internal_static_hbase_pb_UnassignRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(18);
    internal_static_hbase_pb_UnassignRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UnassignRegionStateData_descriptor,
        new java.lang.String[] { "TransitionState", "RegionInfo", "DestinationServer", "HostingServer", "Force", "RemoveAfterUnassigning", "Attempt", });
    internal_static_hbase_pb_MoveRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(19);
    internal_static_hbase_pb_MoveRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MoveRegionStateData_descriptor,
        new java.lang.String[] { "RegionInfo", "SourceServer", "DestinationServer", });
    internal_static_hbase_pb_GCRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(20);
    internal_static_hbase_pb_GCRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GCRegionStateData_descriptor,
        new java.lang.String[] { "RegionInfo", });
    internal_static_hbase_pb_GCMergedRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(21);
    internal_static_hbase_pb_GCMergedRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GCMergedRegionsStateData_descriptor,
        new java.lang.String[] { "ParentA", "ParentB", "MergedChild", });
    internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(22);
    internal_static_hbase_pb_GCMultipleMergedRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor,
        new java.lang.String[] { "Parents", "MergedChild", });
    internal_static_hbase_pb_PeerModificationStateData_descriptor =
      getDescriptor().getMessageTypes().get(23);
    internal_static_hbase_pb_PeerModificationStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_PeerModificationStateData_descriptor,
        new java.lang.String[] { "PeerId", });
    internal_static_hbase_pb_RefreshPeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(24);
    internal_static_hbase_pb_RefreshPeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RefreshPeerStateData_descriptor,
        new java.lang.String[] { "PeerId", "Type", "TargetServer", "Stage", });
    internal_static_hbase_pb_RefreshPeerParameter_descriptor =
      getDescriptor().getMessageTypes().get(25);
    internal_static_hbase_pb_RefreshPeerParameter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RefreshPeerParameter_descriptor,
        new java.lang.String[] { "PeerId", "Type", "TargetServer", "Stage", });
    internal_static_hbase_pb_PeerProcedureStateData_descriptor =
      getDescriptor().getMessageTypes().get(26);
    internal_static_hbase_pb_PeerProcedureStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_PeerProcedureStateData_descriptor,
        new java.lang.String[] { "PeerId", });
    internal_static_hbase_pb_AddPeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(27);
    internal_static_hbase_pb_AddPeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_AddPeerStateData_descriptor,
        new java.lang.String[] { "PeerConfig", "Enabled", });
    internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor =
      getDescriptor().getMessageTypes().get(28);
    internal_static_hbase_pb_UpdatePeerConfigStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor,
        new java.lang.String[] { "PeerConfig", "OldPeerConfig", "Enabled", });
    internal_static_hbase_pb_RemovePeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(29);
    internal_static_hbase_pb_RemovePeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RemovePeerStateData_descriptor,
        new java.lang.String[] { "PeerConfig", });
    internal_static_hbase_pb_EnablePeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(30);
    internal_static_hbase_pb_EnablePeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_EnablePeerStateData_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_DisablePeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(31);
    internal_static_hbase_pb_DisablePeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DisablePeerStateData_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(32);
    internal_static_hbase_pb_ReopenTableRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor,
        new java.lang.String[] { "TableName", "Region", });
    internal_static_hbase_pb_InitMetaStateData_descriptor =
      getDescriptor().getMessageTypes().get(33);
    internal_static_hbase_pb_InitMetaStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_InitMetaStateData_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_descriptor =
      getDescriptor().getMessageTypes().get(34);
    internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_TransitPeerSyncReplicationStateStateData_descriptor,
        new java.lang.String[] { "FromState", "ToState", });
    internal_static_hbase_pb_RecoverStandbyStateData_descriptor =
      getDescriptor().getMessageTypes().get(35);
    internal_static_hbase_pb_RecoverStandbyStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RecoverStandbyStateData_descriptor,
        new java.lang.String[] { "Serial", });
    internal_static_hbase_pb_SyncReplicationReplayWALStateData_descriptor =
      getDescriptor().getMessageTypes().get(36);
    internal_static_hbase_pb_SyncReplicationReplayWALStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SyncReplicationReplayWALStateData_descriptor,
        new java.lang.String[] { "PeerId", "Wal", "Worker", });
    internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_descriptor =
      getDescriptor().getMessageTypes().get(37);
    internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SyncReplicationReplayWALRemoteStateData_descriptor,
        new java.lang.String[] { "PeerId", "Wal", "TargetServer", });
    internal_static_hbase_pb_ReplaySyncReplicationWALParameter_descriptor =
      getDescriptor().getMessageTypes().get(38);
    internal_static_hbase_pb_ReplaySyncReplicationWALParameter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ReplaySyncReplicationWALParameter_descriptor,
        new java.lang.String[] { "PeerId", "Wal", });
    internal_static_hbase_pb_RegionStateTransitionStateData_descriptor =
      getDescriptor().getMessageTypes().get(39);
    internal_static_hbase_pb_RegionStateTransitionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RegionStateTransitionStateData_descriptor,
        new java.lang.String[] { "Type", "AssignCandidate", "ForceNewPlan", });
    internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor =
      getDescriptor().getMessageTypes().get(40);
    internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor,
        new java.lang.String[] { "Region", "TargetServer", "State", "TransitionCode", "SeqId", });
    internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor =
      getDescriptor().getMessageTypes().get(41);
    internal_static_hbase_pb_OpenRegionProcedureStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor =
      getDescriptor().getMessageTypes().get(42);
    internal_static_hbase_pb_CloseRegionProcedureStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor,
        new java.lang.String[] { "AssignCandidate", });
    internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor =
      getDescriptor().getMessageTypes().get(43);
    internal_static_hbase_pb_SwitchRpcThrottleStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor,
        new java.lang.String[] { "RpcThrottleEnabled", });
    internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor =
      getDescriptor().getMessageTypes().get(44);
    internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor,
        new java.lang.String[] { "TargetServer", "RpcThrottleEnabled", });
    internal_static_hbase_pb_SplitWALParameter_descriptor =
      getDescriptor().getMessageTypes().get(45);
    internal_static_hbase_pb_SplitWALParameter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SplitWALParameter_descriptor,
        new java.lang.String[] { "WalPath", });
    internal_static_hbase_pb_SplitWALData_descriptor =
      getDescriptor().getMessageTypes().get(46);
    internal_static_hbase_pb_SplitWALData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SplitWALData_descriptor,
        new java.lang.String[] { "WalPath", "CrashedServer", "Worker", });
    internal_static_hbase_pb_SplitWALRemoteData_descriptor =
      getDescriptor().getMessageTypes().get(47);
    internal_static_hbase_pb_SplitWALRemoteData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SplitWALRemoteData_descriptor,
        new java.lang.String[] { "WalPath", "CrashedServer", "Worker", });
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
